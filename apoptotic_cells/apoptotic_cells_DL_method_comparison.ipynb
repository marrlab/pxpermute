{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Apoptotic cells\n",
    "\n",
    "In this jupyter notebook, we provide an example of how to extract explainable features and run a classification for the imaging flow cytometry dataset provided by:\n",
    "\n",
    "In vivo identification of apoptotic and extracellular vesicle-bound live cells using image-based deep learning https://doi.org/10.1080%2F20013078.2020.1792683\n",
    "\n",
    "\n",
    "We assume you have already installed the library. Otherwise you can install it using \n",
    "\n",
    "`!pip -q install <Path to the cloned module>`\n",
    "\n",
    "This notebook provides an example for deep learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we import a series of needed modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scifAI\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from imageio import imread\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from IPython.core.debugger import Tracer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# Compare Algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scifAI.dl.utils import calculate_weights, get_statistics\n",
    "from scifAI.dl.dataset import DatasetGenerator\n",
    "from scifAI.dl.custom_transforms import ShuffleChannel\n",
    "from scifAI.dl.models import PretrainedModel, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iflai.dl.models import PretrainedModel\n",
    "from skorch.callbacks import LRScheduler,Checkpoint,EpochScoring,EarlyStopping\n",
    "import torch.optim as optim\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we provide a function for visualizing the result of the confusion matrix which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (plot_confusion_matrix, \n",
    "                             matthews_corrcoef, \n",
    "                             classification_report,\n",
    "                             confusion_matrix, \n",
    "                             accuracy_score, \n",
    "                             balanced_accuracy_score, \n",
    "                             cohen_kappa_score, \n",
    "                             f1_score,  \n",
    "                             precision_score, recall_score)\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "def classification_complete_report(y_true, y_pred, plot = True ): \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(15*\"----\")\n",
    "    print(\"matthews correlation coeff: %.2f\" % (matthews_corrcoef(y_true, y_pred)) )\n",
    "    print(\"Cohen Kappa score: %.2f\" % (cohen_kappa_score(y_true, y_pred)) )\n",
    "    print(\"Accuracy: %.2f & balanced Accuracy: %.2f\" % (accuracy_score(y_true, y_pred), balanced_accuracy_score(y_true, y_pred)) )\n",
    "    print(\"macro F1 score: %.2f & micro F1 score: %.2f\" % (f1_score(y_true, y_pred, average = \"macro\"), f1_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Precision score: %.2f & micro Precision score: %.2f\" % (precision_score(y_true, y_pred, average = \"macro\"), precision_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Recall score: %.2f & micro Recall score: %.2f\" % (recall_score(y_true, y_pred, average = \"macro\"), recall_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(15*\"----\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets calculate the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata prepration starts...\n",
      "Experiment_1 Donor_1 condition_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15311/15311 [00:02<00:00, 5508.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...metadata prepration ended.\n",
      "CPU times: user 229 ms, sys: 173 ms, total: 402 ms\n",
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_path = \"/pstore/data/DS4/Apoptotic_cell_detection/\"\n",
    "metadata = scifAI.metadata_generator(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>experiment</th>\n",
       "      <th>donor</th>\n",
       "      <th>condition</th>\n",
       "      <th>object_number</th>\n",
       "      <th>set</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>822</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>12187</td>\n",
       "      <td>labeled</td>\n",
       "      <td>non-apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>2295</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>14306</td>\n",
       "      <td>labeled</td>\n",
       "      <td>non-apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>2584</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>10365</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>2952</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>7308</td>\n",
       "      <td>labeled</td>\n",
       "      <td>non-apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>3211</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15310</th>\n",
       "      <td>/pstore/data/DS4/Apoptotic_cell_detection/Expe...</td>\n",
       "      <td>Experiment_1</td>\n",
       "      <td>Donor_1</td>\n",
       "      <td>condition_1</td>\n",
       "      <td>3500</td>\n",
       "      <td>labeled</td>\n",
       "      <td>apoptotic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file    experiment  \\\n",
       "0      /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "1      /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "2      /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "3      /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "4      /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "...                                                  ...           ...   \n",
       "15306  /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "15307  /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "15308  /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "15309  /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "15310  /pstore/data/DS4/Apoptotic_cell_detection/Expe...  Experiment_1   \n",
       "\n",
       "         donor    condition object_number      set          label  \n",
       "0      Donor_1  condition_1           822  labeled      apoptotic  \n",
       "1      Donor_1  condition_1         12187  labeled  non-apoptotic  \n",
       "2      Donor_1  condition_1          2295  labeled      apoptotic  \n",
       "3      Donor_1  condition_1         14306  labeled  non-apoptotic  \n",
       "4      Donor_1  condition_1          2584  labeled      apoptotic  \n",
       "...        ...          ...           ...      ...            ...  \n",
       "15306  Donor_1  condition_1         10365  labeled      apoptotic  \n",
       "15307  Donor_1  condition_1          2952  labeled      apoptotic  \n",
       "15308  Donor_1  condition_1          7308  labeled  non-apoptotic  \n",
       "15309  Donor_1  condition_1          3211  labeled      apoptotic  \n",
       "15310  Donor_1  condition_1          3500  labeled      apoptotic  \n",
       "\n",
       "[15311 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apoptotic' 'non-apoptotic']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(metadata.label.unique())\n",
    "metadata.label.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have 31280  files with various labels. first we need to get rid of `unknown` labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = metadata.label != \"unknown\"\n",
    "\n",
    "metadata = metadata.loc[row_index,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets plot a random image per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apoptotic\n",
      "non-apoptotic\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.util import crop\n",
    "import h5py\n",
    "\n",
    "def crop_pad_h_w(image_dummy,reshape_size):\n",
    "    if image_dummy.shape[0] < reshape_size:\n",
    "        h1_pad = ( reshape_size - image_dummy.shape[0])/2\n",
    "        h1_pad = int(h1_pad)\n",
    "        h2_pad =  reshape_size - h1_pad - image_dummy.shape[0]\n",
    "        h1_crop = 0\n",
    "        h2_crop = 0\n",
    "    else:\n",
    "        h1_pad = 0\n",
    "        h2_pad = 0\n",
    "        h1_crop = ( reshape_size - image_dummy.shape[0])/2\n",
    "        h1_crop = abs(int(h1_crop))\n",
    "        h2_crop = image_dummy.shape[0]- reshape_size  - h1_crop\n",
    "\n",
    "    if image_dummy.shape[1] < reshape_size:\n",
    "        w1_pad = (reshape_size - image_dummy.shape[1])/2\n",
    "        w1_pad = int(w1_pad)\n",
    "        w2_pad = reshape_size - w1_pad - image_dummy.shape[1]\n",
    "        w1_crop = 0\n",
    "        w2_crop = 0\n",
    "    else:\n",
    "        w1_pad = 0\n",
    "        w2_pad = 0\n",
    "        w1_crop = (reshape_size - image_dummy.shape[1])/2\n",
    "        w1_crop = abs(int(w1_crop))\n",
    "        w2_crop = image_dummy.shape[1]- reshape_size  - w1_crop\n",
    "\n",
    "    h = [h1_crop, h2_crop, h1_pad, h2_pad]\n",
    "    w = [w1_crop, w2_crop, w1_pad, w2_pad] \n",
    "    return h, w\n",
    "\n",
    "def plot_images_with_metadata(metadata,  \n",
    "                              figsize = None,\n",
    "                              channels = [\"BF\",\"BF\", \"BF\"],\n",
    "                    channel_colors =  [\"Greys\", \"Oranges\", \"Blues\"],\n",
    "                    image_size = 128):\n",
    "    \n",
    "    metadata_dummy = metadata.copy()\n",
    "    metadata_dummy = metadata_dummy.reset_index(drop = True)\n",
    "    \n",
    "    nrows = len(metadata_dummy)\n",
    "    ncols = len(channel_colors)\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = ( ncols*2, nrows*2 )\n",
    "    fix,ax = plt.subplots(nrows, ncols, figsize = figsize, tight_layout = True)\n",
    "    \n",
    "    vmin = [4095.]*ncols\n",
    "    vmax = [0.]*ncols\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        h5_file_ = h5py.File(metadata_dummy.loc[i,\"file\"], \"r\")\n",
    "        image = h5_file_.get(\"image\")[()]\n",
    "        for j, ch in enumerate(range(ncols)):\n",
    "            vmin[j] = min(vmin[j], image[:,:,ch].min()  )\n",
    "            vmax[j] = max(vmax[j], image[:,:,ch].max()  )\n",
    "        \n",
    "    for i in range(nrows):\n",
    "        h5_file_ = h5py.File(metadata_dummy.loc[i,\"file\"], \"r\")\n",
    "        image = h5_file_.get(\"image\")[()]         \n",
    "        \n",
    "        h, w = crop_pad_h_w(image, image_size)\n",
    "        h1_crop, h2_crop, h1_pad, h2_pad =  h \n",
    "        w1_crop, w2_crop, w1_pad, w2_pad = w \n",
    "        for j, ch in enumerate(channel_colors):\n",
    "            image_dummy = crop(image[:,:,j], ((h1_crop,h2_crop),(w1_crop,w2_crop)))            \n",
    "            image_dummy = np.pad(image_dummy, \n",
    "                                     ((h1_pad,h2_pad),(w1_pad,w2_pad)), \n",
    "                                     'constant', \n",
    "                                     constant_values = np.mean(image_dummy) )\n",
    "            ax[i,j].imshow(image_dummy, cmap = channel_colors[j] , vmin = vmin[j], vmax = vmax[j]  )\n",
    "            ax[i,j].set_xticks([])\n",
    "            ax[i,j].set_yticks([])\n",
    "            \n",
    "            if j == 0:\n",
    "                print(metadata_dummy.loc[i,\"label\"])\n",
    "                ax[i,j].set_ylabel(metadata_dummy.loc[i,\"label\"])\n",
    "            if i == 0:\n",
    "                ax[i,j].set_xlabel(channels[j])\n",
    "                ax[i,j].xaxis.set_label_position('top') \n",
    "            \n",
    "        h5_file_.close()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "plot_images_with_metadata(metadata.groupby('label').apply(lambda s: s.sample(1, random_state = 2)).reset_index(drop = True) ,  \n",
    "                              figsize = (2,2),\n",
    "                    channel_colors =  [\"Greys\", \"copper\"],\n",
    "                          channels = [\"BF\",\"FL\"],\n",
    "                    image_size = 32)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"Dataset 1 - apoptotic vs non apoptotic cells.png\", bbox_inches='tight')\n",
    "plt.savefig(\"Dataset 1 - apoptotic vs non apoptotic cells.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all random seeds to the specific value, so the results are more reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = \"models\"\n",
    "log_dir = \"logs\"\n",
    "scaling_factor = 255.\n",
    "reshape_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_importance = pd.read_csv(\"channel_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>channel</th>\n",
       "      <th>PXPermute</th>\n",
       "      <th>DeepLift</th>\n",
       "      <th>IntegratedGradients</th>\n",
       "      <th>LRP</th>\n",
       "      <th>GuidedGradCAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ch0</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.965327</td>\n",
       "      <td>0.089264</td>\n",
       "      <td>0.147628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ch1</td>\n",
       "      <td>0.967601</td>\n",
       "      <td>0.230190</td>\n",
       "      <td>0.059443</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.147888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ch0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299684</td>\n",
       "      <td>0.475304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ch1</td>\n",
       "      <td>0.918331</td>\n",
       "      <td>0.183626</td>\n",
       "      <td>0.135990</td>\n",
       "      <td>0.268165</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ch0</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>0.559447</td>\n",
       "      <td>0.734979</td>\n",
       "      <td>0.404710</td>\n",
       "      <td>0.221419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Ch1</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>0.183922</td>\n",
       "      <td>0.203820</td>\n",
       "      <td>0.322268</td>\n",
       "      <td>0.988272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Ch0</td>\n",
       "      <td>0.021791</td>\n",
       "      <td>0.602487</td>\n",
       "      <td>0.659754</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>0.152042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Ch1</td>\n",
       "      <td>0.952428</td>\n",
       "      <td>0.187828</td>\n",
       "      <td>0.169965</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>0.068092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Ch0</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Ch1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold channel  PXPermute  DeepLift  IntegratedGradients       LRP  \\\n",
       "0     1     Ch0   0.016934  0.536150             0.965327  0.089264   \n",
       "1     1     Ch1   0.967601  0.230190             0.059443  0.429087   \n",
       "2     3     Ch0   0.000000  0.299684             0.475304  0.000000   \n",
       "3     3     Ch1   0.918331  0.183626             0.135990  0.268165   \n",
       "4     4     Ch0   0.015669  0.559447             0.734979  0.404710   \n",
       "5     4     Ch1   0.993797  0.183922             0.203820  0.322268   \n",
       "6     2     Ch0   0.021791  0.602487             0.659754  0.228663   \n",
       "7     2     Ch1   0.952428  0.187828             0.169965  0.399413   \n",
       "8     5     Ch0   0.006567  1.000000             1.000000  1.000000   \n",
       "9     5     Ch1   1.000000  0.000000             0.000000  0.206133   \n",
       "\n",
       "   GuidedGradCAM  \n",
       "0       0.147628  \n",
       "1       0.147888  \n",
       "2       0.158674  \n",
       "3       1.000000  \n",
       "4       0.221419  \n",
       "5       0.988272  \n",
       "6       0.152042  \n",
       "7       0.068092  \n",
       "8       0.159642  \n",
       "9       0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "interpretation_methods = [\"PXPermute\", \"DeepLift\", \"IntegratedGradients\", \"LRP\", \"GuidedGradCAM\"]\n",
    "channel_importance.loc[:, interpretation_methods] = MinMaxScaler().fit_transform(channel_importance.loc[:, interpretation_methods])\n",
    "\n",
    "channel_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='variable', ylabel='value'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(data = pd.melt(channel_importance, id_vars=[\"fold\",\"channel\"]), \n",
    "            x = \"variable\", \n",
    "            y = \"value\",\n",
    "            hue = \"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_channels(channel_importance, method, num_top_channels):\n",
    "    grouped_importance = channel_importance.loc[:,[\"channel\",method]].groupby(\"channel\").mean()\n",
    "    grouped_importance = grouped_importance.sort_values(by=method, ascending = False) \n",
    "    selected_channels = grouped_importance.index[:num_top_channels]\n",
    "    selected_channels = [int(ch.replace(\"Ch\",\"\")) for ch in selected_channels]\n",
    "    return selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "    \n",
    "class MinMaxScaler(object):\n",
    "    def __init__(self, min_in , max_in, min_out, max_out):\n",
    "        self.min_in = min_in.reshape(-1,1,1)\n",
    "        self.max_in = max_in.reshape(-1,1,1)\n",
    "        self.min_out = min_out\n",
    "        self.max_out = max_out\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \n",
    "        tensor_ = (tensor - self.min_in)/(self.max_in - self.min_in)\n",
    "        tensor_ = tensor_*(self.max_out - self.min_out) + self.min_out\n",
    "        tensor_[tensor_<self.min_out]= self.min_out\n",
    "        tensor_[tensor_>self.max_out]= self.max_out\n",
    "        return tensor_\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(min_out={0}, max_out={1})'.format(self.min_out, self.max_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PXPermute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:08<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0170]), 'p05': tensor([0.0272]), 'p25': tensor([0.0483]), 'p50': tensor([0.0758]), 'p75': tensor([0.1620]), 'p95': tensor([0.7778]), 'p99': tensor([2.1694]), 'max': tensor([247.5107]), 'mean': tensor([0.2220]), 'std': tensor([1.9308])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3011\u001b[0m       \u001b[32m0.8935\u001b[0m            \u001b[35m0.8927\u001b[0m            \u001b[31m0.8935\u001b[0m        \u001b[94m0.2633\u001b[0m     +  5.5429\n",
      "      2        \u001b[36m0.2146\u001b[0m       0.8861            0.8840            0.8861        0.2801        5.5650\n",
      "      3        \u001b[36m0.1968\u001b[0m       \u001b[32m0.9073\u001b[0m            \u001b[35m0.9059\u001b[0m            \u001b[31m0.9073\u001b[0m        \u001b[94m0.2108\u001b[0m     +  5.4779\n",
      "      4        \u001b[36m0.1886\u001b[0m       \u001b[32m0.9282\u001b[0m            \u001b[35m0.9271\u001b[0m            \u001b[31m0.9282\u001b[0m        \u001b[94m0.1757\u001b[0m     +  5.4922\n",
      "      5        \u001b[36m0.1798\u001b[0m       0.8808            0.8805            0.8808        0.3075        5.5418\n",
      "      6        \u001b[36m0.1712\u001b[0m       0.9049            0.9036            0.9049        0.2410        5.5648\n",
      "      7        0.1745       0.9212            0.9201            0.9212        0.1855        5.4652\n",
      "      8        \u001b[36m0.1626\u001b[0m       \u001b[32m0.9396\u001b[0m            \u001b[35m0.9373\u001b[0m            \u001b[31m0.9396\u001b[0m        \u001b[94m0.1682\u001b[0m     +  5.5699\n",
      "      9        \u001b[36m0.1530\u001b[0m       0.9392            \u001b[35m0.9377\u001b[0m            0.9392        \u001b[94m0.1485\u001b[0m     +  5.6150\n",
      "     10        \u001b[36m0.1496\u001b[0m       0.9224            0.9215            0.9224        0.1979        5.6126\n",
      "     11        \u001b[36m0.1429\u001b[0m       0.9188            0.9180            0.9188        0.2050        5.6079\n",
      "     12        \u001b[36m0.1385\u001b[0m       0.9327            0.9316            0.9327        0.1669        5.5812\n",
      "     13        0.1468       0.8347            0.8347            0.8347        0.4356        5.5279\n",
      "     14        0.1431       0.9388            0.9373            0.9388        0.1550        5.5049\n",
      "     15        \u001b[36m0.1327\u001b[0m       0.9384            0.9370            0.9384        \u001b[94m0.1405\u001b[0m        5.5330\n",
      "     16        \u001b[36m0.1303\u001b[0m       0.9216            0.9201            0.9216        0.1887        5.5516\n",
      "     17        \u001b[36m0.1293\u001b[0m       0.9351            0.9340            0.9351        0.1583        5.5339\n",
      "     18        \u001b[36m0.1230\u001b[0m       0.9229            0.9219            0.9229        0.1791        5.5264\n",
      "     19        0.1245       0.9037            0.9030            0.9037        0.2435        5.5884\n",
      "     20        \u001b[36m0.1221\u001b[0m       0.9102            0.9091            0.9102        0.2049        5.6685\n",
      "     21        \u001b[36m0.1154\u001b[0m       \u001b[32m0.9412\u001b[0m            \u001b[35m0.9395\u001b[0m            \u001b[31m0.9412\u001b[0m        \u001b[94m0.1340\u001b[0m     +  5.5246\n",
      "     22        0.1210       0.9371            0.9358            0.9371        0.1654        5.5309\n",
      "     23        \u001b[36m0.1151\u001b[0m       0.8878            0.8874            0.8878        0.3054        5.5697\n",
      "     24        \u001b[36m0.1111\u001b[0m       0.9314            0.9304            0.9314        0.1594        5.5385\n",
      "     25        \u001b[36m0.1098\u001b[0m       0.9004            0.8998            0.9004        0.2414        5.5823\n",
      "     26        0.1102       0.9380            0.9364            0.9380        0.1636        5.5067\n",
      "     27        \u001b[36m0.1048\u001b[0m       0.9396            0.9371            0.9396        0.1848        5.4973\n",
      "     28        0.1049       \u001b[32m0.9416\u001b[0m            \u001b[35m0.9397\u001b[0m            \u001b[31m0.9416\u001b[0m        0.1534     +  5.5501\n",
      "     29        \u001b[36m0.1024\u001b[0m       \u001b[32m0.9506\u001b[0m            \u001b[35m0.9492\u001b[0m            \u001b[31m0.9506\u001b[0m        \u001b[94m0.1205\u001b[0m     +  5.5831\n",
      "     30        0.1033       0.9269            0.9261            0.9269        0.1721        5.5002\n",
      "     31        \u001b[36m0.0975\u001b[0m       0.9412            0.9398            0.9412        0.1358        5.5077\n",
      "     32        \u001b[36m0.0950\u001b[0m       0.8992            0.8986            0.8992        0.2585        5.5382\n",
      "     33        0.0985       0.9298            0.9285            0.9298        0.2010        5.4695\n",
      "     34        0.1205       0.9384            0.9373            0.9384        0.1542        5.5462\n",
      "     35        0.1055       0.9241            0.9230            0.9241        0.1911        5.6214\n",
      "     36        \u001b[36m0.0944\u001b[0m       0.9396            0.9383            0.9396        0.1614        5.5504\n",
      "     37        0.1035       0.9241            0.9230            0.9241        0.1615        5.6324\n",
      "     38        \u001b[36m0.0917\u001b[0m       0.9355            0.9339            0.9355        0.1747        5.5783\n",
      "     39        \u001b[36m0.0913\u001b[0m       0.9371            0.9359            0.9371        0.1504        5.4812\n",
      "     40        \u001b[36m0.0840\u001b[0m       0.9384            0.9372            0.9384        0.1603        5.6091\n",
      "     41        0.0898       0.9351            0.9339            0.9351        0.1752        5.5698\n",
      "     42        0.0876       0.9408            0.9391            0.9408        0.1290        5.4933\n",
      "     43        0.0895       0.9478            0.9460            0.9478        0.1474        5.6414\n",
      "     44        \u001b[36m0.0816\u001b[0m       0.9416            0.9400            0.9416        0.1439        5.5275\n",
      "     45        \u001b[36m0.0803\u001b[0m       0.9135            0.9127            0.9135        0.2330        5.5588\n",
      "     46        0.0811       0.9335            0.9321            0.9335        0.1813        5.5202\n",
      "     47        0.0810       0.9376            0.9363            0.9376        0.1673        5.4765\n",
      "     48        \u001b[36m0.0757\u001b[0m       0.9343            0.9330            0.9343        0.1735        5.5109\n",
      "     49        \u001b[36m0.0730\u001b[0m       0.9355            0.9337            0.9355        0.1748        5.5040\n",
      "     50        0.0731       0.9469            0.9457            0.9469        0.1576        5.5674\n",
      "     51        \u001b[36m0.0708\u001b[0m       0.9461            0.9446            0.9461        0.1769        5.5982\n",
      "     52        \u001b[36m0.0684\u001b[0m       0.9469            0.9456            0.9469        0.1524        5.6114\n",
      "     53        0.0740       0.9257            0.9245            0.9257        0.2139        5.5218\n",
      "     54        \u001b[36m0.0668\u001b[0m       0.9392            0.9380            0.9392        0.1654        5.5282\n",
      "     55        \u001b[36m0.0665\u001b[0m       0.9449            0.9431            0.9449        0.1803        5.6098\n",
      "     56        0.0682       0.9473            0.9460            0.9473        0.1466        5.5124\n",
      "     57        0.0672       0.9290            0.9280            0.9290        0.1792        5.4885\n",
      "     58        \u001b[36m0.0632\u001b[0m       0.9306            0.9295            0.9306        0.2186        5.4560\n",
      "     59        \u001b[36m0.0579\u001b[0m       0.9314            0.9303            0.9314        0.2152        5.5432\n",
      "     60        0.0598       0.9408            0.9394            0.9408        0.1967        5.5766\n",
      "     61        0.0777       0.9465            0.9449            0.9465        0.1284        5.5882\n",
      "     62        \u001b[36m0.0572\u001b[0m       0.9437            0.9422            0.9437        0.1728        5.5056\n",
      "     63        \u001b[36m0.0569\u001b[0m       0.9400            0.9390            0.9400        0.1643        5.5048\n",
      "     64        \u001b[36m0.0565\u001b[0m       0.9371            0.9357            0.9371        0.1889        5.4964\n",
      "     65        \u001b[36m0.0551\u001b[0m       0.9245            0.9234            0.9245        0.2706        5.5875\n",
      "     66        \u001b[36m0.0542\u001b[0m       0.9367            0.9357            0.9367        0.1762        5.5426\n",
      "     67        0.0553       0.9490            0.9476            0.9490        0.1505        5.5116\n",
      "     68        \u001b[36m0.0520\u001b[0m       0.9478            0.9462            0.9478        0.1688        5.4870\n",
      "     69        0.0561       0.9453            0.9440            0.9453        0.1381        5.4798\n",
      "     70        \u001b[36m0.0498\u001b[0m       0.9449            0.9432            0.9449        0.1693        5.5270\n",
      "     71        \u001b[36m0.0433\u001b[0m       0.9388            0.9374            0.9388        0.1947        5.5231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        0.0534       0.9376            0.9361            0.9376        0.1757        5.5307\n",
      "     73        0.0467       0.9424            0.9406            0.9424        0.1789        5.5403\n",
      "     74        0.0521       0.9420            0.9405            0.9420        0.1656        5.6084\n",
      "     75        0.0523       0.9376            0.9361            0.9376        0.1689        5.6459\n",
      "     76        \u001b[36m0.0422\u001b[0m       0.9367            0.9353            0.9367        0.1953        5.5449\n",
      "     77        0.0457       0.9392            0.9373            0.9392        0.1937        5.6858\n",
      "     78        0.0456       0.9331            0.9320            0.9331        0.2305        5.5221\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:08<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0169]), 'p05': tensor([0.0272]), 'p25': tensor([0.0480]), 'p50': tensor([0.0762]), 'p75': tensor([0.1629]), 'p95': tensor([0.7811]), 'p99': tensor([2.1453]), 'max': tensor([250.7375]), 'mean': tensor([0.2232]), 'std': tensor([2.0162])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3065\u001b[0m       \u001b[32m0.9012\u001b[0m            \u001b[35m0.8960\u001b[0m            \u001b[31m0.9012\u001b[0m        \u001b[94m0.2291\u001b[0m     +  5.5345\n",
      "      2        \u001b[36m0.2106\u001b[0m       \u001b[32m0.9208\u001b[0m            \u001b[35m0.9195\u001b[0m            \u001b[31m0.9208\u001b[0m        \u001b[94m0.2130\u001b[0m     +  5.5142\n",
      "      3        \u001b[36m0.1934\u001b[0m       0.9037            0.9028            0.9037        0.2424        5.4894\n",
      "      4        \u001b[36m0.1809\u001b[0m       \u001b[32m0.9261\u001b[0m            \u001b[35m0.9252\u001b[0m            \u001b[31m0.9261\u001b[0m        0.2271     +  5.4924\n",
      "      5        \u001b[36m0.1726\u001b[0m       0.9171            0.9159            0.9171        \u001b[94m0.2120\u001b[0m        5.5473\n",
      "      6        \u001b[36m0.1684\u001b[0m       0.9151            0.9138            0.9151        0.2517        5.5727\n",
      "      7        \u001b[36m0.1626\u001b[0m       0.9106            0.9095            0.9106        0.2427        5.4989\n",
      "      8        \u001b[36m0.1613\u001b[0m       \u001b[32m0.9294\u001b[0m            \u001b[35m0.9276\u001b[0m            \u001b[31m0.9294\u001b[0m        \u001b[94m0.1620\u001b[0m     +  5.4960\n",
      "      9        \u001b[36m0.1576\u001b[0m       \u001b[32m0.9367\u001b[0m            \u001b[35m0.9353\u001b[0m            \u001b[31m0.9367\u001b[0m        0.1781     +  5.5627\n",
      "     10        \u001b[36m0.1549\u001b[0m       0.9163            0.9138            0.9163        0.2247        5.5161\n",
      "     11        \u001b[36m0.1440\u001b[0m       0.9302            0.9289            0.9302        0.1815        5.5384\n",
      "     12        \u001b[36m0.1392\u001b[0m       0.9310            0.9290            0.9310        \u001b[94m0.1592\u001b[0m        5.5823\n",
      "     13        \u001b[36m0.1378\u001b[0m       0.9118            0.9106            0.9118        0.2407        5.5898\n",
      "     14        0.1406       \u001b[32m0.9437\u001b[0m            \u001b[35m0.9423\u001b[0m            \u001b[31m0.9437\u001b[0m        \u001b[94m0.1448\u001b[0m     +  5.5518\n",
      "     15        \u001b[36m0.1308\u001b[0m       0.9290            0.9268            0.9290        0.1823        5.4995\n",
      "     16        0.1334       0.9122            0.9110            0.9122        0.2213        5.5336\n",
      "     17        \u001b[36m0.1262\u001b[0m       0.9322            0.9310            0.9322        0.1613        5.5143\n",
      "     18        0.1300       0.9433            0.9419            0.9433        0.1493        5.5515\n",
      "     19        \u001b[36m0.1259\u001b[0m       0.9408            0.9399            0.9408        0.1765        5.5318\n",
      "     20        \u001b[36m0.1194\u001b[0m       0.9347            0.9338            0.9347        0.1737        5.5387\n",
      "     21        \u001b[36m0.1157\u001b[0m       0.9131            0.9093            0.9131        0.2140        5.5297\n",
      "     22        0.1170       0.9310            0.9299            0.9310        0.1597        5.4828\n",
      "     23        0.1179       0.9037            0.9031            0.9037        0.2699        5.6536\n",
      "     24        0.1213       0.9420            0.9410            0.9420        0.1492        5.4686\n",
      "     25        0.1162       0.9376            0.9363            0.9376        0.1662        5.5831\n",
      "     26        \u001b[36m0.1114\u001b[0m       0.9355            0.9343            0.9355        0.1537        5.4683\n",
      "     27        0.1116       0.9437            0.9421            0.9437        \u001b[94m0.1444\u001b[0m        5.5915\n",
      "     28        \u001b[36m0.1102\u001b[0m       0.9102            0.9092            0.9102        0.2363        5.5792\n",
      "     29        \u001b[36m0.1080\u001b[0m       0.9380            0.9367            0.9380        0.1690        5.4888\n",
      "     30        0.1115       0.9171            0.9163            0.9171        0.2215        5.5158\n",
      "     31        0.1108       0.9359            0.9346            0.9359        0.1799        5.5304\n",
      "     32        0.1135       0.9224            0.9214            0.9224        0.2208        5.5750\n",
      "     33        \u001b[36m0.1029\u001b[0m       0.9367            0.9356            0.9367        0.1933        5.4940\n",
      "     34        \u001b[36m0.1008\u001b[0m       0.9388            0.9376            0.9388        0.1768        5.5425\n",
      "     35        \u001b[36m0.0989\u001b[0m       0.9420            0.9405            0.9420        0.1651        5.5922\n",
      "     36        \u001b[36m0.0971\u001b[0m       0.9371            0.9347            0.9371        0.1550        5.6252\n",
      "     37        \u001b[36m0.0838\u001b[0m       0.9363            0.9350            0.9363        0.1777        5.5609\n",
      "     38        0.1005       0.9396            0.9386            0.9396        0.1597        5.5693\n",
      "     39        0.0981       0.9400            0.9386            0.9400        0.1577        5.5170\n",
      "     40        0.0884       0.9351            0.9330            0.9351        0.1769        5.5430\n",
      "     41        0.0864       0.9367            0.9355            0.9367        0.1632        5.5150\n",
      "     42        0.0865       \u001b[32m0.9445\u001b[0m            \u001b[35m0.9429\u001b[0m            \u001b[31m0.9445\u001b[0m        0.1491     +  5.5090\n",
      "     43        0.0844       0.9327            0.9316            0.9327        0.2063        5.5670\n",
      "     44        \u001b[36m0.0741\u001b[0m       0.9380            0.9367            0.9380        0.1600        5.5373\n",
      "     45        \u001b[36m0.0558\u001b[0m       0.9351            0.9341            0.9351        0.2273        5.5475\n",
      "     46        0.0584       0.9445            \u001b[35m0.9433\u001b[0m            0.9445        0.1747     +  5.6918\n",
      "     47        0.0599       0.9404            0.9390            0.9404        0.2020        5.6065\n",
      "     48        0.0587       \u001b[32m0.9469\u001b[0m            \u001b[35m0.9454\u001b[0m            \u001b[31m0.9469\u001b[0m        0.1585     +  5.5933\n",
      "     49        \u001b[36m0.0511\u001b[0m       0.9429            0.9416            0.9429        0.2368        5.5020\n",
      "     50        0.0590       0.9457            0.9446            0.9457        0.1871        5.5091\n",
      "     51        0.0574       0.9457            0.9445            0.9457        0.1781        5.5403\n",
      "     52        0.0525       0.9261            0.9251            0.9261        0.2628        5.5363\n",
      "     53        0.0551       0.9371            0.9358            0.9371        0.1890        5.5611\n",
      "     54        \u001b[36m0.0511\u001b[0m       0.9424            0.9413            0.9424        0.2098        5.5654\n",
      "     55        \u001b[36m0.0482\u001b[0m       0.9416            0.9405            0.9416        0.2047        5.5503\n",
      "     56        0.0512       0.9359            0.9348            0.9359        0.1808        5.6244\n",
      "     57        \u001b[36m0.0475\u001b[0m       0.9347            0.9333            0.9347        0.2162        5.6056\n",
      "     58        \u001b[36m0.0475\u001b[0m       0.9400            0.9387            0.9400        0.2125        5.5566\n",
      "     59        \u001b[36m0.0405\u001b[0m       0.9404            0.9392            0.9404        0.2429        5.5708\n",
      "     60        0.0469       0.9376            0.9363            0.9376        0.2434        5.4815\n",
      "     61        0.0475       0.9457            0.9443            0.9457        0.1794        5.5749\n",
      "     62        0.0477       0.9392            0.9381            0.9392        0.2067        5.5252\n",
      "     63        \u001b[36m0.0388\u001b[0m       0.9392            0.9381            0.9392        0.2562        5.6120\n",
      "     64        0.0440       0.9339            0.9328            0.9339        0.2161        5.5886\n",
      "     65        0.0417       0.9371            0.9360            0.9371        0.2348        5.6021\n",
      "     66        0.0394       0.9400            0.9387            0.9400        0.2162        5.5164\n",
      "     67        \u001b[36m0.0363\u001b[0m       0.9318            0.9307            0.9318        0.2796        5.5109\n",
      "     68        0.0454       0.9449            0.9431            0.9449        0.2113        5.4862\n",
      "     69        0.0389       0.9224            0.9214            0.9224        0.2952        5.5654\n",
      "     70        0.0400       0.9294            0.9276            0.9294        0.2169        5.6846\n",
      "     71        0.0400       0.9412            0.9400            0.9412        0.2205        5.4964\n",
      "     72        \u001b[36m0.0329\u001b[0m       0.9404            0.9394            0.9404        0.2335        6.1828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        0.0341       0.9453            0.9439            0.9453        0.2176        5.4987\n",
      "     74        0.0396       0.9384            0.9370            0.9384        0.2311        5.4629\n",
      "     75        \u001b[36m0.0311\u001b[0m       0.9359            0.9345            0.9359        0.2704        5.5512\n",
      "     76        0.0317       0.9461            0.9449            0.9461        0.2161        5.5787\n",
      "     77        0.0324       0.9363            0.9351            0.9363        0.2635        5.5541\n",
      "     78        0.0332       0.9416            0.9403            0.9416        0.2033        5.5894\n",
      "     79        \u001b[36m0.0310\u001b[0m       0.9396            0.9382            0.9396        0.2578        5.5078\n",
      "     80        \u001b[36m0.0292\u001b[0m       0.9412            0.9399            0.9412        0.2486        5.5227\n",
      "     81        0.0339       0.9429            0.9413            0.9429        0.2209        5.5197\n",
      "     82        0.0326       0.9429            0.9411            0.9429        0.2133        5.4665\n",
      "     83        \u001b[36m0.0230\u001b[0m       0.9404            0.9390            0.9404        0.2539        5.5453\n",
      "     84        0.0269       0.9400            0.9389            0.9400        0.2707        5.6453\n",
      "     85        0.0267       0.9416            0.9403            0.9416        0.2422        5.5613\n",
      "     86        0.0322       0.9318            0.9305            0.9318        0.2514        5.5412\n",
      "     87        0.0281       0.9371            0.9355            0.9371        0.2181        5.5683\n",
      "     88        \u001b[36m0.0193\u001b[0m       0.9441            0.9427            0.9441        0.2811        5.5936\n",
      "     89        0.0286       0.9363            0.9352            0.9363        0.2581        5.6132\n",
      "     90        0.0299       0.9367            0.9356            0.9367        0.2318        5.4773\n",
      "     91        0.0246       0.9302            0.9291            0.9302        0.3384        5.4764\n",
      "     92        0.0336       0.9429            0.9415            0.9429        0.2556        5.4759\n",
      "     93        0.0227       0.9424            0.9412            0.9424        0.2644        5.5675\n",
      "     94        0.0255       0.9392            0.9377            0.9392        0.2343        5.5807\n",
      "     95        0.0193       0.9449            0.9434            0.9449        0.2470        5.5658\n",
      "     96        \u001b[36m0.0121\u001b[0m       0.9449            0.9435            0.9449        0.2511        5.5178\n",
      "     97        \u001b[36m0.0104\u001b[0m       0.9445            0.9432            0.9445        0.2836        5.5805\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:08<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0172]), 'p05': tensor([0.0271]), 'p25': tensor([0.0482]), 'p50': tensor([0.0761]), 'p75': tensor([0.1647]), 'p95': tensor([0.7964]), 'p99': tensor([2.2115]), 'max': tensor([247.5681]), 'mean': tensor([0.2254]), 'std': tensor([1.9382])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3125\u001b[0m       \u001b[32m0.7339\u001b[0m            \u001b[35m0.7322\u001b[0m            \u001b[31m0.7339\u001b[0m        \u001b[94m0.6793\u001b[0m     +  5.4852\n",
      "      2        \u001b[36m0.2132\u001b[0m       \u001b[32m0.8845\u001b[0m            \u001b[35m0.8834\u001b[0m            \u001b[31m0.8845\u001b[0m        \u001b[94m0.2739\u001b[0m     +  5.5277\n",
      "      3        \u001b[36m0.1972\u001b[0m       0.8555            0.8553            0.8555        0.3879        5.5983\n",
      "      4        \u001b[36m0.1812\u001b[0m       0.7980            0.7980            0.7980        0.5946        5.5241\n",
      "      5        \u001b[36m0.1748\u001b[0m       0.8747            0.8743            0.8747        \u001b[94m0.2705\u001b[0m        5.5849\n",
      "      6        \u001b[36m0.1656\u001b[0m       \u001b[32m0.9004\u001b[0m            \u001b[35m0.8998\u001b[0m            \u001b[31m0.9004\u001b[0m        0.2856     +  5.4884\n",
      "      7        0.1671       0.8669            0.8667            0.8669        0.3700        5.4856\n",
      "      8        \u001b[36m0.1562\u001b[0m       0.8139            0.8138            0.8139        0.4910        5.5695\n",
      "      9        0.1579       \u001b[32m0.9294\u001b[0m            \u001b[35m0.9284\u001b[0m            \u001b[31m0.9294\u001b[0m        \u001b[94m0.1825\u001b[0m     +  5.4879\n",
      "     10        \u001b[36m0.1549\u001b[0m       \u001b[32m0.9384\u001b[0m            \u001b[35m0.9359\u001b[0m            \u001b[31m0.9384\u001b[0m        \u001b[94m0.1530\u001b[0m     +  5.5844\n",
      "     11        \u001b[36m0.1527\u001b[0m       0.9200            0.9188            0.9200        0.2142        5.5800\n",
      "     12        \u001b[36m0.1483\u001b[0m       0.7857            0.7851            0.7857        0.5702        5.5007\n",
      "     13        \u001b[36m0.1369\u001b[0m       \u001b[32m0.9400\u001b[0m            \u001b[35m0.9385\u001b[0m            \u001b[31m0.9400\u001b[0m        0.1632     +  5.5834\n",
      "     14        \u001b[36m0.1350\u001b[0m       0.9306            0.9292            0.9306        0.1862        5.5206\n",
      "     15        \u001b[36m0.1327\u001b[0m       0.9241            0.9232            0.9241        0.2143        5.5176\n",
      "     16        \u001b[36m0.1236\u001b[0m       0.8927            0.8920            0.8927        0.3078        5.4941\n",
      "     17        0.1238       0.8963            0.8956            0.8963        0.3151        5.5740\n",
      "     18        0.1269       0.9249            0.9236            0.9249        0.1861        5.5317\n",
      "     19        \u001b[36m0.1179\u001b[0m       0.9065            0.9059            0.9065        0.2483        5.5357\n",
      "     20        0.1212       0.9261            0.9251            0.9261        0.2205        5.5550\n",
      "     21        0.1277       0.9347            0.9335            0.9347        0.1772        5.5230\n",
      "     22        \u001b[36m0.1130\u001b[0m       0.8935            0.8930            0.8935        0.3007        5.5381\n",
      "     23        0.1191       0.9363            0.9350            0.9363        0.1802        5.5305\n",
      "     24        \u001b[36m0.1093\u001b[0m       0.9180            0.9171            0.9180        0.2447        5.5691\n",
      "     25        0.1186       \u001b[32m0.9404\u001b[0m            \u001b[35m0.9391\u001b[0m            \u001b[31m0.9404\u001b[0m        \u001b[94m0.1524\u001b[0m     +  5.5326\n",
      "     26        \u001b[36m0.1086\u001b[0m       0.9200            0.9191            0.9200        0.2601        5.5560\n",
      "     27        0.1116       \u001b[32m0.9408\u001b[0m            \u001b[35m0.9396\u001b[0m            \u001b[31m0.9408\u001b[0m        0.1551     +  5.5641\n",
      "     28        \u001b[36m0.1049\u001b[0m       0.9114            0.9106            0.9114        0.2493        5.5035\n",
      "     29        0.1080       0.9359            0.9348            0.9359        0.1731        5.5654\n",
      "     30        \u001b[36m0.1032\u001b[0m       0.9196            0.9153            0.9196        0.2202        5.5329\n",
      "     31        0.1049       0.9139            0.9131            0.9139        0.2447        5.5332\n",
      "     32        \u001b[36m0.1014\u001b[0m       0.9229            0.9218            0.9229        0.2152        5.5181\n",
      "     33        \u001b[36m0.1000\u001b[0m       0.9241            0.9229            0.9241        0.2303        5.5416\n",
      "     34        \u001b[36m0.0987\u001b[0m       0.9306            0.9296            0.9306        0.1996        5.5881\n",
      "     35        \u001b[36m0.0981\u001b[0m       0.9359            0.9347            0.9359        0.1841        5.4450\n",
      "     36        \u001b[36m0.0979\u001b[0m       0.9249            0.9239            0.9249        0.2094        5.5058\n",
      "     37        \u001b[36m0.0964\u001b[0m       0.9176            0.9166            0.9176        0.2370        5.5302\n",
      "     38        0.0975       0.9318            0.9305            0.9318        0.2142        5.5681\n",
      "     39        \u001b[36m0.0867\u001b[0m       0.9314            0.9304            0.9314        0.1865        5.5737\n",
      "     40        0.0910       0.9400            0.9385            0.9400        0.1639        5.5663\n",
      "     41        0.1007       0.9404            0.9389            0.9404        0.1627        5.5251\n",
      "     42        0.1009       0.9327            0.9317            0.9327        0.1853        5.6558\n",
      "     43        \u001b[36m0.0807\u001b[0m       0.9347            0.9336            0.9347        0.1904        5.5320\n",
      "     44        \u001b[36m0.0789\u001b[0m       \u001b[32m0.9441\u001b[0m            \u001b[35m0.9429\u001b[0m            \u001b[31m0.9441\u001b[0m        0.1577     +  5.5673\n",
      "     45        0.0824       0.9273            0.9263            0.9273        0.2172        5.5255\n",
      "     46        \u001b[36m0.0780\u001b[0m       0.9380            0.9358            0.9380        0.2029        5.6145\n",
      "     47        0.0817       0.9159            0.9148            0.9159        0.2451        5.5070\n",
      "     48        \u001b[36m0.0756\u001b[0m       0.9416            0.9400            0.9416        0.1771        5.4964\n",
      "     49        0.0787       0.9376            0.9366            0.9376        0.1967        5.4977\n",
      "     50        0.0761       0.9424            0.9408            0.9424        0.1612        5.4787\n",
      "     51        \u001b[36m0.0731\u001b[0m       \u001b[32m0.9461\u001b[0m            \u001b[35m0.9450\u001b[0m            \u001b[31m0.9461\u001b[0m        0.1644     +  5.5293\n",
      "     52        \u001b[36m0.0682\u001b[0m       \u001b[32m0.9465\u001b[0m            \u001b[35m0.9452\u001b[0m            \u001b[31m0.9465\u001b[0m        0.1643     +  5.5370\n",
      "     53        0.0783       0.9392            0.9378            0.9392        0.1810        5.4899\n",
      "     54        0.0793       0.9396            0.9385            0.9396        0.1790        5.4983\n",
      "     55        0.0726       0.9380            0.9368            0.9380        0.1820        5.5345\n",
      "     56        \u001b[36m0.0644\u001b[0m       \u001b[32m0.9469\u001b[0m            \u001b[35m0.9455\u001b[0m            \u001b[31m0.9469\u001b[0m        0.1610     +  5.5360\n",
      "     57        \u001b[36m0.0631\u001b[0m       0.9306            0.9294            0.9306        0.1903        5.5157\n",
      "     58        0.0693       0.9424            0.9407            0.9424        0.1561        5.5479\n",
      "     59        0.0641       0.9302            0.9293            0.9302        0.2145        5.5037\n",
      "     60        \u001b[36m0.0591\u001b[0m       \u001b[32m0.9490\u001b[0m            \u001b[35m0.9477\u001b[0m            \u001b[31m0.9490\u001b[0m        0.1609     +  5.4609\n",
      "     61        \u001b[36m0.0582\u001b[0m       \u001b[32m0.9506\u001b[0m            \u001b[35m0.9492\u001b[0m            \u001b[31m0.9506\u001b[0m        \u001b[94m0.1348\u001b[0m     +  5.4997\n",
      "     62        \u001b[36m0.0524\u001b[0m       0.9388            0.9372            0.9388        0.1797        5.5709\n",
      "     63        0.0565       0.9347            0.9333            0.9347        0.2234        5.4910\n",
      "     64        0.0562       0.9433            0.9417            0.9433        0.1605        5.5625\n",
      "     65        \u001b[36m0.0498\u001b[0m       0.9408            0.9393            0.9408        0.2430        5.5558\n",
      "     66        0.0588       0.9318            0.9306            0.9318        0.2189        5.5189\n",
      "     67        0.0521       0.9437            0.9426            0.9437        0.1775        5.6177\n",
      "     68        0.0564       0.9416            0.9402            0.9416        0.1804        5.5273\n",
      "     69        \u001b[36m0.0491\u001b[0m       0.9445            0.9431            0.9445        0.1646        5.4744\n",
      "     70        \u001b[36m0.0469\u001b[0m       0.9347            0.9334            0.9347        0.2163        5.5267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     71        \u001b[36m0.0445\u001b[0m       0.9469            0.9455            0.9469        0.1846        5.4878\n",
      "     72        0.0494       0.9449            0.9434            0.9449        0.1891        5.5861\n",
      "     73        0.0547       0.9388            0.9376            0.9388        0.1863        5.5399\n",
      "     74        0.0478       0.9404            0.9390            0.9404        0.2201        5.5704\n",
      "     75        \u001b[36m0.0424\u001b[0m       0.9388            0.9373            0.9388        0.2109        5.5349\n",
      "     76        0.0465       0.9457            0.9444            0.9457        0.1602        5.4881\n",
      "     77        0.0440       0.9351            0.9337            0.9351        0.2069        5.5624\n",
      "     78        0.0426       0.9449            0.9435            0.9449        0.1877        5.5172\n",
      "     79        \u001b[36m0.0374\u001b[0m       0.9437            0.9423            0.9437        0.1799        5.4958\n",
      "     80        0.0390       0.9461            0.9444            0.9461        0.2367        5.5029\n",
      "     81        0.0509       0.9359            0.9348            0.9359        0.1973        5.5561\n",
      "     82        0.0425       0.9420            0.9405            0.9420        0.1823        5.5299\n",
      "     83        0.0380       0.9400            0.9386            0.9400        0.2035        5.4736\n",
      "     84        0.0386       0.9367            0.9356            0.9367        0.2448        5.5227\n",
      "     85        0.0427       0.9420            0.9409            0.9420        0.1927        5.5161\n",
      "     86        \u001b[36m0.0294\u001b[0m       0.9478            0.9466            0.9478        0.1816        5.4772\n",
      "     87        \u001b[36m0.0248\u001b[0m       0.9424            0.9413            0.9424        0.2153        5.5232\n",
      "     88        \u001b[36m0.0169\u001b[0m       0.9502            0.9488            0.9502        0.1957        5.5502\n",
      "     89        \u001b[36m0.0162\u001b[0m       0.9429            0.9415            0.9429        0.2250        5.5936\n",
      "     90        0.0189       0.9486            0.9472            0.9486        0.2088        5.5335\n",
      "     91        \u001b[36m0.0143\u001b[0m       0.9441            0.9429            0.9441        0.2567        5.6204\n",
      "     92        0.0184       0.9420            0.9409            0.9420        0.2492        5.5126\n",
      "     93        0.0153       0.9473            0.9458            0.9473        0.2147        5.5968\n",
      "     94        0.0164       0.9502            0.9490            0.9502        0.2331        5.5044\n",
      "     95        0.0184       0.9469            0.9458            0.9469        0.2165        5.5273\n",
      "     96        \u001b[36m0.0120\u001b[0m       \u001b[32m0.9514\u001b[0m            \u001b[35m0.9502\u001b[0m            \u001b[31m0.9514\u001b[0m        0.2381     +  5.5447\n",
      "     97        0.0202       0.9457            0.9444            0.9457        0.2385        5.5597\n",
      "     98        0.0172       0.9465            0.9452            0.9465        0.2189        5.5973\n",
      "     99        0.0136       0.9498            0.9485            0.9498        0.2268        5.5687\n",
      "    100        0.0123       0.9457            0.9445            0.9457        0.2606        5.5268\n",
      "    101        0.0139       0.9461            0.9446            0.9461        0.2534        5.5294\n",
      "    102        0.0161       0.9412            0.9401            0.9412        0.2607        5.5270\n",
      "    103        \u001b[36m0.0100\u001b[0m       0.9469            0.9458            0.9469        0.2308        5.5322\n",
      "    104        \u001b[36m0.0067\u001b[0m       0.9494            0.9482            0.9494        0.2466        5.5443\n",
      "    105        0.0083       0.9473            0.9461            0.9473        0.2528        5.5129\n",
      "    106        \u001b[36m0.0064\u001b[0m       0.9494            0.9481            0.9494        0.2451        5.4604\n",
      "    107        \u001b[36m0.0058\u001b[0m       0.9494            0.9481            0.9494        0.2534        5.6688\n",
      "    108        \u001b[36m0.0050\u001b[0m       0.9473            0.9463            0.9473        0.2951        5.5712\n",
      "    109        0.0060       0.9441            0.9430            0.9441        0.3142        5.5178\n",
      "    110        0.0061       0.9510            0.9498            0.9510        0.2698        5.5048\n",
      "    111        0.0051       0.9494            0.9479            0.9494        0.2747        5.4438\n",
      "    112        0.0070       0.9482            0.9470            0.9482        0.2780        5.4911\n",
      "    113        \u001b[36m0.0044\u001b[0m       0.9457            0.9444            0.9457        0.2734        5.4752\n",
      "    114        0.0052       0.9441            0.9429            0.9441        0.3009        5.5735\n",
      "    115        0.0060       0.9478            0.9464            0.9478        0.2885        5.5518\n",
      "    116        0.0062       0.9437            0.9425            0.9437        0.2851        5.5921\n",
      "    117        0.0045       0.9498            0.9486            0.9498        0.2852        5.5106\n",
      "    118        0.0060       0.9469            0.9457            0.9469        0.2791        5.5014\n",
      "    119        0.0053       0.9408            0.9396            0.9408        0.3174        5.5576\n",
      "    120        \u001b[36m0.0033\u001b[0m       0.9453            0.9441            0.9453        0.3176        5.6019\n",
      "    121        0.0035       0.9469            0.9456            0.9469        0.2964        5.4560\n",
      "    122        \u001b[36m0.0021\u001b[0m       0.9449            0.9436            0.9449        0.3123        5.4870\n",
      "    123        0.0027       0.9457            0.9444            0.9457        0.3293        5.4895\n",
      "    124        0.0034       0.9420            0.9409            0.9420        0.3496        5.5422\n",
      "    125        \u001b[36m0.0016\u001b[0m       0.9482            0.9469            0.9482        0.3213        5.4851\n",
      "    126        0.0030       0.9461            0.9448            0.9461        0.3117        5.5357\n",
      "    127        0.0038       0.9461            0.9449            0.9461        0.3282        5.5501\n",
      "    128        0.0019       0.9465            0.9452            0.9465        0.3350        5.4615\n",
      "    129        0.0027       0.9457            0.9445            0.9457        0.3338        5.5335\n",
      "    130        0.0043       0.9465            0.9453            0.9465        0.3228        5.5169\n",
      "    131        0.0036       0.9486            0.9473            0.9486        0.3316        5.5519\n",
      "    132        0.0017       0.9482            0.9469            0.9482        0.3263        5.6199\n",
      "    133        0.0026       0.9465            0.9453            0.9465        0.3355        5.5074\n",
      "    134        \u001b[36m0.0009\u001b[0m       0.9461            0.9449            0.9461        0.3358        5.5761\n",
      "    135        0.0013       0.9465            0.9453            0.9465        0.3410        5.5472\n",
      "    136        0.0023       0.9482            0.9469            0.9482        0.3372        5.4801\n",
      "    137        0.0030       0.9478            0.9466            0.9478        0.3457        5.5587\n",
      "    138        0.0016       0.9486            0.9473            0.9486        0.3346        5.5387\n",
      "    139        0.0012       0.9465            0.9454            0.9465        0.3672        5.5318\n",
      "    140        0.0016       0.9469            0.9457            0.9469        0.3539        5.4873\n",
      "    141        0.0021       0.9469            0.9457            0.9469        0.3492        5.5316\n",
      "    142        \u001b[36m0.0006\u001b[0m       0.9486            0.9474            0.9486        0.3562        5.5221\n",
      "    143        0.0007       0.9478            0.9465            0.9478        0.3569        5.6141\n",
      "    144        0.0012       0.9482            0.9469            0.9482        0.3529        5.5871\n",
      "    145        \u001b[36m0.0004\u001b[0m       0.9473            0.9461            0.9473        0.3592        5.5190\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0172]), 'p05': tensor([0.0272]), 'p25': tensor([0.0482]), 'p50': tensor([0.0761]), 'p75': tensor([0.1634]), 'p95': tensor([0.7914]), 'p99': tensor([2.1942]), 'max': tensor([250.7378]), 'mean': tensor([0.2242]), 'std': tensor([1.9192])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2893\u001b[0m       \u001b[32m0.9086\u001b[0m            \u001b[35m0.9062\u001b[0m            \u001b[31m0.9086\u001b[0m        \u001b[94m0.2285\u001b[0m     +  5.5031\n",
      "      2        \u001b[36m0.2048\u001b[0m       0.8494            0.8488            0.8494        0.3624        5.4910\n",
      "      3        \u001b[36m0.1953\u001b[0m       0.8878            0.8870            0.8878        0.2868        5.5750\n",
      "      4        \u001b[36m0.1716\u001b[0m       0.8559            0.8558            0.8559        0.3825        5.4960\n",
      "      5        \u001b[36m0.1664\u001b[0m       0.9049            0.9038            0.9049        0.2994        5.4447\n",
      "      6        0.1665       0.8637            0.8632            0.8637        0.3311        5.5261\n",
      "      7        \u001b[36m0.1649\u001b[0m       0.8914            0.8900            0.8914        0.3240        5.5240\n",
      "      8        \u001b[36m0.1506\u001b[0m       \u001b[32m0.9102\u001b[0m            \u001b[35m0.9086\u001b[0m            \u001b[31m0.9102\u001b[0m        0.2508     +  5.5372\n",
      "      9        \u001b[36m0.1449\u001b[0m       \u001b[32m0.9363\u001b[0m            \u001b[35m0.9349\u001b[0m            \u001b[31m0.9363\u001b[0m        \u001b[94m0.1718\u001b[0m     +  5.5424\n",
      "     10        0.1525       0.9253            0.9242            0.9253        0.1962        5.6045\n",
      "     11        0.1457       0.9143            0.9130            0.9143        0.2182        5.6827\n",
      "     12        \u001b[36m0.1363\u001b[0m       \u001b[32m0.9384\u001b[0m            \u001b[35m0.9373\u001b[0m            \u001b[31m0.9384\u001b[0m        \u001b[94m0.1642\u001b[0m     +  5.5158\n",
      "     13        0.1391       0.8873            0.8868            0.8873        0.2811        5.5218\n",
      "     14        \u001b[36m0.1331\u001b[0m       0.9371            0.9359            0.9371        0.1654        5.4852\n",
      "     15        0.1336       0.9041            0.9032            0.9041        0.2411        5.5464\n",
      "     16        \u001b[36m0.1323\u001b[0m       0.8906            0.8895            0.8906        0.3264        5.5904\n",
      "     17        \u001b[36m0.1230\u001b[0m       0.9318            0.9297            0.9318        0.1680        5.4990\n",
      "     18        0.1287       0.9347            0.9333            0.9347        \u001b[94m0.1590\u001b[0m        5.5694\n",
      "     19        \u001b[36m0.1224\u001b[0m       0.9310            0.9294            0.9310        0.2035        5.5835\n",
      "     20        \u001b[36m0.1159\u001b[0m       0.9302            0.9285            0.9302        0.1893        5.5100\n",
      "     21        \u001b[36m0.1131\u001b[0m       \u001b[32m0.9437\u001b[0m            \u001b[35m0.9420\u001b[0m            \u001b[31m0.9437\u001b[0m        \u001b[94m0.1527\u001b[0m     +  5.5478\n",
      "     22        0.1199       0.9335            0.9316            0.9335        0.2007        5.5250\n",
      "     23        0.1159       0.9420            0.9403            0.9420        \u001b[94m0.1461\u001b[0m        5.4959\n",
      "     24        \u001b[36m0.1063\u001b[0m       0.9314            0.9297            0.9314        0.1821        5.4657\n",
      "     25        \u001b[36m0.1058\u001b[0m       0.9306            0.9272            0.9306        0.2009        5.4752\n",
      "     26        0.1066       \u001b[32m0.9457\u001b[0m            \u001b[35m0.9442\u001b[0m            \u001b[31m0.9457\u001b[0m        \u001b[94m0.1353\u001b[0m     +  5.4877\n",
      "     27        0.1059       0.9298            0.9265            0.9298        0.1910        5.5613\n",
      "     28        \u001b[36m0.0996\u001b[0m       \u001b[32m0.9465\u001b[0m            \u001b[35m0.9448\u001b[0m            \u001b[31m0.9465\u001b[0m        0.1577     +  5.5928\n",
      "     29        0.0998       0.9339            0.9316            0.9339        0.1836        5.5313\n",
      "     30        \u001b[36m0.0974\u001b[0m       0.9367            0.9355            0.9367        0.1645        5.4746\n",
      "     31        \u001b[36m0.0946\u001b[0m       0.9118            0.9111            0.9118        0.2357        5.6307\n",
      "     32        0.1015       0.9306            0.9294            0.9306        0.1966        5.6021\n",
      "     33        \u001b[36m0.0936\u001b[0m       0.9412            0.9396            0.9412        0.1844        5.5337\n",
      "     34        \u001b[36m0.0894\u001b[0m       0.9339            0.9324            0.9339        0.1888        5.6225\n",
      "     35        0.0982       0.9408            0.9392            0.9408        0.1994        5.5219\n",
      "     36        0.0896       0.9339            0.9322            0.9339        0.1907        5.5714\n",
      "     37        0.0996       0.9220            0.9206            0.9220        0.2344        5.5185\n",
      "     38        0.0974       0.9408            0.9396            0.9408        0.1481        5.5227\n",
      "     39        \u001b[36m0.0827\u001b[0m       0.9347            0.9334            0.9347        0.1583        5.4992\n",
      "     40        \u001b[36m0.0794\u001b[0m       0.9318            0.9299            0.9318        0.2264        5.4805\n",
      "     41        0.0833       0.9302            0.9268            0.9302        0.2192        5.5058\n",
      "     42        0.0925       0.9224            0.9215            0.9224        0.2345        5.6216\n",
      "     43        0.0916       0.9327            0.9317            0.9327        0.1962        5.5232\n",
      "     44        0.0798       0.9420            0.9405            0.9420        0.1743        5.5675\n",
      "     45        0.0818       0.9416            0.9403            0.9416        0.1620        5.5844\n",
      "     46        \u001b[36m0.0769\u001b[0m       0.9400            0.9383            0.9400        0.1757        5.4815\n",
      "     47        0.0805       0.9376            0.9360            0.9376        0.2137        5.5679\n",
      "     48        0.0817       0.9408            0.9394            0.9408        0.1689        5.5195\n",
      "     49        \u001b[36m0.0666\u001b[0m       0.9363            0.9342            0.9363        0.2028        5.4329\n",
      "     50        0.0785       0.9306            0.9281            0.9306        0.1946        5.6003\n",
      "     51        0.0701       0.9396            0.9383            0.9396        0.1876        5.5201\n",
      "     52        0.0702       \u001b[32m0.9486\u001b[0m            \u001b[35m0.9469\u001b[0m            \u001b[31m0.9486\u001b[0m        0.1379     +  5.5391\n",
      "     53        \u001b[36m0.0656\u001b[0m       0.9412            0.9400            0.9412        0.1586        5.5376\n",
      "     54        0.0696       0.9469            0.9457            0.9469        0.1587        5.5790\n",
      "     55        \u001b[36m0.0649\u001b[0m       0.9355            0.9342            0.9355        0.1932        5.5711\n",
      "     56        \u001b[36m0.0613\u001b[0m       0.9433            0.9415            0.9433        0.1736        5.6262\n",
      "     57        0.0648       0.9380            0.9355            0.9380        0.2158        5.4996\n",
      "     58        0.0648       0.9433            0.9421            0.9433        0.1674        5.5680\n",
      "     59        \u001b[36m0.0590\u001b[0m       0.9371            0.9353            0.9371        0.2069        5.5205\n",
      "     60        \u001b[36m0.0590\u001b[0m       0.9294            0.9282            0.9294        0.2084        5.5779\n",
      "     61        \u001b[36m0.0546\u001b[0m       0.9416            0.9401            0.9416        0.2074        5.5589\n",
      "     62        \u001b[36m0.0539\u001b[0m       0.9380            0.9366            0.9380        0.2079        5.5468\n",
      "     63        0.0911       0.9302            0.9290            0.9302        0.2135        5.5953\n",
      "     64        0.0637       0.9384            0.9365            0.9384        0.2186        5.5475\n",
      "     65        0.0646       0.9322            0.9312            0.9322        0.1864        5.5538\n",
      "     66        0.0576       0.9420            0.9406            0.9420        0.1658        5.6299\n",
      "     67        \u001b[36m0.0536\u001b[0m       0.9396            0.9379            0.9396        0.2028        5.6216\n",
      "     68        0.0543       0.9404            0.9393            0.9404        0.2016        5.4903\n",
      "     69        \u001b[36m0.0521\u001b[0m       0.9433            0.9418            0.9433        0.1922        5.5219\n",
      "     70        \u001b[36m0.0497\u001b[0m       0.9388            0.9372            0.9388        0.2118        5.5165\n",
      "     71        0.0548       0.9392            0.9377            0.9392        0.1906        5.5655\n",
      "     72        \u001b[36m0.0478\u001b[0m       0.9441            0.9428            0.9441        0.1946        5.4930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        0.0485       0.9408            0.9390            0.9408        0.2127        5.5074\n",
      "     74        \u001b[36m0.0432\u001b[0m       0.9359            0.9347            0.9359        0.2439        5.4977\n",
      "     75        \u001b[36m0.0422\u001b[0m       0.9449            0.9433            0.9449        0.1780        5.5361\n",
      "     76        0.0447       0.9380            0.9368            0.9380        0.2198        5.6080\n",
      "     77        \u001b[36m0.0402\u001b[0m       0.9347            0.9333            0.9347        0.2166        5.5454\n",
      "     78        0.0441       0.9339            0.9322            0.9339        0.2369        5.4938\n",
      "     79        \u001b[36m0.0382\u001b[0m       0.9416            0.9396            0.9416        0.2505        5.5142\n",
      "     80        0.0397       0.9441            0.9428            0.9441        0.2051        5.4989\n",
      "     81        0.0397       0.9457            0.9443            0.9457        0.2066        5.4892\n",
      "     82        0.0399       0.9433            0.9420            0.9433        0.1975        5.5522\n",
      "     83        0.0412       0.9449            0.9437            0.9449        0.2017        5.6237\n",
      "     84        \u001b[36m0.0350\u001b[0m       0.9465            0.9451            0.9465        0.2238        5.5728\n",
      "     85        0.0368       0.9351            0.9340            0.9351        0.2105        5.5707\n",
      "     86        \u001b[36m0.0305\u001b[0m       0.9380            0.9367            0.9380        0.2862        5.5757\n",
      "     87        0.0463       0.9343            0.9329            0.9343        0.2202        5.6192\n",
      "     88        0.0349       0.9347            0.9334            0.9347        0.2741        5.5530\n",
      "     89        0.0413       0.9416            0.9403            0.9416        0.1849        5.5385\n",
      "     90        0.0362       0.9396            0.9384            0.9396        0.2084        5.5392\n",
      "     91        0.0320       0.9424            0.9409            0.9424        0.2217        5.5671\n",
      "     92        0.0314       0.9441            0.9426            0.9441        0.2265        5.5559\n",
      "     93        \u001b[36m0.0210\u001b[0m       0.9445            0.9430            0.9445        0.2532        5.5006\n",
      "     94        \u001b[36m0.0159\u001b[0m       0.9445            0.9431            0.9445        0.2587        5.4947\n",
      "     95        \u001b[36m0.0130\u001b[0m       0.9445            0.9430            0.9445        0.2843        5.5072\n",
      "     96        0.0189       0.9424            0.9409            0.9424        0.2615        5.5426\n",
      "     97        \u001b[36m0.0128\u001b[0m       0.9408            0.9395            0.9408        0.2912        5.5156\n",
      "     98        0.0130       \u001b[32m0.9490\u001b[0m            \u001b[35m0.9476\u001b[0m            \u001b[31m0.9490\u001b[0m        0.2767     +  5.5332\n",
      "     99        0.0128       0.9437            0.9423            0.9437        0.2775        5.5229\n",
      "    100        0.0169       0.9400            0.9388            0.9400        0.2859        5.4814\n",
      "    101        \u001b[36m0.0117\u001b[0m       0.9404            0.9389            0.9404        0.3167        5.5838\n",
      "    102        0.0154       0.9453            0.9438            0.9453        0.2589        5.6147\n",
      "    103        0.0138       0.9429            0.9415            0.9429        0.2772        5.5466\n",
      "    104        0.0141       0.9457            0.9443            0.9457        0.2457        5.5150\n",
      "    105        \u001b[36m0.0115\u001b[0m       0.9445            0.9430            0.9445        0.2698        5.5078\n",
      "    106        0.0131       0.9437            0.9420            0.9437        0.2312        5.5225\n",
      "    107        \u001b[36m0.0112\u001b[0m       0.9461            0.9449            0.9461        0.2596        5.5297\n",
      "    108        \u001b[36m0.0111\u001b[0m       0.9433            0.9418            0.9433        0.2746        5.5457\n",
      "    109        0.0120       0.9404            0.9390            0.9404        0.3140        5.5652\n",
      "    110        0.0119       0.9412            0.9399            0.9412        0.3057        5.4849\n",
      "    111        0.0117       0.9429            0.9415            0.9429        0.2940        5.4643\n",
      "    112        \u001b[36m0.0087\u001b[0m       0.9453            0.9438            0.9453        0.3244        5.5031\n",
      "    113        0.0106       0.9408            0.9395            0.9408        0.3347        5.5366\n",
      "    114        \u001b[36m0.0080\u001b[0m       0.9388            0.9371            0.9388        0.3167        5.5523\n",
      "    115        0.0092       0.9457            0.9444            0.9457        0.3023        5.6320\n",
      "    116        0.0108       0.9469            0.9457            0.9469        0.2844        5.5502\n",
      "    117        0.0120       0.9420            0.9404            0.9420        0.2570        5.5933\n",
      "    118        \u001b[36m0.0076\u001b[0m       0.9453            0.9438            0.9453        0.2901        5.5270\n",
      "    119        0.0116       0.9400            0.9383            0.9400        0.3282        5.4920\n",
      "    120        0.0129       0.9449            0.9437            0.9449        0.2834        5.5447\n",
      "    121        0.0108       0.9404            0.9388            0.9404        0.3185        5.5062\n",
      "    122        0.0109       0.9461            0.9448            0.9461        0.2811        5.4735\n",
      "    123        0.0079       0.9388            0.9373            0.9388        0.3743        5.5344\n",
      "    124        0.0172       0.9449            0.9432            0.9449        0.2755        5.4649\n",
      "    125        0.0090       0.9437            0.9422            0.9437        0.2802        5.5276\n",
      "    126        \u001b[36m0.0043\u001b[0m       0.9396            0.9384            0.9396        0.3077        5.5383\n",
      "    127        0.0046       0.9420            0.9406            0.9420        0.2887        5.5724\n",
      "    128        0.0047       0.9424            0.9411            0.9424        0.3077        5.5739\n",
      "    129        \u001b[36m0.0026\u001b[0m       0.9412            0.9395            0.9412        0.3549        5.5082\n",
      "    130        0.0028       0.9424            0.9410            0.9424        0.3465        5.5066\n",
      "    131        0.0032       0.9457            0.9444            0.9457        0.3628        5.5336\n",
      "    132        0.0060       0.9453            0.9437            0.9453        0.3335        5.5747\n",
      "    133        0.0061       0.9461            0.9446            0.9461        0.3286        5.5181\n",
      "    134        0.0034       0.9449            0.9435            0.9449        0.3543        5.6412\n",
      "    135        0.0033       0.9412            0.9398            0.9412        0.3756        5.5177\n",
      "    136        \u001b[36m0.0020\u001b[0m       0.9437            0.9424            0.9437        0.3712        5.4735\n",
      "    137        0.0030       0.9449            0.9435            0.9449        0.3639        5.4910\n",
      "    138        0.0026       0.9453            0.9439            0.9453        0.3701        5.4782\n",
      "    139        \u001b[36m0.0019\u001b[0m       0.9457            0.9443            0.9457        0.3859        5.4888\n",
      "    140        \u001b[36m0.0012\u001b[0m       0.9449            0.9435            0.9449        0.3802        5.5017\n",
      "    141        0.0017       0.9429            0.9414            0.9429        0.4042        5.5652\n",
      "    142        0.0015       0.9449            0.9435            0.9449        0.4078        5.5019\n",
      "    143        \u001b[36m0.0012\u001b[0m       0.9453            0.9439            0.9453        0.4030        5.5409\n",
      "    144        \u001b[36m0.0004\u001b[0m       0.9441            0.9427            0.9441        0.4183        5.6171\n",
      "    145        0.0013       0.9437            0.9423            0.9437        0.4238        5.5828\n",
      "    146        0.0013       0.9437            0.9421            0.9437        0.4363        5.5862\n",
      "    147        0.0017       0.9433            0.9419            0.9433        0.4384        5.6078\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0170]), 'p05': tensor([0.0272]), 'p25': tensor([0.0484]), 'p50': tensor([0.0764]), 'p75': tensor([0.1635]), 'p95': tensor([0.7942]), 'p99': tensor([2.1700]), 'max': tensor([250.7382]), 'mean': tensor([0.2241]), 'std': tensor([1.9374])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2915\u001b[0m       \u001b[32m0.9127\u001b[0m            \u001b[35m0.9106\u001b[0m            \u001b[31m0.9127\u001b[0m        \u001b[94m0.2258\u001b[0m     +  5.5411\n",
      "      2        \u001b[36m0.2041\u001b[0m       0.8735            0.8728            0.8735        0.3271        5.5092\n",
      "      3        \u001b[36m0.1868\u001b[0m       0.8788            0.8781            0.8788        0.2834        5.5003\n",
      "      4        \u001b[36m0.1778\u001b[0m       \u001b[32m0.9143\u001b[0m            \u001b[35m0.9119\u001b[0m            \u001b[31m0.9143\u001b[0m        \u001b[94m0.2076\u001b[0m     +  5.5460\n",
      "      5        0.1876       0.9135            0.9089            0.9135        \u001b[94m0.1908\u001b[0m        5.5861\n",
      "      6        \u001b[36m0.1660\u001b[0m       \u001b[32m0.9363\u001b[0m            \u001b[35m0.9347\u001b[0m            \u001b[31m0.9363\u001b[0m        \u001b[94m0.1661\u001b[0m     +  5.5382\n",
      "      7        \u001b[36m0.1495\u001b[0m       0.8947            0.8938            0.8947        0.2690        5.5326\n",
      "      8        0.1542       0.9306            0.9281            0.9306        0.1674        5.5548\n",
      "      9        \u001b[36m0.1484\u001b[0m       0.9171            0.9154            0.9171        0.2015        5.4744\n",
      "     10        \u001b[36m0.1437\u001b[0m       0.8702            0.8700            0.8702        0.3291        5.5603\n",
      "     11        0.1441       0.9212            0.9198            0.9212        0.1720        5.5424\n",
      "     12        \u001b[36m0.1347\u001b[0m       0.9102            0.9089            0.9102        0.2514        5.5405\n",
      "     13        0.1394       0.8980            0.8973            0.8980        0.2806        5.6066\n",
      "     14        0.1368       \u001b[32m0.9400\u001b[0m            \u001b[35m0.9382\u001b[0m            \u001b[31m0.9400\u001b[0m        \u001b[94m0.1453\u001b[0m     +  5.5007\n",
      "     15        \u001b[36m0.1265\u001b[0m       0.9167            0.9159            0.9167        0.2000        5.5132\n",
      "     16        \u001b[36m0.1243\u001b[0m       \u001b[32m0.9416\u001b[0m            \u001b[35m0.9396\u001b[0m            \u001b[31m0.9416\u001b[0m        \u001b[94m0.1436\u001b[0m     +  5.5596\n",
      "     17        0.1253       0.9220            0.9211            0.9220        0.2149        5.5069\n",
      "     18        0.1249       0.9412            \u001b[35m0.9400\u001b[0m            0.9412        0.1533     +  5.5849\n",
      "     19        \u001b[36m0.1170\u001b[0m       0.9155            0.9147            0.9155        0.2335        5.5521\n",
      "     20        \u001b[36m0.1164\u001b[0m       0.9351            0.9341            0.9351        0.1814        5.6053\n",
      "     21        \u001b[36m0.1109\u001b[0m       0.9208            0.9187            0.9208        0.2236        5.5855\n",
      "     22        0.1194       0.9082            0.9067            0.9082        0.2205        5.5208\n",
      "     23        \u001b[36m0.1090\u001b[0m       0.9347            0.9336            0.9347        0.1819        5.5105\n",
      "     24        \u001b[36m0.1038\u001b[0m       0.9388            0.9374            0.9388        0.1642        5.5027\n",
      "     25        0.1187       0.9265            0.9254            0.9265        0.2121        5.5023\n",
      "     26        0.1096       0.9171            0.9161            0.9171        0.2146        5.5452\n",
      "     27        \u001b[36m0.0998\u001b[0m       \u001b[32m0.9420\u001b[0m            \u001b[35m0.9406\u001b[0m            \u001b[31m0.9420\u001b[0m        0.1548     +  5.5346\n",
      "     28        \u001b[36m0.0991\u001b[0m       0.9122            0.9112            0.9122        0.2499        5.5336\n",
      "     29        0.1028       \u001b[32m0.9433\u001b[0m            \u001b[35m0.9416\u001b[0m            \u001b[31m0.9433\u001b[0m        0.1545     +  5.4902\n",
      "     30        0.1019       0.9282            0.9270            0.9282        0.1770        5.5404\n",
      "     31        \u001b[36m0.0911\u001b[0m       0.9351            0.9340            0.9351        0.1656        5.5241\n",
      "     32        0.0978       0.9306            0.9294            0.9306        0.1812        5.5504\n",
      "     33        \u001b[36m0.0898\u001b[0m       0.9384            0.9366            0.9384        0.1598        5.4871\n",
      "     34        0.0930       0.8510            0.8508            0.8510        4.7697        5.5235\n",
      "     35        0.1186       0.9376            0.9355            0.9376        0.1534        5.5238\n",
      "     36        \u001b[36m0.0895\u001b[0m       0.9249            0.9237            0.9249        0.2033        5.5074\n",
      "     37        \u001b[36m0.0855\u001b[0m       0.9388            0.9373            0.9388        0.1745        5.6055\n",
      "     38        0.0860       0.9429            0.9410            0.9429        0.1648        5.5383\n",
      "     39        0.0859       0.9335            0.9318            0.9335        0.1698        5.5790\n",
      "     40        \u001b[36m0.0805\u001b[0m       0.9335            0.9324            0.9335        0.1986        5.4941\n",
      "     41        \u001b[36m0.0753\u001b[0m       0.9224            0.9215            0.9224        0.2155        5.4968\n",
      "     42        0.0856       0.9424            0.9406            0.9424        0.1570        5.4963\n",
      "     43        0.0782       0.9371            0.9359            0.9371        0.1725        5.5391\n",
      "     44        \u001b[36m0.0683\u001b[0m       0.9433            \u001b[35m0.9419\u001b[0m            0.9433        0.1807     +  5.4896\n",
      "     45        0.0717       \u001b[32m0.9437\u001b[0m            \u001b[35m0.9423\u001b[0m            \u001b[31m0.9437\u001b[0m        0.1695     +  5.5569\n",
      "     46        0.0786       0.9302            0.9290            0.9302        0.1817        5.4868\n",
      "     47        0.0717       0.9273            0.9260            0.9273        0.2185        5.5846\n",
      "     48        0.0706       0.9261            0.9251            0.9261        0.2215        5.5545\n",
      "     49        0.0763       0.9384            0.9370            0.9384        0.1701        5.4314\n",
      "     50        \u001b[36m0.0656\u001b[0m       0.9412            0.9398            0.9412        0.1795        5.5302\n",
      "     51        0.0735       0.9400            0.9387            0.9400        0.1620        5.5136\n",
      "     52        \u001b[36m0.0656\u001b[0m       0.9396            0.9379            0.9396        0.1824        5.5689\n",
      "     53        \u001b[36m0.0605\u001b[0m       0.9400            0.9385            0.9400        0.1840        5.5234\n",
      "     54        0.0665       0.9318            0.9304            0.9318        0.2128        5.5171\n",
      "     55        0.0655       0.9314            0.9303            0.9314        0.2175        5.5718\n",
      "     56        \u001b[36m0.0570\u001b[0m       0.9278            0.9266            0.9278        0.2162        5.5133\n",
      "     57        0.0653       0.9286            0.9269            0.9286        0.1993        5.6040\n",
      "     58        \u001b[36m0.0532\u001b[0m       0.9400            0.9385            0.9400        0.1983        5.5069\n",
      "     59        0.0614       0.9278            0.9266            0.9278        0.2253        5.5402\n",
      "     60        0.0535       0.9331            0.9314            0.9331        0.2383        5.5479\n",
      "     61        0.0597       0.9294            0.9280            0.9294        0.1915        5.5220\n",
      "     62        \u001b[36m0.0494\u001b[0m       0.9290            0.9277            0.9290        0.2273        5.6128\n",
      "     63        0.0515       0.9343            0.9329            0.9343        0.2140        5.5993\n",
      "     64        0.0509       0.9322            0.9301            0.9322        0.2161        5.5190\n",
      "     65        \u001b[36m0.0491\u001b[0m       0.9412            0.9399            0.9412        0.2096        5.5174\n",
      "     66        0.0600       0.9335            0.9321            0.9335        0.1857        5.5820\n",
      "     67        \u001b[36m0.0464\u001b[0m       0.9376            0.9358            0.9376        0.2119        5.5858\n",
      "     68        \u001b[36m0.0457\u001b[0m       0.9392            0.9378            0.9392        0.2087        5.5215\n",
      "     69        0.0490       0.9388            0.9374            0.9388        0.2010        5.5907\n",
      "     70        \u001b[36m0.0456\u001b[0m       \u001b[32m0.9449\u001b[0m            \u001b[35m0.9433\u001b[0m            \u001b[31m0.9449\u001b[0m        0.2072     +  5.5528\n",
      "     71        \u001b[36m0.0425\u001b[0m       0.9327            0.9312            0.9327        0.2562        5.5481\n",
      "     72        0.0426       0.9343            0.9330            0.9343        0.2354        5.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        \u001b[36m0.0401\u001b[0m       0.9286            0.9272            0.9286        0.2322        5.5204\n",
      "     74        0.0461       0.9392            0.9378            0.9392        0.2204        5.4870\n",
      "     75        \u001b[36m0.0365\u001b[0m       0.9396            0.9379            0.9396        0.2108        5.6441\n",
      "     76        0.0468       0.9363            0.9350            0.9363        0.2052        5.5087\n",
      "     77        \u001b[36m0.0349\u001b[0m       0.9376            0.9355            0.9376        0.2519        5.5348\n",
      "     78        0.0408       0.9429            0.9414            0.9429        0.2057        5.5196\n",
      "     79        0.0414       0.9192            0.9180            0.9192        0.3076        5.4697\n",
      "     80        0.0394       0.9355            0.9343            0.9355        0.2275        5.5173\n",
      "     81        0.0403       0.9359            0.9348            0.9359        0.2035        5.5352\n",
      "     82        0.0356       0.9429            0.9417            0.9429        0.1882        5.5039\n",
      "     83        0.0390       0.9384            0.9372            0.9384        0.2213        5.6011\n",
      "     84        \u001b[36m0.0309\u001b[0m       0.9437            0.9420            0.9437        0.2178        5.5949\n",
      "     85        \u001b[36m0.0246\u001b[0m       0.9392            0.9373            0.9392        0.2410        5.5852\n",
      "     86        \u001b[36m0.0229\u001b[0m       0.9404            0.9387            0.9404        0.2274        5.5915\n",
      "     87        \u001b[36m0.0132\u001b[0m       0.9412            0.9395            0.9412        0.2751        5.5092\n",
      "     88        0.0211       0.9384            0.9371            0.9384        0.2535        5.5394\n",
      "     89        0.0155       0.9420            0.9406            0.9420        0.2596        5.5099\n",
      "     90        0.0150       0.9396            0.9382            0.9396        0.2714        5.5327\n",
      "     91        0.0139       0.9376            0.9361            0.9376        0.3233        5.5332\n",
      "     92        0.0163       0.9331            0.9317            0.9331        0.3177        5.5567\n",
      "     93        0.0142       0.9388            0.9371            0.9388        0.2857        5.4928\n",
      "     94        \u001b[36m0.0129\u001b[0m       0.9400            0.9383            0.9400        0.2800        5.5786\n",
      "     95        \u001b[36m0.0068\u001b[0m       0.9437            0.9424            0.9437        0.2963        5.5147\n",
      "     96        0.0077       0.9424            0.9410            0.9424        0.3089        5.5295\n",
      "     97        0.0087       0.9412            0.9399            0.9412        0.3208        5.5461\n",
      "     98        \u001b[36m0.0061\u001b[0m       0.9388            0.9373            0.9388        0.3476        5.5219\n",
      "     99        0.0080       0.9392            0.9377            0.9392        0.3428        5.5557\n",
      "    100        \u001b[36m0.0059\u001b[0m       0.9376            0.9361            0.9376        0.3502        5.5588\n",
      "    101        0.0076       0.9359            0.9346            0.9359        0.3627        5.6272\n",
      "    102        0.0079       0.9412            0.9396            0.9412        0.3358        5.4805\n",
      "    103        0.0062       0.9420            0.9407            0.9420        0.3722        5.5516\n",
      "    104        0.0080       0.9449            \u001b[35m0.9434\u001b[0m            0.9449        0.3261     +  5.5397\n",
      "    105        0.0060       0.9408            0.9393            0.9408        0.3419        5.5752\n",
      "    106        \u001b[36m0.0056\u001b[0m       0.9392            0.9378            0.9392        0.3731        5.5543\n",
      "    107        0.0066       0.9404            0.9389            0.9404        0.3582        5.6261\n",
      "    108        0.0079       0.9412            0.9397            0.9412        0.3524        5.5009\n",
      "    109        0.0073       0.9412            0.9398            0.9412        0.3295        5.5987\n",
      "    110        \u001b[36m0.0055\u001b[0m       0.9380            0.9364            0.9380        0.3374        5.5138\n",
      "    111        \u001b[36m0.0055\u001b[0m       0.9437            0.9421            0.9437        0.3337        5.4991\n",
      "    112        \u001b[36m0.0051\u001b[0m       0.9437            0.9422            0.9437        0.3561        5.5103\n",
      "    113        \u001b[36m0.0040\u001b[0m       \u001b[32m0.9469\u001b[0m            \u001b[35m0.9454\u001b[0m            \u001b[31m0.9469\u001b[0m        0.3696     +  5.5339\n",
      "    114        0.0048       0.9429            0.9415            0.9429        0.3906        5.5423\n",
      "    115        0.0064       0.9367            0.9352            0.9367        0.3729        5.5253\n",
      "    116        0.0044       0.9408            0.9392            0.9408        0.3587        5.5175\n",
      "    117        0.0075       0.9392            0.9377            0.9392        0.3540        5.4868\n",
      "    118        0.0053       0.9453            0.9439            0.9453        0.3214        5.5187\n",
      "    119        \u001b[36m0.0030\u001b[0m       0.9416            0.9402            0.9416        0.3581        5.5204\n",
      "    120        0.0045       0.9388            0.9375            0.9388        0.3932        5.5679\n",
      "    121        0.0048       0.9396            0.9383            0.9396        0.3601        5.5428\n",
      "    122        0.0050       0.9392            0.9375            0.9392        0.3379        5.4996\n",
      "    123        0.0039       0.9408            0.9394            0.9408        0.3884        5.5279\n",
      "    124        0.0054       0.9384            0.9368            0.9384        0.3598        5.5869\n",
      "    125        0.0044       0.9424            0.9410            0.9424        0.3855        5.5044\n",
      "    126        0.0042       0.9408            0.9393            0.9408        0.3345        5.5318\n",
      "    127        \u001b[36m0.0027\u001b[0m       0.9376            0.9361            0.9376        0.3550        5.5329\n",
      "    128        0.0033       0.9396            0.9383            0.9396        0.3733        5.5178\n",
      "    129        0.0035       0.9433            0.9418            0.9433        0.3569        5.6444\n",
      "    130        0.0050       0.9412            0.9399            0.9412        0.3599        5.6280\n",
      "    131        0.0038       0.9441            0.9426            0.9441        0.3566        5.5145\n",
      "    132        0.0034       0.9396            0.9380            0.9396        0.3630        5.6529\n",
      "    133        \u001b[36m0.0021\u001b[0m       0.9416            0.9401            0.9416        0.3760        5.5796\n",
      "    134        \u001b[36m0.0010\u001b[0m       0.9404            0.9389            0.9404        0.3966        5.4856\n",
      "    135        0.0020       0.9441            0.9426            0.9441        0.3963        5.5245\n",
      "    136        0.0011       0.9412            0.9397            0.9412        0.4134        5.5214\n",
      "    137        0.0049       0.9404            0.9389            0.9404        0.3743        5.5674\n",
      "    138        0.0029       0.9408            0.9394            0.9408        0.3589        5.4867\n",
      "    139        0.0034       0.9412            0.9397            0.9412        0.3728        5.5106\n",
      "    140        \u001b[36m0.0007\u001b[0m       0.9416            0.9401            0.9416        0.3766        5.5073\n",
      "    141        0.0031       0.9400            0.9385            0.9400        0.3855        5.5409\n",
      "    142        0.0022       0.9437            0.9421            0.9437        0.3765        5.5679\n",
      "    143        0.0031       0.9420            0.9405            0.9420        0.3718        5.6883\n",
      "    144        0.0031       0.9433            0.9417            0.9433        0.3738        5.5873\n",
      "    145        0.0024       0.9404            0.9389            0.9404        0.3776        5.5500\n",
      "    146        0.0016       0.9416            0.9400            0.9416        0.3886        5.5585\n",
      "    147        0.0015       0.9420            0.9405            0.9420        0.4107        5.5518\n",
      "    148        0.0029       0.9388            0.9373            0.9388        0.4218        5.5973\n",
      "    149        0.0020       0.9376            0.9361            0.9376        0.4044        5.5460\n",
      "    150        0.0012       0.9396            0.9381            0.9396        0.4126        5.5701\n",
      "    151        \u001b[36m0.0006\u001b[0m       0.9408            0.9393            0.9408        0.4120        5.5186\n",
      "    152        0.0018       0.9416            0.9401            0.9416        0.4198        5.5722\n",
      "    153        0.0017       0.9412            0.9397            0.9412        0.4181        5.4926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    154        0.0020       0.9404            0.9389            0.9404        0.4186        5.5476\n",
      "    155        \u001b[36m0.0003\u001b[0m       0.9404            0.9389            0.9404        0.4273        5.5808\n",
      "    156        0.0007       0.9412            0.9397            0.9412        0.4328        5.5258\n",
      "    157        0.0005       0.9420            0.9404            0.9420        0.4445        5.5411\n",
      "    158        0.0015       0.9429            0.9413            0.9429        0.4357        5.4349\n",
      "    159        0.0011       0.9388            0.9373            0.9388        0.4608        5.5183\n",
      "    160        0.0006       0.9424            0.9409            0.9424        0.4487        5.5303\n",
      "    161        0.0006       0.9420            0.9406            0.9420        0.4559        5.5451\n",
      "    162        0.0007       0.9429            0.9413            0.9429        0.4681        5.5403\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n",
      "DeepLift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4801]), 'p01': tensor([2.5327]), 'p05': tensor([2.8099]), 'p25': tensor([3.0939]), 'p50': tensor([3.1463]), 'p75': tensor([3.1873]), 'p95': tensor([3.4509]), 'p99': tensor([3.7470]), 'max': tensor([5.1939]), 'mean': tensor([3.1396]), 'std': tensor([0.1962])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6893\u001b[0m       \u001b[32m0.6196\u001b[0m            \u001b[35m0.5988\u001b[0m            \u001b[31m0.6196\u001b[0m        \u001b[94m0.6630\u001b[0m     +  5.5185\n",
      "      2        \u001b[36m0.6457\u001b[0m       \u001b[32m0.6253\u001b[0m            0.5557            \u001b[31m0.6253\u001b[0m        \u001b[94m0.6390\u001b[0m        5.5063\n",
      "      3        \u001b[36m0.6448\u001b[0m       \u001b[32m0.6290\u001b[0m            0.5421            \u001b[31m0.6290\u001b[0m        0.6639        5.5539\n",
      "      4        \u001b[36m0.6303\u001b[0m       \u001b[32m0.6482\u001b[0m            \u001b[35m0.6175\u001b[0m            \u001b[31m0.6482\u001b[0m        \u001b[94m0.6247\u001b[0m     +  5.5511\n",
      "      5        \u001b[36m0.6224\u001b[0m       \u001b[32m0.6531\u001b[0m            \u001b[35m0.6199\u001b[0m            \u001b[31m0.6531\u001b[0m        \u001b[94m0.6207\u001b[0m     +  5.5421\n",
      "      6        \u001b[36m0.6145\u001b[0m       0.6445            \u001b[35m0.6353\u001b[0m            0.6445        0.6305     +  5.6433\n",
      "      7        0.6178       0.6388            0.6039            0.6388        0.6268        5.5305\n",
      "      8        \u001b[36m0.6112\u001b[0m       \u001b[32m0.6571\u001b[0m            \u001b[35m0.6439\u001b[0m            \u001b[31m0.6571\u001b[0m        \u001b[94m0.6199\u001b[0m     +  5.5541\n",
      "      9        \u001b[36m0.6069\u001b[0m       0.6282            0.6028            0.6282        0.6542        5.5946\n",
      "     10        \u001b[36m0.6034\u001b[0m       0.6363            0.5595            0.6363        0.6519        5.5478\n",
      "     11        \u001b[36m0.5964\u001b[0m       0.6106            0.6100            0.6106        0.6705        5.5354\n",
      "     12        \u001b[36m0.5957\u001b[0m       0.6490            0.6399            0.6490        0.6403        5.5015\n",
      "     13        0.5958       0.6249            0.6243            0.6249        0.6553        5.5073\n",
      "     14        \u001b[36m0.5869\u001b[0m       0.6420            0.5747            0.6420        0.6700        5.6417\n",
      "     15        \u001b[36m0.5850\u001b[0m       0.6335            0.6333            0.6335        0.6490        5.5464\n",
      "     16        0.5895       0.6506            0.5909            0.6506        0.6546        5.5956\n",
      "     17        \u001b[36m0.5821\u001b[0m       0.5816            0.5793            0.5816        0.6815        5.5107\n",
      "     18        \u001b[36m0.5781\u001b[0m       0.6380            0.6036            0.6380        0.6551        5.5718\n",
      "     19        \u001b[36m0.5699\u001b[0m       \u001b[32m0.6657\u001b[0m            0.6281            \u001b[31m0.6657\u001b[0m        0.6434        5.5924\n",
      "     20        0.5700       0.6486            0.5998            0.6486        0.6328        5.5372\n",
      "     21        \u001b[36m0.5640\u001b[0m       0.6559            0.6021            0.6559        0.6483        5.6191\n",
      "     22        \u001b[36m0.5634\u001b[0m       0.6376            0.6307            0.6376        0.6425        5.5824\n",
      "     23        \u001b[36m0.5616\u001b[0m       0.6527            0.5882            0.6527        0.7287        5.5546\n",
      "     24        \u001b[36m0.5519\u001b[0m       0.6457            \u001b[35m0.6443\u001b[0m            0.6457        0.6600     +  5.6045\n",
      "     25        \u001b[36m0.5423\u001b[0m       0.6147            0.6063            0.6147        0.7316        5.5119\n",
      "     26        0.5439       0.6584            0.6206            0.6584        0.6417        5.4750\n",
      "     27        \u001b[36m0.5389\u001b[0m       0.6159            0.5504            0.6159        0.7246        5.5572\n",
      "     28        \u001b[36m0.5382\u001b[0m       0.5980            0.5928            0.5980        0.7055        5.5380\n",
      "     29        \u001b[36m0.5327\u001b[0m       0.6535            \u001b[35m0.6505\u001b[0m            0.6535        0.6791     +  5.6160\n",
      "     30        \u001b[36m0.5257\u001b[0m       0.6322            0.5429            0.6322        0.7155        5.4847\n",
      "     31        \u001b[36m0.5172\u001b[0m       0.6318            0.6315            0.6318        0.7026        5.5000\n",
      "     32        \u001b[36m0.5143\u001b[0m       0.6388            0.6198            0.6388        0.6761        5.5618\n",
      "     33        \u001b[36m0.4978\u001b[0m       0.6465            0.6394            0.6465        0.6691        5.6318\n",
      "     34        \u001b[36m0.4976\u001b[0m       0.6327            0.5926            0.6327        0.7473        5.5618\n",
      "     35        \u001b[36m0.4823\u001b[0m       0.6433            0.6363            0.6433        0.7537        5.5941\n",
      "     36        0.4920       0.6551            0.6480            0.6551        0.6838        5.5604\n",
      "     37        \u001b[36m0.4695\u001b[0m       0.6220            0.6203            0.6220        0.7465        5.5640\n",
      "     38        \u001b[36m0.4629\u001b[0m       0.6408            0.6311            0.6408        0.6938        5.6198\n",
      "     39        \u001b[36m0.4584\u001b[0m       0.6522            0.6501            0.6522        0.7077        5.6244\n",
      "     40        \u001b[36m0.4456\u001b[0m       0.6441            0.6184            0.6441        0.7187        5.5193\n",
      "     41        \u001b[36m0.4393\u001b[0m       0.6600            0.6278            0.6600        0.7920        5.6137\n",
      "     42        \u001b[36m0.4216\u001b[0m       0.6302            0.6206            0.6302        0.7570        5.5745\n",
      "     43        \u001b[36m0.4102\u001b[0m       0.6278            0.6195            0.6278        0.7781        5.6096\n",
      "     44        \u001b[36m0.4061\u001b[0m       0.6404            0.6310            0.6404        0.7340        5.5348\n",
      "     45        0.4218       0.6396            0.6342            0.6396        0.7762        5.5639\n",
      "     46        \u001b[36m0.3916\u001b[0m       0.6184            0.6105            0.6184        0.8859        5.4733\n",
      "     47        \u001b[36m0.3762\u001b[0m       0.6265            0.6123            0.6265        0.8097        5.5166\n",
      "     48        \u001b[36m0.3618\u001b[0m       0.6331            0.6143            0.6331        0.8416        5.5575\n",
      "     49        \u001b[36m0.3442\u001b[0m       0.6139            0.6091            0.6139        0.8802        5.5156\n",
      "     50        \u001b[36m0.3200\u001b[0m       0.6347            0.6251            0.6347        0.9052        5.5121\n",
      "     51        0.3236       0.6351            0.6144            0.6351        0.9779        5.5169\n",
      "     52        \u001b[36m0.3068\u001b[0m       0.6273            0.5988            0.6273        1.0258        5.5702\n",
      "     53        \u001b[36m0.2848\u001b[0m       0.6278            0.6208            0.6278        0.9747        5.4834\n",
      "     54        \u001b[36m0.2743\u001b[0m       0.6216            0.6154            0.6216        1.0259        5.5159\n",
      "     55        0.2787       0.6224            0.6155            0.6224        1.0037        5.6244\n",
      "     56        \u001b[36m0.2604\u001b[0m       0.6400            0.6283            0.6400        1.0003        5.5291\n",
      "     57        \u001b[36m0.2365\u001b[0m       0.6204            0.6130            0.6204        1.1881        5.5799\n",
      "     58        0.2433       0.6424            0.6299            0.6424        1.1587        5.5979\n",
      "     59        \u001b[36m0.2282\u001b[0m       0.6367            0.6279            0.6367        1.0289        5.5251\n",
      "     60        \u001b[36m0.2189\u001b[0m       0.6159            0.6114            0.6159        1.2033        5.5270\n",
      "     61        \u001b[36m0.2052\u001b[0m       0.6363            0.6331            0.6363        1.2532        5.6179\n",
      "     62        0.2126       0.6159            0.5751            0.6159        1.0440        5.5304\n",
      "     63        \u001b[36m0.1961\u001b[0m       0.6306            0.6133            0.6306        1.2068        5.6323\n",
      "     64        \u001b[36m0.1791\u001b[0m       0.6180            0.6147            0.6180        1.2521        5.5750\n",
      "     65        0.1895       0.6278            0.6058            0.6278        1.1490        5.4915\n",
      "     66        \u001b[36m0.1785\u001b[0m       0.6273            0.6201            0.6273        1.1193        5.6046\n",
      "     67        \u001b[36m0.1632\u001b[0m       0.6273            0.6179            0.6273        1.1965        5.5928\n",
      "     68        \u001b[36m0.1485\u001b[0m       0.6184            0.6117            0.6184        1.3877        5.5284\n",
      "     69        \u001b[36m0.1455\u001b[0m       0.6118            0.6072            0.6118        1.3953        5.5498\n",
      "     70        0.1496       0.6245            0.6129            0.6245        1.3344        5.5143\n",
      "     71        0.1569       0.6429            0.6337            0.6429        1.1259        5.5198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.1415\u001b[0m       0.6176            0.5969            0.6176        1.3121        5.5622\n",
      "     73        \u001b[36m0.1299\u001b[0m       0.6118            0.6033            0.6118        1.3241        5.4953\n",
      "     74        0.1309       0.6224            0.5914            0.6224        1.4512        5.4872\n",
      "     75        \u001b[36m0.1214\u001b[0m       0.6359            0.6025            0.6359        1.4870        5.6221\n",
      "     76        \u001b[36m0.1127\u001b[0m       0.6237            0.6204            0.6237        1.3921        5.5599\n",
      "     77        0.1128       0.6241            0.6037            0.6241        1.5452        5.5469\n",
      "     78        \u001b[36m0.1115\u001b[0m       0.5694            0.5660            0.5694        1.3650        5.5792\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4599]), 'p01': tensor([2.5298]), 'p05': tensor([2.8079]), 'p25': tensor([3.0937]), 'p50': tensor([3.1462]), 'p75': tensor([3.1873]), 'p95': tensor([3.4512]), 'p99': tensor([3.7476]), 'max': tensor([5.2849]), 'mean': tensor([3.1394]), 'std': tensor([0.1971])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6818\u001b[0m       \u001b[32m0.6135\u001b[0m            \u001b[35m0.5088\u001b[0m            \u001b[31m0.6135\u001b[0m        \u001b[94m0.6633\u001b[0m     +  5.4996\n",
      "      2        \u001b[36m0.6439\u001b[0m       0.5939            \u001b[35m0.5916\u001b[0m            0.5939        \u001b[94m0.6424\u001b[0m     +  5.6022\n",
      "      3        \u001b[36m0.6333\u001b[0m       \u001b[32m0.6241\u001b[0m            \u001b[35m0.6206\u001b[0m            \u001b[31m0.6241\u001b[0m        \u001b[94m0.6369\u001b[0m     +  5.5197\n",
      "      4        \u001b[36m0.6284\u001b[0m       \u001b[32m0.6343\u001b[0m            0.5394            \u001b[31m0.6343\u001b[0m        \u001b[94m0.6329\u001b[0m        5.6669\n",
      "      5        \u001b[36m0.6227\u001b[0m       0.6098            0.6070            0.6098        0.6526        5.5909\n",
      "      6        \u001b[36m0.6178\u001b[0m       \u001b[32m0.6486\u001b[0m            0.6019            \u001b[31m0.6486\u001b[0m        0.6652        5.5400\n",
      "      7        \u001b[36m0.6141\u001b[0m       0.6278            0.5712            0.6278        0.6640        5.6119\n",
      "      8        \u001b[36m0.6123\u001b[0m       \u001b[32m0.6576\u001b[0m            \u001b[35m0.6307\u001b[0m            \u001b[31m0.6576\u001b[0m        \u001b[94m0.6161\u001b[0m     +  5.6928\n",
      "      9        \u001b[36m0.6065\u001b[0m       0.6514            0.5942            0.6514        0.6258        5.4949\n",
      "     10        \u001b[36m0.5990\u001b[0m       0.6494            \u001b[35m0.6371\u001b[0m            0.6494        0.6250     +  5.5642\n",
      "     11        \u001b[36m0.5955\u001b[0m       0.6343            0.5769            0.6343        0.6390        5.5538\n",
      "     12        \u001b[36m0.5884\u001b[0m       0.6441            \u001b[35m0.6437\u001b[0m            0.6441        0.6390     +  5.6270\n",
      "     13        \u001b[36m0.5854\u001b[0m       0.6057            0.5918            0.6057        0.6946        5.5039\n",
      "     14        \u001b[36m0.5839\u001b[0m       \u001b[32m0.6682\u001b[0m            0.6353            \u001b[31m0.6682\u001b[0m        \u001b[94m0.6136\u001b[0m        5.4999\n",
      "     15        \u001b[36m0.5805\u001b[0m       0.6306            0.6247            0.6306        0.6371        5.4904\n",
      "     16        \u001b[36m0.5746\u001b[0m       0.6212            0.5451            0.6212        0.7368        5.5456\n",
      "     17        \u001b[36m0.5739\u001b[0m       0.6347            0.5992            0.6347        0.6846        5.6050\n",
      "     18        0.5762       0.6433            0.6230            0.6433        0.6337        5.6326\n",
      "     19        \u001b[36m0.5707\u001b[0m       0.6498            0.6265            0.6498        0.6453        5.6176\n",
      "     20        \u001b[36m0.5675\u001b[0m       0.6490            0.6350            0.6490        0.6338        5.5022\n",
      "     21        \u001b[36m0.5591\u001b[0m       0.6527            0.6097            0.6527        0.6465        5.5752\n",
      "     22        0.5616       0.6229            0.5914            0.6229        0.6566        5.5115\n",
      "     23        \u001b[36m0.5547\u001b[0m       0.6249            0.6236            0.6249        0.7071        5.6056\n",
      "     24        \u001b[36m0.5431\u001b[0m       0.6384            0.6340            0.6384        0.6623        5.5462\n",
      "     25        \u001b[36m0.5353\u001b[0m       0.6616            0.6433            0.6616        0.6389        5.5349\n",
      "     26        \u001b[36m0.5281\u001b[0m       0.6253            0.6246            0.6253        0.6883        5.4648\n",
      "     27        0.5323       0.5841            0.5110            0.5841        0.8054        5.4940\n",
      "     28        \u001b[36m0.5252\u001b[0m       0.6269            0.6165            0.6269        0.6637        5.5397\n",
      "     29        \u001b[36m0.5215\u001b[0m       0.6061            0.5985            0.6061        0.7244        5.5356\n",
      "     30        \u001b[36m0.5091\u001b[0m       0.6433            0.6211            0.6433        0.6913        5.5590\n",
      "     31        \u001b[36m0.5044\u001b[0m       0.5853            0.5853            0.5853        0.8012        5.5248\n",
      "     32        \u001b[36m0.5004\u001b[0m       0.6457            0.6322            0.6457        0.6585        5.4644\n",
      "     33        \u001b[36m0.4842\u001b[0m       0.6347            0.6237            0.6347        0.7338        5.5522\n",
      "     34        0.4864       0.6469            0.6372            0.6469        0.6826        5.4609\n",
      "     35        0.4870       0.6400            0.6334            0.6400        0.7048        5.5406\n",
      "     36        \u001b[36m0.4696\u001b[0m       0.5988            0.5980            0.5988        0.7737        5.5231\n",
      "     37        \u001b[36m0.4632\u001b[0m       0.6094            0.6081            0.6094        0.7467        5.5274\n",
      "     38        \u001b[36m0.4484\u001b[0m       0.6445            0.6395            0.6445        0.7408        5.5161\n",
      "     39        0.4557       0.5967            0.5967            0.5967        0.8382        5.5419\n",
      "     40        \u001b[36m0.4349\u001b[0m       0.6094            0.6087            0.6094        0.7667        5.5295\n",
      "     41        \u001b[36m0.4259\u001b[0m       0.6151            0.5703            0.6151        0.8303        5.5426\n",
      "     42        \u001b[36m0.4167\u001b[0m       0.6122            0.5524            0.6122        0.9758        5.6232\n",
      "     43        \u001b[36m0.3999\u001b[0m       0.5927            0.5782            0.5927        0.8505        5.5431\n",
      "     44        \u001b[36m0.3861\u001b[0m       0.6278            0.5904            0.6278        0.8727        5.5925\n",
      "     45        \u001b[36m0.3810\u001b[0m       0.6159            0.6000            0.6159        0.8300        5.5171\n",
      "     46        \u001b[36m0.3633\u001b[0m       0.6122            0.5977            0.6122        0.9106        5.5638\n",
      "     47        \u001b[36m0.3535\u001b[0m       0.5996            0.5698            0.5996        0.9646        5.5617\n",
      "     48        0.3738       0.5943            0.5831            0.5943        0.8739        5.5434\n",
      "     49        \u001b[36m0.3425\u001b[0m       0.6090            0.5959            0.6090        0.8916        5.5363\n",
      "     50        \u001b[36m0.3250\u001b[0m       0.6012            0.6006            0.6012        1.0124        5.5160\n",
      "     51        0.3281       0.6204            0.6076            0.6204        0.9112        5.4763\n",
      "     52        \u001b[36m0.3028\u001b[0m       0.6237            0.6105            0.6237        1.0113        5.5225\n",
      "     53        \u001b[36m0.2817\u001b[0m       0.6029            0.5918            0.6029        1.0043        5.4767\n",
      "     54        \u001b[36m0.2787\u001b[0m       0.6008            0.5933            0.6008        1.0793        5.5779\n",
      "     55        \u001b[36m0.2666\u001b[0m       0.6106            0.5944            0.6106        1.0460        5.4770\n",
      "     56        \u001b[36m0.2586\u001b[0m       0.6171            0.5848            0.6171        1.1076        5.5508\n",
      "     57        \u001b[36m0.2577\u001b[0m       0.5988            0.5949            0.5988        1.0872        5.5657\n",
      "     58        \u001b[36m0.2501\u001b[0m       0.6237            0.6189            0.6237        1.0147        5.5310\n",
      "     59        \u001b[36m0.2291\u001b[0m       0.5861            0.5765            0.5861        1.1167        5.5942\n",
      "     60        \u001b[36m0.2153\u001b[0m       0.6004            0.5874            0.6004        1.1553        5.5063\n",
      "     61        0.2197       0.6188            0.6015            0.6188        1.0052        5.5517\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4945]), 'p01': tensor([2.5289]), 'p05': tensor([2.8081]), 'p25': tensor([3.0940]), 'p50': tensor([3.1465]), 'p75': tensor([3.1875]), 'p95': tensor([3.4523]), 'p99': tensor([3.7478]), 'max': tensor([5.2376]), 'mean': tensor([3.1398]), 'std': tensor([0.1972])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7075\u001b[0m       \u001b[32m0.6016\u001b[0m            \u001b[35m0.4527\u001b[0m            \u001b[31m0.6016\u001b[0m        \u001b[94m0.6911\u001b[0m     +  5.5707\n",
      "      2        \u001b[36m0.6481\u001b[0m       \u001b[32m0.6233\u001b[0m            \u001b[35m0.5693\u001b[0m            \u001b[31m0.6233\u001b[0m        \u001b[94m0.6470\u001b[0m     +  5.5108\n",
      "      3        \u001b[36m0.6384\u001b[0m       0.5935            \u001b[35m0.5931\u001b[0m            0.5935        0.6586     +  5.5094\n",
      "      4        \u001b[36m0.6311\u001b[0m       0.6139            \u001b[35m0.6122\u001b[0m            0.6139        0.6558     +  5.5092\n",
      "      5        \u001b[36m0.6290\u001b[0m       \u001b[32m0.6376\u001b[0m            0.5718            \u001b[31m0.6376\u001b[0m        \u001b[94m0.6290\u001b[0m        5.5347\n",
      "      6        \u001b[36m0.6191\u001b[0m       0.6224            0.5802            0.6224        0.6578        5.5554\n",
      "      7        \u001b[36m0.6161\u001b[0m       0.6298            0.6063            0.6298        0.6478        5.5358\n",
      "      8        0.6189       \u001b[32m0.6571\u001b[0m            \u001b[35m0.6374\u001b[0m            \u001b[31m0.6571\u001b[0m        0.6359     +  6.1532\n",
      "      9        \u001b[36m0.6097\u001b[0m       0.6139            0.6139            0.6139        0.6645        5.5201\n",
      "     10        \u001b[36m0.6053\u001b[0m       0.6343            0.6315            0.6343        0.6412        5.5495\n",
      "     11        \u001b[36m0.6019\u001b[0m       0.5873            0.5862            0.5873        0.6589        5.5950\n",
      "     12        \u001b[36m0.6011\u001b[0m       0.5951            0.4728            0.5951        0.7025        5.5090\n",
      "     13        0.6043       0.6453            0.6173            0.6453        0.6350        5.5587\n",
      "     14        \u001b[36m0.5977\u001b[0m       0.6310            0.6231            0.6310        0.6459        5.4787\n",
      "     15        \u001b[36m0.5920\u001b[0m       0.6110            0.6108            0.6110        0.6783        5.6332\n",
      "     16        \u001b[36m0.5886\u001b[0m       0.6494            0.6255            0.6494        \u001b[94m0.6234\u001b[0m        5.5621\n",
      "     17        \u001b[36m0.5860\u001b[0m       0.6551            0.6093            0.6551        0.6317        5.4763\n",
      "     18        0.5903       0.6510            \u001b[35m0.6452\u001b[0m            0.6510        \u001b[94m0.6163\u001b[0m     +  5.5724\n",
      "     19        \u001b[36m0.5813\u001b[0m       \u001b[32m0.6612\u001b[0m            0.6338            \u001b[31m0.6612\u001b[0m        0.6316        5.5134\n",
      "     20        \u001b[36m0.5748\u001b[0m       0.6510            0.6120            0.6510        0.6464        5.6326\n",
      "     21        \u001b[36m0.5731\u001b[0m       0.5220            0.4998            0.5220        1.0492        5.6199\n",
      "     22        \u001b[36m0.5677\u001b[0m       0.6449            0.6366            0.6449        0.6263        5.5228\n",
      "     23        \u001b[36m0.5616\u001b[0m       0.5927            0.5848            0.5927        0.7075        5.4789\n",
      "     24        0.5660       0.6224            0.6219            0.6224        0.6825        5.5009\n",
      "     25        \u001b[36m0.5544\u001b[0m       0.6294            0.6280            0.6294        0.6543        5.4830\n",
      "     26        \u001b[36m0.5473\u001b[0m       0.6445            0.6272            0.6445        0.6555        5.5045\n",
      "     27        \u001b[36m0.5418\u001b[0m       0.6286            0.6284            0.6286        0.6754        5.5112\n",
      "     28        0.5493       0.6367            0.5922            0.6367        0.7501        5.5203\n",
      "     29        \u001b[36m0.5383\u001b[0m       0.6314            0.6279            0.6314        0.6887        5.5978\n",
      "     30        \u001b[36m0.5336\u001b[0m       0.6159            0.6104            0.6159        0.6717        5.4775\n",
      "     31        \u001b[36m0.5213\u001b[0m       \u001b[32m0.6616\u001b[0m            \u001b[35m0.6498\u001b[0m            \u001b[31m0.6616\u001b[0m        0.6334     +  5.5601\n",
      "     32        0.5400       0.6494            0.5962            0.6494        0.6798        5.5913\n",
      "     33        0.5242       0.6376            0.6366            0.6376        0.6566        5.5672\n",
      "     34        \u001b[36m0.5117\u001b[0m       0.6327            0.6268            0.6327        0.7055        5.5320\n",
      "     35        \u001b[36m0.5108\u001b[0m       0.6188            0.6136            0.6188        0.6746        5.4651\n",
      "     36        \u001b[36m0.5009\u001b[0m       0.6363            0.6325            0.6363        0.7101        5.4985\n",
      "     37        \u001b[36m0.4923\u001b[0m       0.6367            0.6254            0.6367        0.7057        5.4603\n",
      "     38        \u001b[36m0.4789\u001b[0m       0.6204            0.5856            0.6204        0.8224        5.5867\n",
      "     39        \u001b[36m0.4730\u001b[0m       0.6204            0.6162            0.6204        0.7823        5.5317\n",
      "     40        \u001b[36m0.4610\u001b[0m       0.6371            0.6341            0.6371        0.7088        5.5393\n",
      "     41        \u001b[36m0.4569\u001b[0m       0.6527            0.6151            0.6527        0.7583        5.5070\n",
      "     42        \u001b[36m0.4493\u001b[0m       0.6380            0.6106            0.6380        0.7098        5.5508\n",
      "     43        \u001b[36m0.4435\u001b[0m       0.6294            0.6195            0.6294        0.7440        5.5275\n",
      "     44        \u001b[36m0.4324\u001b[0m       0.6473            0.6128            0.6473        0.7770        5.5719\n",
      "     45        \u001b[36m0.4232\u001b[0m       0.6400            0.5973            0.6400        1.0318        5.5713\n",
      "     46        \u001b[36m0.4115\u001b[0m       0.6298            0.5683            0.6298        0.7940        5.4768\n",
      "     47        0.4160       0.6135            0.6110            0.6135        0.8610        5.4840\n",
      "     48        0.4196       \u001b[32m0.6665\u001b[0m            \u001b[35m0.6573\u001b[0m            \u001b[31m0.6665\u001b[0m        0.7611     +  5.5152\n",
      "     49        \u001b[36m0.3886\u001b[0m       0.6135            0.6098            0.6135        0.8751        5.4975\n",
      "     50        \u001b[36m0.3666\u001b[0m       0.6151            0.6127            0.6151        0.8993        5.6093\n",
      "     51        \u001b[36m0.3537\u001b[0m       0.6061            0.6018            0.6061        0.9017        5.5710\n",
      "     52        0.3553       0.6257            0.6106            0.6257        0.8463        5.5160\n",
      "     53        \u001b[36m0.3378\u001b[0m       0.6290            0.6044            0.6290        0.8402        5.5423\n",
      "     54        \u001b[36m0.3203\u001b[0m       0.6576            0.6430            0.6576        0.8725        5.5325\n",
      "     55        \u001b[36m0.3147\u001b[0m       0.6363            0.6292            0.6363        0.9071        5.4635\n",
      "     56        \u001b[36m0.2998\u001b[0m       0.6224            0.6222            0.6224        0.9271        5.5052\n",
      "     57        0.3014       0.6424            0.6070            0.6424        1.0504        5.5595\n",
      "     58        \u001b[36m0.2846\u001b[0m       0.6314            0.6283            0.6314        0.9185        5.6458\n",
      "     59        \u001b[36m0.2750\u001b[0m       0.6192            0.6123            0.6192        0.9610        5.5586\n",
      "     60        \u001b[36m0.2508\u001b[0m       0.6151            0.6074            0.6151        0.9826        5.5726\n",
      "     61        0.2520       0.6208            0.6158            0.6208        1.0506        5.4498\n",
      "     62        0.2516       0.6208            0.6113            0.6208        1.0858        5.6050\n",
      "     63        \u001b[36m0.2295\u001b[0m       0.6547            0.6307            0.6547        1.0498        5.5048\n",
      "     64        \u001b[36m0.2213\u001b[0m       0.6302            0.6033            0.6302        1.0661        5.4903\n",
      "     65        \u001b[36m0.2054\u001b[0m       0.6400            0.6350            0.6400        1.2144        5.4726\n",
      "     66        0.2105       0.6457            0.6302            0.6457        1.2101        5.5120\n",
      "     67        \u001b[36m0.1986\u001b[0m       0.6380            0.6269            0.6380        1.0439        5.5343\n",
      "     68        \u001b[36m0.1880\u001b[0m       0.6265            0.6192            0.6265        1.2112        5.5582\n",
      "     69        \u001b[36m0.1783\u001b[0m       0.6147            0.6133            0.6147        1.3313        5.5765\n",
      "     70        \u001b[36m0.1659\u001b[0m       0.6078            0.6037            0.6078        1.2195        5.5628\n",
      "     71        0.1694       0.6404            0.6344            0.6404        1.1905        5.5274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.1644\u001b[0m       0.6310            0.6021            0.6310        1.2876        5.5833\n",
      "     73        \u001b[36m0.1517\u001b[0m       0.6363            0.6252            0.6363        1.1293        5.5419\n",
      "     74        \u001b[36m0.1407\u001b[0m       0.6355            0.6265            0.6355        1.1873        5.6459\n",
      "     75        0.1475       0.6163            0.6068            0.6163        1.2549        5.5975\n",
      "     76        0.1428       0.6441            0.6278            0.6441        1.2560        5.5593\n",
      "     77        \u001b[36m0.1282\u001b[0m       0.6327            0.6215            0.6327        1.3149        5.4654\n",
      "     78        \u001b[36m0.1185\u001b[0m       0.6224            0.5981            0.6224        1.4671        5.5288\n",
      "     79        0.1423       0.6131            0.5990            0.6131        1.3339        5.4460\n",
      "     80        0.1282       0.6241            0.6191            0.6241        1.4047        5.5212\n",
      "     81        \u001b[36m0.1156\u001b[0m       0.6180            0.6051            0.6180        1.4512        5.5721\n",
      "     82        \u001b[36m0.1097\u001b[0m       0.6192            0.6180            0.6192        1.5196        5.4899\n",
      "     83        0.1117       0.6441            0.6337            0.6441        1.4763        5.4970\n",
      "     84        \u001b[36m0.0943\u001b[0m       0.6237            0.6058            0.6237        1.5196        5.4896\n",
      "     85        0.0966       0.6339            0.6195            0.6339        1.4751        5.5940\n",
      "     86        0.0980       0.6241            0.6041            0.6241        1.6129        5.5412\n",
      "     87        0.0954       0.6237            0.6167            0.6237        1.4209        5.5480\n",
      "     88        \u001b[36m0.0917\u001b[0m       0.6212            0.5948            0.6212        1.5668        5.5577\n",
      "     89        0.0936       0.6192            0.6082            0.6192        1.4338        5.4840\n",
      "     90        \u001b[36m0.0799\u001b[0m       0.6273            0.6103            0.6273        1.5103        5.5373\n",
      "     91        0.0908       0.6396            0.6236            0.6396        1.5224        5.5564\n",
      "     92        0.0816       0.6306            0.6189            0.6306        1.6212        5.5272\n",
      "     93        0.0822       0.6396            0.6270            0.6396        1.6429        5.5692\n",
      "     94        \u001b[36m0.0784\u001b[0m       0.6437            0.6322            0.6437        1.6079        5.5991\n",
      "     95        \u001b[36m0.0720\u001b[0m       0.6367            0.6136            0.6367        1.7175        5.5377\n",
      "     96        0.0802       0.6233            0.6082            0.6233        1.6746        5.5235\n",
      "     97        0.0733       0.6188            0.6079            0.6188        1.5886        5.4794\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4757]), 'p01': tensor([2.5295]), 'p05': tensor([2.8071]), 'p25': tensor([3.0940]), 'p50': tensor([3.1461]), 'p75': tensor([3.1876]), 'p95': tensor([3.4514]), 'p99': tensor([3.7498]), 'max': tensor([5.2048]), 'mean': tensor([3.1395]), 'std': tensor([0.1973])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6958\u001b[0m       \u001b[32m0.6082\u001b[0m            \u001b[35m0.5208\u001b[0m            \u001b[31m0.6082\u001b[0m        \u001b[94m0.6661\u001b[0m     +  5.5443\n",
      "      2        \u001b[36m0.6451\u001b[0m       \u001b[32m0.6216\u001b[0m            \u001b[35m0.5228\u001b[0m            \u001b[31m0.6216\u001b[0m        \u001b[94m0.6623\u001b[0m     +  5.5367\n",
      "      3        \u001b[36m0.6328\u001b[0m       \u001b[32m0.6339\u001b[0m            \u001b[35m0.6049\u001b[0m            \u001b[31m0.6339\u001b[0m        \u001b[94m0.6434\u001b[0m     +  5.5257\n",
      "      4        \u001b[36m0.6217\u001b[0m       0.6216            0.5276            0.6216        0.6594        5.5443\n",
      "      5        \u001b[36m0.6168\u001b[0m       \u001b[32m0.6392\u001b[0m            0.5787            \u001b[31m0.6392\u001b[0m        0.6461        5.5733\n",
      "      6        \u001b[36m0.6130\u001b[0m       0.5543            0.5483            0.5543        0.6757        5.5530\n",
      "      7        \u001b[36m0.6110\u001b[0m       0.6371            \u001b[35m0.6308\u001b[0m            0.6371        \u001b[94m0.6346\u001b[0m     +  5.4942\n",
      "      8        \u001b[36m0.6069\u001b[0m       0.5984            0.4348            0.5984        0.8080        5.5275\n",
      "      9        \u001b[36m0.5969\u001b[0m       0.6212            0.6152            0.6212        0.6640        5.5852\n",
      "     10        0.5977       0.6371            0.6066            0.6371        0.6651        5.5432\n",
      "     11        \u001b[36m0.5940\u001b[0m       0.6188            0.5426            0.6188        0.6657        5.5940\n",
      "     12        0.5974       \u001b[32m0.6416\u001b[0m            \u001b[35m0.6403\u001b[0m            \u001b[31m0.6416\u001b[0m        0.6436     +  5.4600\n",
      "     13        \u001b[36m0.5913\u001b[0m       \u001b[32m0.6473\u001b[0m            0.5996            \u001b[31m0.6473\u001b[0m        0.6773        5.5225\n",
      "     14        \u001b[36m0.5876\u001b[0m       0.6473            0.6361            0.6473        \u001b[94m0.6290\u001b[0m        5.4715\n",
      "     15        \u001b[36m0.5801\u001b[0m       0.5841            0.3904            0.5841        0.8466        5.5056\n",
      "     16        \u001b[36m0.5729\u001b[0m       0.6384            0.5802            0.6384        0.6511        5.4857\n",
      "     17        0.5737       0.6261            0.6259            0.6261        0.6296        5.5949\n",
      "     18        \u001b[36m0.5705\u001b[0m       0.6118            0.4819            0.6118        0.8175        5.5937\n",
      "     19        0.5727       0.5633            0.5477            0.5633        0.7663        5.5374\n",
      "     20        \u001b[36m0.5601\u001b[0m       \u001b[32m0.6486\u001b[0m            0.6077            \u001b[31m0.6486\u001b[0m        0.6428        5.5371\n",
      "     21        \u001b[36m0.5565\u001b[0m       0.6261            0.6175            0.6261        0.6484        5.5530\n",
      "     22        0.5582       0.6351            0.5692            0.6351        0.6608        5.6221\n",
      "     23        \u001b[36m0.5542\u001b[0m       0.6253            0.5504            0.6253        0.6743        5.5138\n",
      "     24        \u001b[36m0.5530\u001b[0m       0.5482            0.5291            0.5482        0.7855        5.5742\n",
      "     25        \u001b[36m0.5437\u001b[0m       \u001b[32m0.6518\u001b[0m            \u001b[35m0.6475\u001b[0m            \u001b[31m0.6518\u001b[0m        0.6437     +  5.5383\n",
      "     26        \u001b[36m0.5338\u001b[0m       \u001b[32m0.6531\u001b[0m            0.6427            \u001b[31m0.6531\u001b[0m        0.6529        5.5002\n",
      "     27        \u001b[36m0.5316\u001b[0m       0.6347            0.5872            0.6347        0.6859        5.5355\n",
      "     28        \u001b[36m0.5300\u001b[0m       0.6514            0.6443            0.6514        0.6400        5.5074\n",
      "     29        \u001b[36m0.5226\u001b[0m       0.6490            0.6359            0.6490        0.6693        5.5017\n",
      "     30        \u001b[36m0.5176\u001b[0m       0.6388            0.5763            0.6388        0.7386        5.4708\n",
      "     31        \u001b[36m0.5097\u001b[0m       \u001b[32m0.6710\u001b[0m            \u001b[35m0.6605\u001b[0m            \u001b[31m0.6710\u001b[0m        0.6638     +  5.5099\n",
      "     32        \u001b[36m0.5065\u001b[0m       0.6327            0.6000            0.6327        0.6939        5.7547\n",
      "     33        \u001b[36m0.4962\u001b[0m       0.6029            0.6015            0.6029        0.7782        5.7053\n",
      "     34        \u001b[36m0.4860\u001b[0m       0.6408            0.6381            0.6408        0.6809        5.8070\n",
      "     35        \u001b[36m0.4817\u001b[0m       0.6322            0.5723            0.6322        0.7123        5.7681\n",
      "     36        \u001b[36m0.4755\u001b[0m       0.5996            0.5989            0.5996        0.7250        5.7673\n",
      "     37        \u001b[36m0.4747\u001b[0m       0.6380            0.6336            0.6380        0.7047        5.9691\n",
      "     38        \u001b[36m0.4594\u001b[0m       0.6310            0.5929            0.6310        0.7569        5.9093\n",
      "     39        \u001b[36m0.4438\u001b[0m       0.6184            0.6080            0.6184        0.8024        5.8622\n",
      "     40        \u001b[36m0.4336\u001b[0m       0.6200            0.5768            0.6200        0.8160        5.8014\n",
      "     41        \u001b[36m0.4251\u001b[0m       0.6216            0.6200            0.6216        0.7962        5.9331\n",
      "     42        \u001b[36m0.4217\u001b[0m       0.5963            0.5909            0.5963        0.8710        5.9869\n",
      "     43        \u001b[36m0.4071\u001b[0m       0.6469            0.6281            0.6469        0.7745        5.9650\n",
      "     44        \u001b[36m0.4028\u001b[0m       0.6224            0.6041            0.6224        0.8529        5.9467\n",
      "     45        \u001b[36m0.3815\u001b[0m       0.6371            0.6214            0.6371        0.7990        6.0058\n",
      "     46        \u001b[36m0.3590\u001b[0m       0.6318            0.6257            0.6318        0.8088        5.9525\n",
      "     47        0.3692       0.6322            0.5867            0.6322        0.8608        5.8936\n",
      "     48        \u001b[36m0.3556\u001b[0m       0.6286            0.6251            0.6286        0.9387        5.6264\n",
      "     49        \u001b[36m0.3414\u001b[0m       0.5914            0.5895            0.5914        0.9821        5.6849\n",
      "     50        \u001b[36m0.3220\u001b[0m       0.6233            0.6065            0.6233        0.8229        5.8288\n",
      "     51        \u001b[36m0.3143\u001b[0m       0.6061            0.5983            0.6061        1.0345        5.8651\n",
      "     52        \u001b[36m0.2959\u001b[0m       0.6159            0.5858            0.6159        0.9711        5.7636\n",
      "     53        \u001b[36m0.2885\u001b[0m       0.6265            0.5943            0.6265        0.9933        5.5504\n",
      "     54        \u001b[36m0.2815\u001b[0m       0.6176            0.5797            0.6176        1.1110        5.7818\n",
      "     55        \u001b[36m0.2741\u001b[0m       0.6131            0.5840            0.6131        1.0950        6.0222\n",
      "     56        \u001b[36m0.2526\u001b[0m       0.6184            0.5643            0.6184        1.1612        5.8961\n",
      "     57        \u001b[36m0.2482\u001b[0m       0.6167            0.6100            0.6167        1.0399        5.7679\n",
      "     58        \u001b[36m0.2458\u001b[0m       0.6212            0.6092            0.6212        1.0742        5.5789\n",
      "     59        \u001b[36m0.2262\u001b[0m       0.6237            0.6191            0.6237        1.1225        5.5832\n",
      "     60        \u001b[36m0.2098\u001b[0m       0.6131            0.6011            0.6131        1.0451        5.4803\n",
      "     61        0.2260       0.6314            0.6032            0.6314        1.1504        5.5298\n",
      "     62        \u001b[36m0.1942\u001b[0m       0.6167            0.6059            0.6167        1.1862        5.5399\n",
      "     63        \u001b[36m0.1927\u001b[0m       0.6314            0.5909            0.6314        1.3025        5.6032\n",
      "     64        \u001b[36m0.1824\u001b[0m       0.6290            0.6132            0.6290        1.2053        5.5527\n",
      "     65        \u001b[36m0.1712\u001b[0m       0.6355            0.6223            0.6355        1.2780        5.6405\n",
      "     66        \u001b[36m0.1638\u001b[0m       0.6102            0.5769            0.6102        1.2896        5.4864\n",
      "     67        0.1758       0.6253            0.6119            0.6253        1.2109        5.6646\n",
      "     68        \u001b[36m0.1575\u001b[0m       0.6253            0.6137            0.6253        1.3224        5.5170\n",
      "     69        \u001b[36m0.1487\u001b[0m       0.6192            0.6024            0.6192        1.3127        5.6125\n",
      "     70        0.1562       0.5976            0.5971            0.5976        1.5766        5.5585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     71        \u001b[36m0.1355\u001b[0m       0.6180            0.6074            0.6180        1.2591        5.5823\n",
      "     72        \u001b[36m0.1338\u001b[0m       0.5980            0.5916            0.5980        1.4231        5.5097\n",
      "     73        \u001b[36m0.1185\u001b[0m       0.6016            0.5940            0.6016        1.5464        5.5351\n",
      "     74        0.1193       0.6196            0.6093            0.6196        1.4196        5.5814\n",
      "     75        \u001b[36m0.1118\u001b[0m       0.6131            0.5899            0.6131        1.5012        5.6098\n",
      "     76        0.1207       0.6188            0.6103            0.6188        1.4061        5.5098\n",
      "     77        \u001b[36m0.1090\u001b[0m       0.6033            0.5998            0.6033        1.6649        5.5265\n",
      "     78        \u001b[36m0.1079\u001b[0m       0.6090            0.5940            0.6090        1.5552        5.5020\n",
      "     79        \u001b[36m0.1070\u001b[0m       0.6188            0.6036            0.6188        1.5139        5.5815\n",
      "     80        0.1115       0.6310            0.6245            0.6310        1.5059        5.6026\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.5383]), 'p01': tensor([2.5298]), 'p05': tensor([2.8084]), 'p25': tensor([3.0936]), 'p50': tensor([3.1463]), 'p75': tensor([3.1878]), 'p95': tensor([3.4512]), 'p99': tensor([3.7484]), 'max': tensor([5.2319]), 'mean': tensor([3.1397]), 'std': tensor([0.1969])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6940\u001b[0m       \u001b[32m0.6147\u001b[0m            \u001b[35m0.4854\u001b[0m            \u001b[31m0.6147\u001b[0m        \u001b[94m0.6666\u001b[0m     +  5.5298\n",
      "      2        \u001b[36m0.6436\u001b[0m       \u001b[32m0.6416\u001b[0m            \u001b[35m0.5707\u001b[0m            \u001b[31m0.6416\u001b[0m        \u001b[94m0.6453\u001b[0m     +  5.5466\n",
      "      3        \u001b[36m0.6333\u001b[0m       \u001b[32m0.6429\u001b[0m            \u001b[35m0.6329\u001b[0m            \u001b[31m0.6429\u001b[0m        \u001b[94m0.6254\u001b[0m     +  5.5059\n",
      "      4        \u001b[36m0.6326\u001b[0m       \u001b[32m0.6563\u001b[0m            \u001b[35m0.6399\u001b[0m            \u001b[31m0.6563\u001b[0m        0.6264     +  5.5783\n",
      "      5        \u001b[36m0.6227\u001b[0m       0.6551            0.6172            0.6551        \u001b[94m0.6253\u001b[0m        5.5187\n",
      "      6        \u001b[36m0.6200\u001b[0m       0.6420            0.6233            0.6420        \u001b[94m0.6245\u001b[0m        5.5743\n",
      "      7        \u001b[36m0.6086\u001b[0m       0.6518            0.5948            0.6518        0.6449        5.5528\n",
      "      8        \u001b[36m0.6080\u001b[0m       0.5894            0.5888            0.5894        0.6646        5.5325\n",
      "      9        0.6097       0.6563            \u001b[35m0.6505\u001b[0m            0.6563        \u001b[94m0.6197\u001b[0m     +  5.5999\n",
      "     10        \u001b[36m0.5998\u001b[0m       0.6449            0.5917            0.6449        0.6416        5.5210\n",
      "     11        \u001b[36m0.5952\u001b[0m       0.5824            0.3787            0.5824        0.9297        5.5150\n",
      "     12        \u001b[36m0.5927\u001b[0m       0.5943            0.5925            0.5943        0.6811        5.6842\n",
      "     13        \u001b[36m0.5873\u001b[0m       0.5931            0.5914            0.5931        0.7292        5.5024\n",
      "     14        0.5886       0.6449            0.5981            0.6449        0.6527        5.5481\n",
      "     15        \u001b[36m0.5797\u001b[0m       0.5996            0.5994            0.5996        0.6759        5.6448\n",
      "     16        \u001b[36m0.5782\u001b[0m       0.6437            0.6395            0.6437        0.6410        5.5874\n",
      "     17        0.5797       0.6510            0.6354            0.6510        0.6327        5.6989\n",
      "     18        \u001b[36m0.5700\u001b[0m       0.6367            0.6294            0.6367        0.6533        5.5268\n",
      "     19        \u001b[36m0.5663\u001b[0m       0.6408            0.6381            0.6408        0.6439        5.6575\n",
      "     20        0.5682       0.6269            0.5252            0.6269        0.8312        5.6258\n",
      "     21        \u001b[36m0.5570\u001b[0m       0.6535            0.6418            0.6535        0.6410        5.5609\n",
      "     22        0.5599       \u001b[32m0.6608\u001b[0m            0.6434            \u001b[31m0.6608\u001b[0m        0.6359        5.5810\n",
      "     23        0.5587       0.5396            0.5384            0.5396        0.7713        5.5974\n",
      "     24        \u001b[36m0.5524\u001b[0m       0.6527            0.6442            0.6527        0.6536        5.5445\n",
      "     25        \u001b[36m0.5401\u001b[0m       0.6506            0.5930            0.6506        0.6578        5.5353\n",
      "     26        \u001b[36m0.5354\u001b[0m       0.6408            0.5958            0.6408        0.6488        5.6463\n",
      "     27        0.5388       0.6518            0.5971            0.6518        0.7139        5.5013\n",
      "     28        \u001b[36m0.5339\u001b[0m       0.6592            \u001b[35m0.6511\u001b[0m            0.6592        0.6492     +  5.4956\n",
      "     29        0.5352       0.6433            0.5992            0.6433        0.6927        5.5275\n",
      "     30        \u001b[36m0.5280\u001b[0m       0.5947            0.4355            0.5947        0.9400        5.6541\n",
      "     31        \u001b[36m0.5221\u001b[0m       0.5939            0.5937            0.5939        0.7506        5.5715\n",
      "     32        \u001b[36m0.5157\u001b[0m       0.6404            0.5747            0.6404        0.7312        5.4768\n",
      "     33        \u001b[36m0.5120\u001b[0m       0.6249            0.6198            0.6249        0.6913        5.5610\n",
      "     34        \u001b[36m0.5065\u001b[0m       0.6355            0.5866            0.6355        0.6923        5.5577\n",
      "     35        \u001b[36m0.4975\u001b[0m       0.6184            0.6183            0.6184        0.7359        5.5224\n",
      "     36        \u001b[36m0.4819\u001b[0m       0.5861            0.5283            0.5861        0.7758        5.5036\n",
      "     37        \u001b[36m0.4772\u001b[0m       0.6322            0.6020            0.6322        0.7440        5.5112\n",
      "     38        \u001b[36m0.4706\u001b[0m       0.5955            0.5955            0.5955        0.8567        5.5740\n",
      "     39        \u001b[36m0.4626\u001b[0m       0.6347            0.6212            0.6347        0.7327        5.6410\n",
      "     40        \u001b[36m0.4564\u001b[0m       0.6176            0.5865            0.6176        0.7797        5.6026\n",
      "     41        \u001b[36m0.4558\u001b[0m       0.6306            0.5912            0.6306        0.8187        5.5368\n",
      "     42        \u001b[36m0.4410\u001b[0m       0.6314            0.6104            0.6314        0.7512        5.4994\n",
      "     43        \u001b[36m0.4307\u001b[0m       0.5939            0.5737            0.5939        0.8311        5.4936\n",
      "     44        0.4407       0.5927            0.4548            0.5927        1.2314        5.4812\n",
      "     45        \u001b[36m0.4133\u001b[0m       0.6331            0.6217            0.6331        0.7643        5.5891\n",
      "     46        \u001b[36m0.4025\u001b[0m       0.6265            0.6155            0.6265        0.7849        5.5055\n",
      "     47        \u001b[36m0.3933\u001b[0m       0.6216            0.5657            0.6216        0.8698        5.5278\n",
      "     48        \u001b[36m0.3851\u001b[0m       0.6322            0.6111            0.6322        0.8497        5.5363\n",
      "     49        \u001b[36m0.3537\u001b[0m       0.6061            0.6012            0.6061        0.9903        5.5702\n",
      "     50        0.3573       0.6008            0.5993            0.6008        0.9439        5.5670\n",
      "     51        0.3635       0.6069            0.5844            0.6069        0.9151        5.5430\n",
      "     52        0.3603       0.6363            0.6135            0.6363        0.9166        5.5020\n",
      "     53        \u001b[36m0.3328\u001b[0m       0.6143            0.5908            0.6143        0.9665        5.5688\n",
      "     54        \u001b[36m0.3175\u001b[0m       0.6327            0.6108            0.6327        0.9751        5.6765\n",
      "     55        \u001b[36m0.2881\u001b[0m       0.6208            0.6119            0.6208        1.0800        5.5655\n",
      "     56        0.2892       0.6367            0.6329            0.6367        1.0208        5.6182\n",
      "     57        0.2948       0.6298            0.5762            0.6298        1.2009        5.5556\n",
      "     58        \u001b[36m0.2806\u001b[0m       0.6196            0.6084            0.6196        1.0356        5.5080\n",
      "     59        \u001b[36m0.2557\u001b[0m       0.6265            0.6000            0.6265        1.0391        5.4863\n",
      "     60        \u001b[36m0.2371\u001b[0m       0.6339            0.6139            0.6339        1.1311        5.5283\n",
      "     61        \u001b[36m0.2314\u001b[0m       0.6371            0.6161            0.6371        1.0863        5.5591\n",
      "     62        \u001b[36m0.2273\u001b[0m       0.6331            0.6117            0.6331        1.1627        5.5354\n",
      "     63        \u001b[36m0.2243\u001b[0m       0.6224            0.6124            0.6224        1.0881        5.5049\n",
      "     64        \u001b[36m0.2092\u001b[0m       0.6216            0.6109            0.6216        1.2617        5.5373\n",
      "     65        0.2110       0.6196            0.5915            0.6196        1.3781        5.5728\n",
      "     66        \u001b[36m0.1981\u001b[0m       0.6208            0.6155            0.6208        1.2060        5.5362\n",
      "     67        \u001b[36m0.1854\u001b[0m       0.6457            0.6340            0.6457        1.1675        5.5300\n",
      "     68        \u001b[36m0.1738\u001b[0m       0.6110            0.5460            0.6110        1.4761        5.5113\n",
      "     69        \u001b[36m0.1589\u001b[0m       0.6082            0.5942            0.6082        1.3804        5.4747\n",
      "     70        \u001b[36m0.1532\u001b[0m       0.6233            0.6030            0.6233        1.3806        5.5217\n",
      "     71        0.1566       0.6184            0.6135            0.6184        1.3087        5.4815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        0.1643       0.6282            0.6055            0.6282        1.1650        5.5241\n",
      "     73        0.1602       0.6355            0.6221            0.6355        1.3177        5.5632\n",
      "     74        \u001b[36m0.1326\u001b[0m       0.6163            0.5969            0.6163        1.5052        5.5383\n",
      "     75        0.1437       0.6257            0.6169            0.6257        1.3436        5.4903\n",
      "     76        0.1329       0.6237            0.6208            0.6237        1.4410        5.5320\n",
      "     77        \u001b[36m0.1290\u001b[0m       0.6269            0.6164            0.6269        1.3857        5.5727\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n",
      "IntegratedGradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4801]), 'p01': tensor([2.5327]), 'p05': tensor([2.8099]), 'p25': tensor([3.0939]), 'p50': tensor([3.1463]), 'p75': tensor([3.1873]), 'p95': tensor([3.4509]), 'p99': tensor([3.7470]), 'max': tensor([5.1939]), 'mean': tensor([3.1396]), 'std': tensor([0.1962])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6955\u001b[0m       \u001b[32m0.6229\u001b[0m            \u001b[35m0.5822\u001b[0m            \u001b[31m0.6229\u001b[0m        \u001b[94m0.6493\u001b[0m     +  5.4979\n",
      "      2        \u001b[36m0.6406\u001b[0m       \u001b[32m0.6359\u001b[0m            \u001b[35m0.5937\u001b[0m            \u001b[31m0.6359\u001b[0m        \u001b[94m0.6358\u001b[0m     +  5.6372\n",
      "      3        \u001b[36m0.6385\u001b[0m       0.6053            \u001b[35m0.5997\u001b[0m            0.6053        0.6538     +  5.5458\n",
      "      4        \u001b[36m0.6244\u001b[0m       0.6163            \u001b[35m0.6129\u001b[0m            0.6163        \u001b[94m0.6353\u001b[0m     +  5.6181\n",
      "      5        \u001b[36m0.6211\u001b[0m       0.6265            0.5419            0.6265        0.6693        5.4993\n",
      "      6        \u001b[36m0.6160\u001b[0m       \u001b[32m0.6437\u001b[0m            0.5663            \u001b[31m0.6437\u001b[0m        0.6436        5.5286\n",
      "      7        \u001b[36m0.6151\u001b[0m       0.6310            0.5842            0.6310        \u001b[94m0.6351\u001b[0m        5.4090\n",
      "      8        \u001b[36m0.6120\u001b[0m       \u001b[32m0.6612\u001b[0m            \u001b[35m0.6224\u001b[0m            \u001b[31m0.6612\u001b[0m        \u001b[94m0.6348\u001b[0m     +  5.5994\n",
      "      9        \u001b[36m0.5985\u001b[0m       0.5955            0.4210            0.5955        0.8148        5.5306\n",
      "     10        0.6072       0.5690            0.5644            0.5690        0.6896        5.5263\n",
      "     11        0.6037       0.6290            \u001b[35m0.6258\u001b[0m            0.6290        0.6443     +  5.5265\n",
      "     12        \u001b[36m0.5945\u001b[0m       0.6290            0.6218            0.6290        0.6355        5.5674\n",
      "     13        0.5964       0.6469            \u001b[35m0.6290\u001b[0m            0.6469        0.6560     +  5.5307\n",
      "     14        \u001b[36m0.5910\u001b[0m       0.5931            0.5904            0.5931        0.6679        5.6079\n",
      "     15        \u001b[36m0.5834\u001b[0m       0.6396            0.5638            0.6396        0.6573        5.5428\n",
      "     16        0.5837       0.5722            0.5722            0.5722        0.7224        5.5191\n",
      "     17        \u001b[36m0.5753\u001b[0m       0.6298            0.5202            0.6298        0.7433        5.4915\n",
      "     18        \u001b[36m0.5681\u001b[0m       0.6318            \u001b[35m0.6290\u001b[0m            0.6318        0.6534     +  5.5266\n",
      "     19        0.5779       0.5955            0.5955            0.5955        0.6839        5.5262\n",
      "     20        0.5690       0.6392            0.6275            0.6392        0.6521        5.6041\n",
      "     21        \u001b[36m0.5588\u001b[0m       0.6531            0.6063            0.6531        0.6622        5.5329\n",
      "     22        \u001b[36m0.5584\u001b[0m       0.6498            0.5920            0.6498        0.6702        5.5384\n",
      "     23        \u001b[36m0.5502\u001b[0m       0.6502            0.6186            0.6502        0.7231        5.6784\n",
      "     24        \u001b[36m0.5453\u001b[0m       0.6302            0.5892            0.6302        0.7741        5.5675\n",
      "     25        \u001b[36m0.5419\u001b[0m       0.6531            \u001b[35m0.6349\u001b[0m            0.6531        0.6441     +  5.5023\n",
      "     26        \u001b[36m0.5358\u001b[0m       \u001b[32m0.6657\u001b[0m            0.6330            \u001b[31m0.6657\u001b[0m        0.6549        5.5897\n",
      "     27        \u001b[36m0.5284\u001b[0m       0.6314            0.6232            0.6314        0.6780        5.5753\n",
      "     28        0.5286       0.6608            \u001b[35m0.6350\u001b[0m            0.6608        0.6822     +  5.5571\n",
      "     29        \u001b[36m0.5164\u001b[0m       0.6310            0.6143            0.6310        0.6909        5.4936\n",
      "     30        \u001b[36m0.5064\u001b[0m       0.6322            0.5892            0.6322        0.7646        5.5136\n",
      "     31        0.5080       0.6106            0.6104            0.6106        0.7242        5.5036\n",
      "     32        \u001b[36m0.4958\u001b[0m       0.6420            0.6325            0.6420        0.7005        5.5157\n",
      "     33        \u001b[36m0.4952\u001b[0m       0.6176            0.5817            0.6176        0.7370        5.5838\n",
      "     34        \u001b[36m0.4884\u001b[0m       0.6355            0.6322            0.6355        0.7424        5.5317\n",
      "     35        \u001b[36m0.4760\u001b[0m       0.6437            0.6072            0.6437        0.7428        5.5659\n",
      "     36        \u001b[36m0.4644\u001b[0m       0.6294            0.5742            0.6294        0.7515        5.5058\n",
      "     37        0.4658       0.6265            0.5852            0.6265        0.7352        5.5986\n",
      "     38        \u001b[36m0.4415\u001b[0m       0.6298            0.5795            0.6298        0.9103        5.5432\n",
      "     39        \u001b[36m0.4343\u001b[0m       0.6127            0.5265            0.6127        0.9557        5.6143\n",
      "     40        0.4358       0.6188            0.6092            0.6188        0.7451        5.4912\n",
      "     41        \u001b[36m0.4109\u001b[0m       0.6061            0.5979            0.6061        0.8187        5.4583\n",
      "     42        \u001b[36m0.4013\u001b[0m       0.6314            0.6131            0.6314        0.8353        5.4624\n",
      "     43        0.4016       0.6245            0.6030            0.6245        0.8835        5.4783\n",
      "     44        \u001b[36m0.3873\u001b[0m       0.6339            0.6086            0.6339        0.8607        5.5828\n",
      "     45        \u001b[36m0.3597\u001b[0m       0.5976            0.5811            0.5976        0.8462        5.5388\n",
      "     46        \u001b[36m0.3587\u001b[0m       0.6310            0.6200            0.6310        0.8624        5.5328\n",
      "     47        \u001b[36m0.3486\u001b[0m       0.6233            0.6131            0.6233        0.8526        5.5299\n",
      "     48        \u001b[36m0.3374\u001b[0m       0.5890            0.5884            0.5890        1.0247        5.5311\n",
      "     49        \u001b[36m0.3266\u001b[0m       0.6265            0.6244            0.6265        0.8812        5.5435\n",
      "     50        \u001b[36m0.3079\u001b[0m       0.6318            0.6202            0.6318        0.9319        5.5679\n",
      "     51        0.3089       0.6237            0.6052            0.6237        0.9619        5.5336\n",
      "     52        \u001b[36m0.2779\u001b[0m       0.6090            0.5873            0.6090        1.0334        5.5883\n",
      "     53        \u001b[36m0.2692\u001b[0m       0.6465            0.6340            0.6465        0.9615        5.5623\n",
      "     54        0.2701       0.6318            0.6223            0.6318        1.1059        5.6102\n",
      "     55        0.2937       0.6241            0.5966            0.6241        1.0190        5.4765\n",
      "     56        \u001b[36m0.2628\u001b[0m       0.6408            0.6315            0.6408        1.0186        5.5116\n",
      "     57        \u001b[36m0.2377\u001b[0m       0.6367            0.6020            0.6367        0.9834        5.4850\n",
      "     58        \u001b[36m0.2259\u001b[0m       0.6049            0.6032            0.6049        1.1974        5.5078\n",
      "     59        0.2266       0.6208            0.5979            0.6208        1.0546        5.5205\n",
      "     60        \u001b[36m0.2038\u001b[0m       0.6273            0.6215            0.6273        1.2588        5.6153\n",
      "     61        \u001b[36m0.1974\u001b[0m       0.6176            0.5738            0.6176        1.2121        5.5447\n",
      "     62        0.2004       0.6110            0.6003            0.6110        1.1995        5.5460\n",
      "     63        \u001b[36m0.1772\u001b[0m       0.6049            0.5990            0.6049        1.2448        5.5207\n",
      "     64        0.1774       0.6269            0.6229            0.6269        1.2127        5.5126\n",
      "     65        \u001b[36m0.1721\u001b[0m       0.6465            \u001b[35m0.6384\u001b[0m            0.6465        1.1392     +  5.6158\n",
      "     66        \u001b[36m0.1647\u001b[0m       0.6486            0.6287            0.6486        1.3478        5.4768\n",
      "     67        \u001b[36m0.1528\u001b[0m       0.6180            0.6137            0.6180        1.3493        5.6273\n",
      "     68        \u001b[36m0.1497\u001b[0m       0.6327            0.6199            0.6327        1.4277        5.5970\n",
      "     69        \u001b[36m0.1350\u001b[0m       0.6229            0.6136            0.6229        1.4699        5.5415\n",
      "     70        0.1472       0.6208            0.6119            0.6208        1.2093        5.5311\n",
      "     71        \u001b[36m0.1345\u001b[0m       0.6167            0.6025            0.6167        1.4102        5.5031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        0.1369       0.6290            0.6154            0.6290        1.4555        5.6035\n",
      "     73        0.1384       0.6212            0.6069            0.6212        1.3091        5.5261\n",
      "     74        \u001b[36m0.1183\u001b[0m       0.6102            0.5905            0.6102        1.4992        5.5391\n",
      "     75        0.1221       0.6363            0.6148            0.6363        1.3575        5.5537\n",
      "     76        \u001b[36m0.1091\u001b[0m       0.6086            0.5998            0.6086        1.6221        5.4990\n",
      "     77        \u001b[36m0.1069\u001b[0m       0.6384            0.6068            0.6384        1.4909        5.4618\n",
      "     78        0.1108       0.6127            0.5978            0.6127        1.5647        5.5493\n",
      "     79        0.1131       0.6306            0.6159            0.6306        1.3685        5.5965\n",
      "     80        \u001b[36m0.1014\u001b[0m       0.6371            0.6169            0.6371        1.4956        5.5357\n",
      "     81        0.1019       0.6310            0.5808            0.6310        1.6142        5.5442\n",
      "     82        0.1026       0.6416            0.6236            0.6416        1.5269        5.5372\n",
      "     83        \u001b[36m0.1000\u001b[0m       0.6004            0.5933            0.6004        1.5516        5.4949\n",
      "     84        \u001b[36m0.0912\u001b[0m       0.6212            0.6000            0.6212        1.5986        5.5122\n",
      "     85        \u001b[36m0.0880\u001b[0m       0.6257            0.6168            0.6257        1.6048        5.5191\n",
      "     86        0.0893       0.6265            0.6105            0.6265        1.4758        5.5090\n",
      "     87        \u001b[36m0.0781\u001b[0m       0.6249            0.5964            0.6249        1.7346        5.5570\n",
      "     88        \u001b[36m0.0718\u001b[0m       0.6114            0.6114            0.6114        2.0828        5.6074\n",
      "     89        0.0826       0.6000            0.5971            0.6000        1.7363        5.5567\n",
      "     90        0.0766       0.6114            0.5916            0.6114        1.7348        5.5356\n",
      "     91        0.0776       0.6090            0.5951            0.6090        1.7350        5.5153\n",
      "     92        0.0765       0.6318            0.6184            0.6318        1.5646        5.5717\n",
      "     93        \u001b[36m0.0649\u001b[0m       0.6282            0.6221            0.6282        1.9097        5.5148\n",
      "     94        0.0689       0.6278            0.6160            0.6278        1.8668        5.5848\n",
      "     95        0.0903       0.5829            0.5796            0.5829        1.7753        5.5443\n",
      "     96        0.0679       0.6212            0.6106            0.6212        1.7675        5.5344\n",
      "     97        0.0664       0.6163            0.6078            0.6163        1.8159        5.5507\n",
      "     98        0.0675       0.6212            0.6124            0.6212        1.8457        5.5644\n",
      "     99        0.0699       0.6000            0.5969            0.6000        1.8818        5.5081\n",
      "    100        \u001b[36m0.0393\u001b[0m       0.6180            0.6028            0.6180        2.0346        5.5682\n",
      "    101        \u001b[36m0.0308\u001b[0m       0.6229            0.6091            0.6229        2.1679        5.5159\n",
      "    102        \u001b[36m0.0242\u001b[0m       0.6110            0.6018            0.6110        2.3388        5.5622\n",
      "    103        0.0250       0.6135            0.6056            0.6135        2.2450        5.6676\n",
      "    104        \u001b[36m0.0240\u001b[0m       0.6102            0.6006            0.6102        2.2776        5.5592\n",
      "    105        \u001b[36m0.0204\u001b[0m       0.6257            0.6098            0.6257        2.2238        5.5302\n",
      "    106        \u001b[36m0.0176\u001b[0m       0.6167            0.6023            0.6167        2.4503        5.5312\n",
      "    107        \u001b[36m0.0158\u001b[0m       0.6184            0.6105            0.6184        2.6200        5.5862\n",
      "    108        0.0202       0.6261            0.6159            0.6261        2.2613        5.5836\n",
      "    109        \u001b[36m0.0143\u001b[0m       0.6302            0.6169            0.6302        2.5583        5.5299\n",
      "    110        0.0201       0.6114            0.6051            0.6114        2.5005        5.5392\n",
      "    111        0.0166       0.6110            0.6026            0.6110        2.5513        5.5422\n",
      "    112        \u001b[36m0.0138\u001b[0m       0.6273            0.6061            0.6273        2.6706        5.5035\n",
      "    113        0.0181       0.6159            0.6023            0.6159        2.4159        5.4595\n",
      "    114        \u001b[36m0.0126\u001b[0m       0.6224            0.6100            0.6224        2.7192        5.6111\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4599]), 'p01': tensor([2.5298]), 'p05': tensor([2.8079]), 'p25': tensor([3.0937]), 'p50': tensor([3.1462]), 'p75': tensor([3.1873]), 'p95': tensor([3.4512]), 'p99': tensor([3.7476]), 'max': tensor([5.2849]), 'mean': tensor([3.1394]), 'std': tensor([0.1971])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7041\u001b[0m       \u001b[32m0.6249\u001b[0m            \u001b[35m0.5512\u001b[0m            \u001b[31m0.6249\u001b[0m        \u001b[94m0.6497\u001b[0m     +  5.4869\n",
      "      2        \u001b[36m0.6469\u001b[0m       0.6167            \u001b[35m0.6131\u001b[0m            0.6167        0.6507     +  5.5526\n",
      "      3        \u001b[36m0.6358\u001b[0m       \u001b[32m0.6302\u001b[0m            0.5402            \u001b[31m0.6302\u001b[0m        0.7111        5.5999\n",
      "      4        \u001b[36m0.6332\u001b[0m       \u001b[32m0.6355\u001b[0m            0.5649            \u001b[31m0.6355\u001b[0m        0.6969        5.5695\n",
      "      5        \u001b[36m0.6309\u001b[0m       \u001b[32m0.6371\u001b[0m            0.5855            \u001b[31m0.6371\u001b[0m        \u001b[94m0.6314\u001b[0m        5.6273\n",
      "      6        \u001b[36m0.6174\u001b[0m       0.6347            0.6035            0.6347        0.6367        5.5519\n",
      "      7        \u001b[36m0.6122\u001b[0m       \u001b[32m0.6412\u001b[0m            0.5763            \u001b[31m0.6412\u001b[0m        \u001b[94m0.6250\u001b[0m        5.5236\n",
      "      8        \u001b[36m0.6116\u001b[0m       0.6086            0.6084            0.6086        0.6557        5.5427\n",
      "      9        \u001b[36m0.6080\u001b[0m       0.6253            0.6031            0.6253        0.6590        5.6701\n",
      "     10        0.6088       0.6171            0.5000            0.6171        0.7659        5.5866\n",
      "     11        \u001b[36m0.6062\u001b[0m       \u001b[32m0.6616\u001b[0m            \u001b[35m0.6249\u001b[0m            \u001b[31m0.6616\u001b[0m        \u001b[94m0.6181\u001b[0m     +  5.7317\n",
      "     12        \u001b[36m0.6007\u001b[0m       0.6269            0.5270            0.6269        0.6751        5.5533\n",
      "     13        0.6017       0.6290            0.6217            0.6290        0.6450        5.5201\n",
      "     14        \u001b[36m0.5948\u001b[0m       0.6061            0.5809            0.6061        0.7553        5.5258\n",
      "     15        \u001b[36m0.5920\u001b[0m       0.6441            \u001b[35m0.6336\u001b[0m            0.6441        0.6366     +  5.5598\n",
      "     16        \u001b[36m0.5873\u001b[0m       0.6408            0.5626            0.6408        0.6389        5.4944\n",
      "     17        \u001b[36m0.5781\u001b[0m       0.6363            0.5832            0.6363        0.7363        5.5600\n",
      "     18        0.5823       0.6335            0.6300            0.6335        0.6930        5.5222\n",
      "     19        0.5783       0.6367            0.6307            0.6367        0.6578        5.5060\n",
      "     20        \u001b[36m0.5705\u001b[0m       0.6441            \u001b[35m0.6368\u001b[0m            0.6441        0.6318     +  5.5319\n",
      "     21        0.5741       0.6090            0.6037            0.6090        0.6820        5.5381\n",
      "     22        \u001b[36m0.5657\u001b[0m       0.6416            \u001b[35m0.6370\u001b[0m            0.6416        0.6326     +  5.5445\n",
      "     23        \u001b[36m0.5610\u001b[0m       0.6184            0.6132            0.6184        0.7306        5.5105\n",
      "     24        0.5683       0.5780            0.5722            0.5780        0.8535        5.5351\n",
      "     25        \u001b[36m0.5599\u001b[0m       0.6453            \u001b[35m0.6437\u001b[0m            0.6453        0.6403     +  5.5609\n",
      "     26        \u001b[36m0.5584\u001b[0m       0.6465            0.6243            0.6465        0.6306        5.5535\n",
      "     27        \u001b[36m0.5504\u001b[0m       0.6535            0.6377            0.6535        0.6395        5.5524\n",
      "     28        \u001b[36m0.5465\u001b[0m       0.6257            0.6142            0.6257        0.6745        5.5384\n",
      "     29        \u001b[36m0.5416\u001b[0m       0.5824            0.5675            0.5824        0.7144        5.5077\n",
      "     30        \u001b[36m0.5389\u001b[0m       0.6506            0.6326            0.6506        0.6608        5.5092\n",
      "     31        \u001b[36m0.5265\u001b[0m       0.6290            0.6278            0.6290        0.6844        5.5387\n",
      "     32        \u001b[36m0.5240\u001b[0m       0.6008            0.5842            0.6008        0.7034        5.6330\n",
      "     33        \u001b[36m0.5128\u001b[0m       0.6580            \u001b[35m0.6442\u001b[0m            0.6580        0.6898     +  5.4888\n",
      "     34        0.5208       0.5902            0.5902            0.5902        0.7436        5.5038\n",
      "     35        \u001b[36m0.5072\u001b[0m       0.6376            0.6287            0.6376        0.7098        5.5584\n",
      "     36        \u001b[36m0.4951\u001b[0m       0.6322            0.6205            0.6322        0.7218        5.6170\n",
      "     37        \u001b[36m0.4858\u001b[0m       0.6073            0.5684            0.6073        0.7048        5.5312\n",
      "     38        0.4933       0.6498            0.6343            0.6498        0.6792        5.5650\n",
      "     39        0.5144       0.6233            0.5844            0.6233        0.8273        5.5359\n",
      "     40        0.4905       0.6482            0.6436            0.6482        0.7125        5.5450\n",
      "     41        \u001b[36m0.4711\u001b[0m       0.6420            0.6272            0.6420        0.7155        5.5152\n",
      "     42        \u001b[36m0.4540\u001b[0m       0.6306            0.5989            0.6306        0.6981        5.5256\n",
      "     43        \u001b[36m0.4427\u001b[0m       0.6441            0.6323            0.6441        0.7170        5.5547\n",
      "     44        0.4589       0.6314            0.6110            0.6314        0.6963        5.5983\n",
      "     45        \u001b[36m0.4228\u001b[0m       0.6290            0.6103            0.6290        0.7694        5.5160\n",
      "     46        \u001b[36m0.4027\u001b[0m       0.6265            0.6068            0.6265        0.8132        5.4827\n",
      "     47        \u001b[36m0.3958\u001b[0m       0.6082            0.6071            0.6082        0.8528        5.6103\n",
      "     48        \u001b[36m0.3864\u001b[0m       0.6567            0.6357            0.6567        0.7977        5.5208\n",
      "     49        \u001b[36m0.3707\u001b[0m       0.5980            0.5837            0.5980        0.8697        5.5407\n",
      "     50        0.3732       0.6359            0.6009            0.6359        0.9155        5.5197\n",
      "     51        \u001b[36m0.3500\u001b[0m       0.6290            0.6040            0.6290        0.9571        5.6077\n",
      "     52        \u001b[36m0.3363\u001b[0m       0.6237            0.6138            0.6237        0.8594        5.5555\n",
      "     53        \u001b[36m0.3169\u001b[0m       0.6184            0.6170            0.6184        0.9460        5.4951\n",
      "     54        0.3203       0.6343            0.6111            0.6343        0.8657        5.6309\n",
      "     55        \u001b[36m0.3056\u001b[0m       0.6176            0.6014            0.6176        0.9487        5.6093\n",
      "     56        \u001b[36m0.2877\u001b[0m       0.6127            0.6000            0.6127        0.9193        5.5219\n",
      "     57        \u001b[36m0.2644\u001b[0m       0.6510            0.6311            0.6510        0.9996        5.4760\n",
      "     58        0.2779       0.6306            0.6161            0.6306        0.9916        5.4849\n",
      "     59        \u001b[36m0.2615\u001b[0m       0.6212            0.6135            0.6212        1.0632        5.5507\n",
      "     60        \u001b[36m0.2481\u001b[0m       0.5959            0.5926            0.5959        1.0412        5.5840\n",
      "     61        \u001b[36m0.2306\u001b[0m       0.6155            0.6003            0.6155        1.1366        5.5227\n",
      "     62        \u001b[36m0.2271\u001b[0m       0.6380            0.6057            0.6380        1.1304        5.5466\n",
      "     63        \u001b[36m0.2245\u001b[0m       0.5829            0.5611            0.5829        1.2041        5.5603\n",
      "     64        \u001b[36m0.2041\u001b[0m       0.6155            0.5933            0.6155        1.1498        5.5582\n",
      "     65        \u001b[36m0.2032\u001b[0m       0.6265            0.6114            0.6265        1.1585        5.6694\n",
      "     66        \u001b[36m0.1951\u001b[0m       0.6049            0.6045            0.6049        1.1511        5.5945\n",
      "     67        0.2033       0.6269            0.6166            0.6269        1.0985        5.6311\n",
      "     68        \u001b[36m0.1848\u001b[0m       0.6143            0.5910            0.6143        1.2302        5.6248\n",
      "     69        \u001b[36m0.1700\u001b[0m       0.6216            0.6135            0.6216        1.2699        5.5427\n",
      "     70        \u001b[36m0.1570\u001b[0m       0.6241            0.6022            0.6241        1.3091        5.5883\n",
      "     71        \u001b[36m0.1534\u001b[0m       0.5943            0.5928            0.5943        1.3290        5.5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.1482\u001b[0m       0.6139            0.6010            0.6139        1.2813        5.5296\n",
      "     73        \u001b[36m0.1427\u001b[0m       0.6306            0.6114            0.6306        1.3038        5.6204\n",
      "     74        \u001b[36m0.1330\u001b[0m       0.6139            0.6046            0.6139        1.4294        5.4999\n",
      "     75        \u001b[36m0.1294\u001b[0m       0.6094            0.5922            0.6094        1.3096        5.5461\n",
      "     76        \u001b[36m0.1272\u001b[0m       0.6057            0.5931            0.6057        1.4476        5.5493\n",
      "     77        \u001b[36m0.1247\u001b[0m       0.6388            0.6166            0.6388        1.3257        5.5410\n",
      "     78        \u001b[36m0.1130\u001b[0m       0.6237            0.6032            0.6237        1.5460        5.5244\n",
      "     79        0.1174       0.6220            0.6064            0.6220        1.3747        5.4891\n",
      "     80        0.1155       0.6167            0.5861            0.6167        1.3113        5.5016\n",
      "     81        \u001b[36m0.1075\u001b[0m       0.6118            0.5990            0.6118        1.4126        5.5625\n",
      "     82        \u001b[36m0.1019\u001b[0m       0.6188            0.6073            0.6188        1.4913        5.6045\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4945]), 'p01': tensor([2.5289]), 'p05': tensor([2.8081]), 'p25': tensor([3.0940]), 'p50': tensor([3.1465]), 'p75': tensor([3.1875]), 'p95': tensor([3.4523]), 'p99': tensor([3.7478]), 'max': tensor([5.2376]), 'mean': tensor([3.1398]), 'std': tensor([0.1972])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7006\u001b[0m       \u001b[32m0.6135\u001b[0m            \u001b[35m0.5587\u001b[0m            \u001b[31m0.6135\u001b[0m        \u001b[94m0.6596\u001b[0m     +  5.5998\n",
      "      2        \u001b[36m0.6462\u001b[0m       \u001b[32m0.6180\u001b[0m            \u001b[35m0.6135\u001b[0m            \u001b[31m0.6180\u001b[0m        \u001b[94m0.6474\u001b[0m     +  5.5374\n",
      "      3        \u001b[36m0.6339\u001b[0m       0.6139            0.4925            0.6139        0.6518        5.5630\n",
      "      4        \u001b[36m0.6325\u001b[0m       \u001b[32m0.6355\u001b[0m            \u001b[35m0.6242\u001b[0m            \u001b[31m0.6355\u001b[0m        \u001b[94m0.6355\u001b[0m     +  5.6163\n",
      "      5        \u001b[36m0.6213\u001b[0m       0.6188            0.6123            0.6188        0.6687        5.4819\n",
      "      6        \u001b[36m0.6174\u001b[0m       \u001b[32m0.6612\u001b[0m            \u001b[35m0.6371\u001b[0m            \u001b[31m0.6612\u001b[0m        \u001b[94m0.6207\u001b[0m     +  5.5683\n",
      "      7        \u001b[36m0.6115\u001b[0m       0.6245            0.5866            0.6245        0.6373        5.5734\n",
      "      8        \u001b[36m0.6102\u001b[0m       0.5792            0.5731            0.5792        0.7155        5.5375\n",
      "      9        \u001b[36m0.6021\u001b[0m       0.6543            0.6169            0.6543        0.6253        5.5253\n",
      "     10        \u001b[36m0.5947\u001b[0m       0.6473            0.6358            0.6473        0.6306        5.6235\n",
      "     11        \u001b[36m0.5947\u001b[0m       \u001b[32m0.6620\u001b[0m            0.6277            \u001b[31m0.6620\u001b[0m        \u001b[94m0.6144\u001b[0m        5.6465\n",
      "     12        0.5955       0.6380            0.6261            0.6380        0.6269        5.5296\n",
      "     13        \u001b[36m0.5896\u001b[0m       0.6384            0.5737            0.6384        0.6392        5.4984\n",
      "     14        \u001b[36m0.5870\u001b[0m       0.6380            0.5608            0.6380        0.7012        5.5910\n",
      "     15        \u001b[36m0.5790\u001b[0m       0.6416            0.6291            0.6416        0.6513        5.6189\n",
      "     16        0.5792       0.6408            0.5740            0.6408        0.6763        5.4974\n",
      "     17        \u001b[36m0.5719\u001b[0m       0.5282            0.5239            0.5282        0.7341        5.6528\n",
      "     18        \u001b[36m0.5674\u001b[0m       0.6086            0.6084            0.6086        0.7129        5.5688\n",
      "     19        0.5680       0.6118            0.6114            0.6118        0.6775        5.6209\n",
      "     20        \u001b[36m0.5639\u001b[0m       0.5633            0.5573            0.5633        0.7251        5.5801\n",
      "     21        \u001b[36m0.5600\u001b[0m       0.6608            \u001b[35m0.6497\u001b[0m            0.6608        0.6198     +  5.5108\n",
      "     22        \u001b[36m0.5495\u001b[0m       0.6388            0.6060            0.6388        0.6958        5.5692\n",
      "     23        \u001b[36m0.5476\u001b[0m       0.6143            0.6142            0.6143        0.6909        5.5764\n",
      "     24        \u001b[36m0.5428\u001b[0m       0.6367            0.6316            0.6367        0.6792        5.5668\n",
      "     25        \u001b[36m0.5354\u001b[0m       0.6339            0.6272            0.6339        0.6583        5.5214\n",
      "     26        \u001b[36m0.5331\u001b[0m       0.6514            0.6204            0.6514        0.6681        5.5901\n",
      "     27        \u001b[36m0.5313\u001b[0m       0.6237            0.5913            0.6237        0.6796        5.6027\n",
      "     28        \u001b[36m0.5152\u001b[0m       0.6253            0.5285            0.6253        0.7774        5.5523\n",
      "     29        0.5196       0.6180            0.4942            0.6180        0.9019        5.5463\n",
      "     30        0.5164       0.6441            0.6324            0.6441        0.6776        5.4843\n",
      "     31        \u001b[36m0.5129\u001b[0m       0.6547            0.6284            0.6547        0.6350        5.6234\n",
      "     32        \u001b[36m0.4960\u001b[0m       0.6445            0.6271            0.6445        0.7619        5.5309\n",
      "     33        \u001b[36m0.4927\u001b[0m       0.6229            0.6196            0.6229        0.7004        5.5972\n",
      "     34        \u001b[36m0.4853\u001b[0m       0.6294            0.6109            0.6294        0.7343        5.6348\n",
      "     35        \u001b[36m0.4769\u001b[0m       0.6445            0.5975            0.6445        0.7498        5.6622\n",
      "     36        \u001b[36m0.4685\u001b[0m       0.6224            0.6197            0.6224        0.7516        5.5434\n",
      "     37        \u001b[36m0.4589\u001b[0m       0.6559            0.6252            0.6559        0.7240        5.6585\n",
      "     38        \u001b[36m0.4553\u001b[0m       0.6127            0.6081            0.6127        0.7419        5.5900\n",
      "     39        \u001b[36m0.4411\u001b[0m       0.6363            0.6245            0.6363        0.7567        5.5368\n",
      "     40        \u001b[36m0.4378\u001b[0m       0.6412            0.6260            0.6412        0.7515        5.4766\n",
      "     41        \u001b[36m0.4163\u001b[0m       0.6290            0.6181            0.6290        0.7919        5.5894\n",
      "     42        \u001b[36m0.4018\u001b[0m       0.6396            0.6164            0.6396        0.7724        5.5863\n",
      "     43        \u001b[36m0.3930\u001b[0m       0.6204            0.5972            0.6204        0.8627        5.4924\n",
      "     44        \u001b[36m0.3879\u001b[0m       0.6453            0.6137            0.6453        0.8222        5.5094\n",
      "     45        \u001b[36m0.3634\u001b[0m       0.6053            0.5965            0.6053        0.8689        5.5291\n",
      "     46        \u001b[36m0.3556\u001b[0m       0.6347            0.6194            0.6347        0.8538        5.5140\n",
      "     47        \u001b[36m0.3456\u001b[0m       0.6376            0.6285            0.6376        0.8546        5.5468\n",
      "     48        \u001b[36m0.3342\u001b[0m       0.6461            0.6105            0.6461        0.9359        5.5373\n",
      "     49        \u001b[36m0.3256\u001b[0m       0.6371            0.6253            0.6371        0.9538        5.5319\n",
      "     50        \u001b[36m0.3224\u001b[0m       0.5792            0.5574            0.5792        0.9683        5.6160\n",
      "     51        \u001b[36m0.3026\u001b[0m       0.6355            0.5850            0.6355        1.2100        5.5827\n",
      "     52        \u001b[36m0.2904\u001b[0m       0.6261            0.6145            0.6261        0.9013        5.5866\n",
      "     53        \u001b[36m0.2823\u001b[0m       0.6294            0.6099            0.6294        0.9453        5.5144\n",
      "     54        \u001b[36m0.2756\u001b[0m       0.6176            0.6111            0.6176        0.9507        5.5743\n",
      "     55        \u001b[36m0.2676\u001b[0m       0.6306            0.6053            0.6306        1.0857        5.6036\n",
      "     56        \u001b[36m0.2535\u001b[0m       0.6253            0.6190            0.6253        0.9960        5.6130\n",
      "     57        \u001b[36m0.2493\u001b[0m       0.5971            0.5922            0.5971        1.0417        5.6343\n",
      "     58        \u001b[36m0.2408\u001b[0m       0.6167            0.6163            0.6167        1.1530        5.5893\n",
      "     59        \u001b[36m0.2149\u001b[0m       0.6241            0.5842            0.6241        1.3393        5.5498\n",
      "     60        0.2326       0.6363            0.6208            0.6363        1.0287        5.5222\n",
      "     61        \u001b[36m0.2022\u001b[0m       0.6078            0.6055            0.6078        1.1275        5.5353\n",
      "     62        0.2073       0.6351            0.6191            0.6351        1.0437        5.5398\n",
      "     63        \u001b[36m0.1872\u001b[0m       0.6412            0.6178            0.6412        1.1377        5.5352\n",
      "     64        0.2124       0.5882            0.5880            0.5882        1.2836        5.6024\n",
      "     65        0.1909       0.6049            0.5957            0.6049        1.2757        5.5868\n",
      "     66        \u001b[36m0.1610\u001b[0m       0.6204            0.6045            0.6204        1.2311        5.5883\n",
      "     67        \u001b[36m0.1606\u001b[0m       0.6282            0.6071            0.6282        1.2668        5.6062\n",
      "     68        \u001b[36m0.1524\u001b[0m       0.6229            0.5981            0.6229        1.3220        5.5194\n",
      "     69        \u001b[36m0.1449\u001b[0m       0.5996            0.5867            0.5996        1.4221        5.5801\n",
      "     70        \u001b[36m0.1409\u001b[0m       0.6171            0.6094            0.6171        1.2534        5.5659\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4757]), 'p01': tensor([2.5295]), 'p05': tensor([2.8071]), 'p25': tensor([3.0940]), 'p50': tensor([3.1461]), 'p75': tensor([3.1876]), 'p95': tensor([3.4514]), 'p99': tensor([3.7498]), 'max': tensor([5.2048]), 'mean': tensor([3.1395]), 'std': tensor([0.1973])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6915\u001b[0m       \u001b[32m0.6053\u001b[0m            \u001b[35m0.5262\u001b[0m            \u001b[31m0.6053\u001b[0m        \u001b[94m0.6995\u001b[0m     +  5.5254\n",
      "      2        \u001b[36m0.6406\u001b[0m       \u001b[32m0.6114\u001b[0m            \u001b[35m0.6009\u001b[0m            \u001b[31m0.6114\u001b[0m        \u001b[94m0.6772\u001b[0m     +  5.5202\n",
      "      3        \u001b[36m0.6353\u001b[0m       \u001b[32m0.6310\u001b[0m            \u001b[35m0.6049\u001b[0m            \u001b[31m0.6310\u001b[0m        \u001b[94m0.6368\u001b[0m     +  5.5420\n",
      "      4        \u001b[36m0.6304\u001b[0m       \u001b[32m0.6343\u001b[0m            \u001b[35m0.6119\u001b[0m            \u001b[31m0.6343\u001b[0m        0.6776     +  5.5978\n",
      "      5        \u001b[36m0.6283\u001b[0m       0.6167            0.6090            0.6167        0.6597        5.5674\n",
      "      6        \u001b[36m0.6201\u001b[0m       \u001b[32m0.6347\u001b[0m            \u001b[35m0.6143\u001b[0m            \u001b[31m0.6347\u001b[0m        0.6400     +  5.5095\n",
      "      7        \u001b[36m0.6121\u001b[0m       0.5841            0.4092            0.5841        0.8437        5.5913\n",
      "      8        \u001b[36m0.6098\u001b[0m       \u001b[32m0.6571\u001b[0m            \u001b[35m0.6245\u001b[0m            \u001b[31m0.6571\u001b[0m        \u001b[94m0.6199\u001b[0m     +  5.5073\n",
      "      9        \u001b[36m0.6040\u001b[0m       0.6424            \u001b[35m0.6411\u001b[0m            0.6424        0.6267     +  5.5806\n",
      "     10        \u001b[36m0.6035\u001b[0m       0.6212            0.5068            0.6212        0.7469        5.4954\n",
      "     11        \u001b[36m0.5984\u001b[0m       0.6257            0.5436            0.6257        0.6646        5.5882\n",
      "     12        \u001b[36m0.5913\u001b[0m       0.6298            0.6232            0.6298        0.6615        5.5765\n",
      "     13        \u001b[36m0.5873\u001b[0m       0.6482            0.6199            0.6482        0.6320        5.5407\n",
      "     14        \u001b[36m0.5838\u001b[0m       0.6535            0.6373            0.6535        \u001b[94m0.6198\u001b[0m        5.6184\n",
      "     15        \u001b[36m0.5790\u001b[0m       0.5816            0.5797            0.5816        0.7160        5.5221\n",
      "     16        0.5819       0.6278            0.6277            0.6278        0.6394        5.5194\n",
      "     17        0.5796       0.6400            0.6098            0.6400        0.6620        5.5358\n",
      "     18        \u001b[36m0.5775\u001b[0m       0.6327            0.6225            0.6327        0.6567        5.6122\n",
      "     19        \u001b[36m0.5666\u001b[0m       0.6343            0.6192            0.6343        0.6664        5.6746\n",
      "     20        \u001b[36m0.5663\u001b[0m       0.6396            0.6304            0.6396        0.6908        5.5246\n",
      "     21        \u001b[36m0.5574\u001b[0m       0.6220            0.6205            0.6220        0.6800        5.5950\n",
      "     22        0.5639       0.5914            0.5475            0.5914        0.7048        5.5491\n",
      "     23        \u001b[36m0.5535\u001b[0m       0.6143            0.6124            0.6143        0.7226        5.5468\n",
      "     24        \u001b[36m0.5407\u001b[0m       0.6457            0.6341            0.6457        0.6607        5.6559\n",
      "     25        \u001b[36m0.5407\u001b[0m       0.5955            0.5945            0.5955        0.7203        5.5554\n",
      "     26        0.5450       0.6502            0.6133            0.6502        0.6782        5.5821\n",
      "     27        \u001b[36m0.5370\u001b[0m       0.6371            0.5737            0.6371        0.6936        5.5863\n",
      "     28        \u001b[36m0.5291\u001b[0m       0.5910            0.4104            0.5910        1.0804        5.6247\n",
      "     29        \u001b[36m0.5188\u001b[0m       0.6049            0.4723            0.6049        0.9082        5.6426\n",
      "     30        0.5188       0.6249            0.6242            0.6249        0.7099        5.5443\n",
      "     31        \u001b[36m0.5036\u001b[0m       0.6551            \u001b[35m0.6424\u001b[0m            0.6551        0.6655     +  5.5565\n",
      "     32        \u001b[36m0.4996\u001b[0m       0.6122            0.6113            0.6122        0.6936        5.5300\n",
      "     33        \u001b[36m0.4859\u001b[0m       0.6424            0.6254            0.6424        0.7467        5.5225\n",
      "     34        \u001b[36m0.4796\u001b[0m       0.6106            0.6099            0.6106        0.7465        5.6004\n",
      "     35        \u001b[36m0.4751\u001b[0m       0.6220            0.6068            0.6220        0.7122        5.5141\n",
      "     36        0.4808       0.6086            0.6012            0.6086        0.7050        5.5738\n",
      "     37        \u001b[36m0.4652\u001b[0m       0.6400            0.6396            0.6400        0.7012        5.5440\n",
      "     38        \u001b[36m0.4482\u001b[0m       0.6416            0.6332            0.6416        0.6864        5.5577\n",
      "     39        \u001b[36m0.4386\u001b[0m       0.5049            0.5049            0.5049        1.0451        5.5746\n",
      "     40        \u001b[36m0.4220\u001b[0m       0.6159            0.6061            0.6159        0.7932        5.5565\n",
      "     41        \u001b[36m0.4117\u001b[0m       0.6139            0.6065            0.6139        0.8069        5.5500\n",
      "     42        0.4120       0.6335            0.6188            0.6335        0.8194        5.5669\n",
      "     43        \u001b[36m0.4001\u001b[0m       0.6167            0.6085            0.6167        0.8258        5.6601\n",
      "     44        \u001b[36m0.3838\u001b[0m       0.6433            0.6293            0.6433        0.8219        5.5378\n",
      "     45        \u001b[36m0.3746\u001b[0m       0.6302            0.6263            0.6302        0.9065        5.5682\n",
      "     46        0.3938       0.6469            0.6194            0.6469        0.8866        5.5808\n",
      "     47        \u001b[36m0.3604\u001b[0m       0.6449            0.6284            0.6449        1.0484        5.4766\n",
      "     48        \u001b[36m0.3417\u001b[0m       0.5873            0.5840            0.5873        1.0889        5.4637\n",
      "     49        \u001b[36m0.3195\u001b[0m       0.6024            0.5983            0.6024        0.9870        5.4818\n",
      "     50        \u001b[36m0.3065\u001b[0m       0.6192            0.6038            0.6192        1.0221        5.5197\n",
      "     51        \u001b[36m0.2952\u001b[0m       0.6376            0.6346            0.6376        0.9444        5.5847\n",
      "     52        \u001b[36m0.2933\u001b[0m       0.6131            0.6068            0.6131        0.9908        5.5493\n",
      "     53        \u001b[36m0.2789\u001b[0m       0.6229            0.6108            0.6229        1.0080        5.5455\n",
      "     54        \u001b[36m0.2613\u001b[0m       0.6400            0.6174            0.6400        0.9972        5.6049\n",
      "     55        \u001b[36m0.2460\u001b[0m       0.5788            0.5788            0.5788        1.2669        5.5494\n",
      "     56        \u001b[36m0.2456\u001b[0m       0.6429            0.6360            0.6429        1.0622        5.5589\n",
      "     57        \u001b[36m0.2428\u001b[0m       0.6265            0.6074            0.6265        1.0311        5.5862\n",
      "     58        \u001b[36m0.2210\u001b[0m       0.6061            0.6013            0.6061        1.1815        5.6174\n",
      "     59        \u001b[36m0.2010\u001b[0m       0.6208            0.5958            0.6208        1.1638        5.4563\n",
      "     60        0.2041       0.6188            0.6165            0.6188        1.1273        5.6027\n",
      "     61        \u001b[36m0.1952\u001b[0m       0.6184            0.6068            0.6184        1.2547        5.5341\n",
      "     62        \u001b[36m0.1911\u001b[0m       0.6257            0.6209            0.6257        1.0906        5.4952\n",
      "     63        \u001b[36m0.1715\u001b[0m       0.6388            0.6278            0.6388        1.1889        5.5767\n",
      "     64        \u001b[36m0.1674\u001b[0m       0.6122            0.6102            0.6122        1.3394        5.5625\n",
      "     65        0.1706       0.6229            0.6159            0.6229        1.2882        5.5817\n",
      "     66        \u001b[36m0.1516\u001b[0m       0.6257            0.6121            0.6257        1.3460        5.4874\n",
      "     67        0.1559       0.6269            0.6103            0.6269        1.1736        5.5084\n",
      "     68        \u001b[36m0.1446\u001b[0m       0.6122            0.6122            0.6122        1.5896        5.6038\n",
      "     69        \u001b[36m0.1357\u001b[0m       0.6278            0.6188            0.6278        1.6007        5.6097\n",
      "     70        0.1650       0.6233            0.6173            0.6233        1.3272        5.5488\n",
      "     71        \u001b[36m0.1311\u001b[0m       0.6212            0.6175            0.6212        1.3971        5.5381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.1270\u001b[0m       0.6082            0.6063            0.6082        1.5133        5.6135\n",
      "     73        \u001b[36m0.1155\u001b[0m       0.5980            0.5968            0.5980        1.6487        5.5918\n",
      "     74        0.1375       0.6322            0.6211            0.6322        1.3137        5.4883\n",
      "     75        \u001b[36m0.1098\u001b[0m       0.6143            0.6111            0.6143        1.5319        5.4919\n",
      "     76        \u001b[36m0.1023\u001b[0m       0.6269            0.6123            0.6269        1.5743        5.5766\n",
      "     77        0.1056       0.6233            0.5961            0.6233        1.6282        5.5999\n",
      "     78        \u001b[36m0.0950\u001b[0m       0.6278            0.6057            0.6278        1.6374        5.5988\n",
      "     79        0.0955       0.6433            0.6278            0.6433        1.4632        5.5448\n",
      "     80        \u001b[36m0.0907\u001b[0m       0.6147            0.6009            0.6147        1.6186        5.5645\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.5383]), 'p01': tensor([2.5298]), 'p05': tensor([2.8084]), 'p25': tensor([3.0936]), 'p50': tensor([3.1463]), 'p75': tensor([3.1878]), 'p95': tensor([3.4512]), 'p99': tensor([3.7484]), 'max': tensor([5.2319]), 'mean': tensor([3.1397]), 'std': tensor([0.1969])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7019\u001b[0m       \u001b[32m0.6155\u001b[0m            \u001b[35m0.5815\u001b[0m            \u001b[31m0.6155\u001b[0m        \u001b[94m0.6666\u001b[0m     +  5.5429\n",
      "      2        \u001b[36m0.6461\u001b[0m       0.6098            \u001b[35m0.6097\u001b[0m            0.6098        \u001b[94m0.6640\u001b[0m     +  5.6054\n",
      "      3        \u001b[36m0.6324\u001b[0m       \u001b[32m0.6380\u001b[0m            0.5984            \u001b[31m0.6380\u001b[0m        \u001b[94m0.6370\u001b[0m        5.5502\n",
      "      4        \u001b[36m0.6248\u001b[0m       0.6241            \u001b[35m0.6236\u001b[0m            0.6241        0.6408     +  5.5261\n",
      "      5        \u001b[36m0.6164\u001b[0m       \u001b[32m0.6420\u001b[0m            0.5980            \u001b[31m0.6420\u001b[0m        0.6373        5.5649\n",
      "      6        \u001b[36m0.6140\u001b[0m       \u001b[32m0.6490\u001b[0m            0.6105            \u001b[31m0.6490\u001b[0m        \u001b[94m0.6263\u001b[0m        5.5430\n",
      "      7        \u001b[36m0.6070\u001b[0m       0.6114            0.6114            0.6114        0.6634        5.5132\n",
      "      8        \u001b[36m0.5991\u001b[0m       0.6000            0.4543            0.6000        0.8501        5.4960\n",
      "      9        0.6014       0.6310            0.5540            0.6310        0.6603        5.5862\n",
      "     10        0.6011       \u001b[32m0.6514\u001b[0m            0.6208            \u001b[31m0.6514\u001b[0m        0.6367        5.5935\n",
      "     11        \u001b[36m0.5910\u001b[0m       \u001b[32m0.6612\u001b[0m            \u001b[35m0.6513\u001b[0m            \u001b[31m0.6612\u001b[0m        0.6278     +  5.6125\n",
      "     12        \u001b[36m0.5901\u001b[0m       0.5596            0.5594            0.5596        0.7063        5.5913\n",
      "     13        \u001b[36m0.5828\u001b[0m       0.5812            0.5806            0.5812        0.7020        5.5559\n",
      "     14        \u001b[36m0.5810\u001b[0m       \u001b[32m0.6657\u001b[0m            0.6383            \u001b[31m0.6657\u001b[0m        0.6408        5.5891\n",
      "     15        \u001b[36m0.5793\u001b[0m       0.5865            0.5864            0.5865        0.6782        5.5498\n",
      "     16        \u001b[36m0.5732\u001b[0m       0.6261            0.5784            0.6261        0.8073        5.5790\n",
      "     17        \u001b[36m0.5724\u001b[0m       0.6482            0.6155            0.6482        0.6521        5.5445\n",
      "     18        \u001b[36m0.5676\u001b[0m       0.6343            0.6146            0.6343        0.6459        5.4685\n",
      "     19        \u001b[36m0.5648\u001b[0m       0.6176            0.5097            0.6176        0.7683        5.5119\n",
      "     20        \u001b[36m0.5543\u001b[0m       0.6290            0.6283            0.6290        0.6565        5.6169\n",
      "     21        \u001b[36m0.5543\u001b[0m       0.6445            0.6281            0.6445        0.6783        5.5129\n",
      "     22        \u001b[36m0.5515\u001b[0m       0.6008            0.4354            0.6008        0.9999        5.5410\n",
      "     23        0.5601       0.6335            0.5867            0.6335        0.6722        5.5622\n",
      "     24        \u001b[36m0.5423\u001b[0m       0.6180            0.6168            0.6180        0.7013        5.5735\n",
      "     25        \u001b[36m0.5402\u001b[0m       0.6576            0.6308            0.6576        0.6869        5.5340\n",
      "     26        \u001b[36m0.5305\u001b[0m       0.5661            0.5588            0.5661        0.7777        5.5940\n",
      "     27        0.5327       0.6469            0.6352            0.6469        0.7017        5.5797\n",
      "     28        \u001b[36m0.5257\u001b[0m       0.6371            0.6166            0.6371        0.6784        5.5682\n",
      "     29        \u001b[36m0.5205\u001b[0m       0.6110            0.6108            0.6110        0.7627        5.6220\n",
      "     30        \u001b[36m0.5124\u001b[0m       0.6339            0.6270            0.6339        0.7086        5.5389\n",
      "     31        \u001b[36m0.5105\u001b[0m       0.6163            0.6140            0.6163        0.7795        5.5219\n",
      "     32        0.5140       0.6347            0.6323            0.6347        0.8267        5.5288\n",
      "     33        \u001b[36m0.5061\u001b[0m       0.6229            0.5732            0.6229        0.9012        5.6231\n",
      "     34        \u001b[36m0.4848\u001b[0m       0.6229            0.5442            0.6229        0.8852        5.7185\n",
      "     35        \u001b[36m0.4844\u001b[0m       0.5833            0.5820            0.5833        0.7428        5.5483\n",
      "     36        \u001b[36m0.4752\u001b[0m       0.6355            0.6061            0.6355        0.8155        5.5083\n",
      "     37        \u001b[36m0.4547\u001b[0m       0.6220            0.5525            0.6220        1.0642        5.5262\n",
      "     38        0.4575       0.6269            0.6103            0.6269        0.7695        5.6217\n",
      "     39        \u001b[36m0.4431\u001b[0m       0.5894            0.5890            0.5894        0.8371        5.5562\n",
      "     40        \u001b[36m0.4316\u001b[0m       0.6314            0.6034            0.6314        0.8450        5.5151\n",
      "     41        \u001b[36m0.4232\u001b[0m       0.6343            0.5942            0.6343        0.8102        5.5089\n",
      "     42        \u001b[36m0.4153\u001b[0m       0.6245            0.6121            0.6245        0.8318        5.5701\n",
      "     43        \u001b[36m0.4078\u001b[0m       0.6102            0.6101            0.6102        0.8688        5.4726\n",
      "     44        \u001b[36m0.3904\u001b[0m       0.6041            0.5993            0.6041        0.8278        5.5920\n",
      "     45        \u001b[36m0.3899\u001b[0m       0.6208            0.5787            0.6208        0.8278        5.5008\n",
      "     46        \u001b[36m0.3648\u001b[0m       0.6078            0.5957            0.6078        0.8549        5.5800\n",
      "     47        \u001b[36m0.3564\u001b[0m       0.5894            0.5747            0.5894        0.9506        5.6215\n",
      "     48        \u001b[36m0.3536\u001b[0m       0.6294            0.5958            0.6294        0.9210        5.5767\n",
      "     49        \u001b[36m0.3370\u001b[0m       0.5857            0.5799            0.5857        1.0120        5.5785\n",
      "     50        \u001b[36m0.3256\u001b[0m       0.5820            0.5767            0.5820        1.1023        5.5344\n",
      "     51        \u001b[36m0.3109\u001b[0m       0.6171            0.6066            0.6171        0.9580        5.5345\n",
      "     52        \u001b[36m0.3047\u001b[0m       0.6314            0.6227            0.6314        0.9502        5.5713\n",
      "     53        \u001b[36m0.2911\u001b[0m       0.6033            0.5907            0.6033        0.9859        5.6051\n",
      "     54        \u001b[36m0.2816\u001b[0m       0.5910            0.5874            0.5910        1.0498        5.6109\n",
      "     55        \u001b[36m0.2752\u001b[0m       0.6061            0.5957            0.6061        1.0180        5.5250\n",
      "     56        \u001b[36m0.2622\u001b[0m       0.6286            0.6075            0.6286        1.0786        5.5966\n",
      "     57        \u001b[36m0.2479\u001b[0m       0.6237            0.6184            0.6237        1.1437        5.5199\n",
      "     58        \u001b[36m0.2421\u001b[0m       0.6029            0.5920            0.6029        1.1087        5.5464\n",
      "     59        \u001b[36m0.2340\u001b[0m       0.6290            0.6083            0.6290        1.1674        5.5753\n",
      "     60        \u001b[36m0.2268\u001b[0m       0.6176            0.5772            0.6176        1.1815        5.5758\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n",
      "LRP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4801]), 'p01': tensor([2.5327]), 'p05': tensor([2.8099]), 'p25': tensor([3.0939]), 'p50': tensor([3.1463]), 'p75': tensor([3.1873]), 'p95': tensor([3.4509]), 'p99': tensor([3.7470]), 'max': tensor([5.1939]), 'mean': tensor([3.1396]), 'std': tensor([0.1962])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7047\u001b[0m       \u001b[32m0.6188\u001b[0m            \u001b[35m0.5658\u001b[0m            \u001b[31m0.6188\u001b[0m        \u001b[94m0.6730\u001b[0m     +  5.5170\n",
      "      2        \u001b[36m0.6469\u001b[0m       \u001b[32m0.6408\u001b[0m            \u001b[35m0.6136\u001b[0m            \u001b[31m0.6408\u001b[0m        \u001b[94m0.6592\u001b[0m     +  5.5898\n",
      "      3        \u001b[36m0.6359\u001b[0m       0.6327            0.5567            0.6327        \u001b[94m0.6348\u001b[0m        5.6285\n",
      "      4        \u001b[36m0.6311\u001b[0m       0.5673            0.5593            0.5673        0.6787        5.6820\n",
      "      5        \u001b[36m0.6302\u001b[0m       0.6339            \u001b[35m0.6139\u001b[0m            0.6339        0.6532     +  5.5761\n",
      "      6        \u001b[36m0.6210\u001b[0m       \u001b[32m0.6473\u001b[0m            0.5983            \u001b[31m0.6473\u001b[0m        \u001b[94m0.6221\u001b[0m        5.5732\n",
      "      7        \u001b[36m0.6183\u001b[0m       0.6453            0.5997            0.6453        0.6393        5.5217\n",
      "      8        \u001b[36m0.6137\u001b[0m       \u001b[32m0.6522\u001b[0m            \u001b[35m0.6289\u001b[0m            \u001b[31m0.6522\u001b[0m        0.6296     +  5.5321\n",
      "      9        \u001b[36m0.6055\u001b[0m       0.6053            0.5860            0.6053        0.6581        5.5236\n",
      "     10        \u001b[36m0.6047\u001b[0m       0.5857            0.5856            0.5857        0.6767        5.6123\n",
      "     11        \u001b[36m0.6009\u001b[0m       0.6367            0.5527            0.6367        0.6600        5.6892\n",
      "     12        \u001b[36m0.5959\u001b[0m       \u001b[32m0.6580\u001b[0m            0.6222            \u001b[31m0.6580\u001b[0m        0.6868        5.6076\n",
      "     13        \u001b[36m0.5951\u001b[0m       0.5992            0.5943            0.5992        0.6562        5.5757\n",
      "     14        \u001b[36m0.5912\u001b[0m       0.5771            0.5770            0.5771        0.7456        5.5541\n",
      "     15        0.5926       0.6482            \u001b[35m0.6454\u001b[0m            0.6482        0.6484     +  5.6449\n",
      "     16        \u001b[36m0.5818\u001b[0m       0.6441            0.6304            0.6441        0.6275        5.6189\n",
      "     17        \u001b[36m0.5811\u001b[0m       0.5735            0.5732            0.5735        0.6848        5.5168\n",
      "     18        \u001b[36m0.5771\u001b[0m       0.6453            0.6290            0.6453        0.7047        5.6113\n",
      "     19        \u001b[36m0.5716\u001b[0m       0.6441            0.6299            0.6441        0.6625        5.6443\n",
      "     20        \u001b[36m0.5644\u001b[0m       0.6314            0.6285            0.6314        0.6521        5.5996\n",
      "     21        0.5682       0.6429            0.6390            0.6429        0.6410        5.6847\n",
      "     22        0.5658       \u001b[32m0.6600\u001b[0m            \u001b[35m0.6501\u001b[0m            \u001b[31m0.6600\u001b[0m        0.6400     +  5.6292\n",
      "     23        \u001b[36m0.5551\u001b[0m       0.6261            0.6139            0.6261        0.6541        5.6923\n",
      "     24        \u001b[36m0.5504\u001b[0m       0.6518            0.6331            0.6518        0.6777        5.6175\n",
      "     25        0.5540       0.6498            0.6101            0.6498        0.6641        5.6847\n",
      "     26        \u001b[36m0.5332\u001b[0m       0.6343            0.6326            0.6343        0.6729        5.5706\n",
      "     27        \u001b[36m0.5317\u001b[0m       0.6482            0.6401            0.6482        0.6476        5.7069\n",
      "     28        \u001b[36m0.5268\u001b[0m       0.6457            0.5873            0.6457        0.7452        5.6608\n",
      "     29        \u001b[36m0.5237\u001b[0m       0.6090            0.4823            0.6090        0.8547        5.6555\n",
      "     30        0.5262       0.5800            0.5788            0.5800        0.7163        5.6135\n",
      "     31        \u001b[36m0.5152\u001b[0m       0.6473            0.6307            0.6473        0.6899        5.6253\n",
      "     32        0.5276       0.6527            0.6158            0.6527        0.7348        5.6681\n",
      "     33        \u001b[36m0.5131\u001b[0m       \u001b[32m0.6620\u001b[0m            0.6340            \u001b[31m0.6620\u001b[0m        0.6539        5.7184\n",
      "     34        \u001b[36m0.5037\u001b[0m       0.6204            0.5381            0.6204        0.8100        5.7397\n",
      "     35        \u001b[36m0.4895\u001b[0m       0.6441            0.6102            0.6441        0.7862        5.6896\n",
      "     36        \u001b[36m0.4843\u001b[0m       0.6204            0.6039            0.6204        0.7288        5.6561\n",
      "     37        \u001b[36m0.4752\u001b[0m       0.6265            0.6237            0.6265        0.7575        5.6595\n",
      "     38        \u001b[36m0.4601\u001b[0m       0.6563            0.6306            0.6563        0.7042        5.6425\n",
      "     39        \u001b[36m0.4513\u001b[0m       0.6302            0.6149            0.6302        0.7178        5.6120\n",
      "     40        \u001b[36m0.4444\u001b[0m       0.6273            0.6261            0.6273        0.8730        5.7007\n",
      "     41        \u001b[36m0.4284\u001b[0m       0.6445            0.6387            0.6445        0.7713        5.6257\n",
      "     42        \u001b[36m0.4148\u001b[0m       0.6078            0.5990            0.6078        0.7899        5.6933\n",
      "     43        0.4410       0.6331            0.5856            0.6331        0.8176        5.6232\n",
      "     44        0.4203       0.5694            0.5643            0.5694        1.0145        5.6955\n",
      "     45        \u001b[36m0.4000\u001b[0m       0.6498            0.6243            0.6498        0.7715        5.6447\n",
      "     46        \u001b[36m0.3823\u001b[0m       0.6453            0.6402            0.6453        0.7740        5.6320\n",
      "     47        \u001b[36m0.3745\u001b[0m       0.6192            0.6162            0.6192        0.8689        5.6062\n",
      "     48        \u001b[36m0.3523\u001b[0m       0.6404            0.6295            0.6404        0.8501        5.6152\n",
      "     49        \u001b[36m0.3394\u001b[0m       0.6176            0.6126            0.6176        0.8616        5.6464\n",
      "     50        \u001b[36m0.3309\u001b[0m       0.6216            0.5525            0.6216        1.0810        5.6849\n",
      "     51        \u001b[36m0.3265\u001b[0m       0.5914            0.5763            0.5914        1.0521        5.6646\n",
      "     52        \u001b[36m0.3043\u001b[0m       0.6482            0.6348            0.6482        0.9228        5.7082\n",
      "     53        \u001b[36m0.2888\u001b[0m       0.6380            0.6248            0.6380        0.9449        5.6122\n",
      "     54        \u001b[36m0.2861\u001b[0m       0.6404            0.6284            0.6404        1.0160        5.6618\n",
      "     55        \u001b[36m0.2636\u001b[0m       0.6404            0.6184            0.6404        1.0226        5.6119\n",
      "     56        \u001b[36m0.2598\u001b[0m       0.6302            0.6264            0.6302        0.9741        5.6240\n",
      "     57        \u001b[36m0.2357\u001b[0m       0.6245            0.6028            0.6245        1.1934        6.0246\n",
      "     58        \u001b[36m0.2304\u001b[0m       0.6078            0.6029            0.6078        1.0628        5.7783\n",
      "     59        \u001b[36m0.2180\u001b[0m       0.6302            0.6274            0.6302        1.0746        5.9639\n",
      "     60        \u001b[36m0.2050\u001b[0m       0.6086            0.6013            0.6086        1.1623        5.8487\n",
      "     61        0.2543       0.5841            0.5716            0.5841        1.1390        5.8269\n",
      "     62        0.2075       0.6220            0.6090            0.6220        1.0838        5.9463\n",
      "     63        \u001b[36m0.1899\u001b[0m       0.6339            0.6121            0.6339        1.2177        5.9116\n",
      "     64        \u001b[36m0.1879\u001b[0m       0.6290            0.6110            0.6290        1.1514        6.0023\n",
      "     65        \u001b[36m0.1713\u001b[0m       0.6184            0.6166            0.6184        1.2159        5.6773\n",
      "     66        \u001b[36m0.1674\u001b[0m       0.6143            0.5916            0.6143        1.2654        6.0225\n",
      "     67        \u001b[36m0.1601\u001b[0m       0.6322            0.6148            0.6322        1.2598        5.7726\n",
      "     68        0.1965       0.5939            0.5863            0.5939        1.2951        6.2497\n",
      "     69        \u001b[36m0.1523\u001b[0m       0.6147            0.6082            0.6147        1.2316        5.7426\n",
      "     70        0.1544       0.6339            0.6244            0.6339        1.3185        6.2047\n",
      "     71        \u001b[36m0.1242\u001b[0m       0.6188            0.6123            0.6188        1.4038        5.9439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4599]), 'p01': tensor([2.5298]), 'p05': tensor([2.8079]), 'p25': tensor([3.0937]), 'p50': tensor([3.1462]), 'p75': tensor([3.1873]), 'p95': tensor([3.4512]), 'p99': tensor([3.7476]), 'max': tensor([5.2849]), 'mean': tensor([3.1394]), 'std': tensor([0.1971])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7058\u001b[0m       \u001b[32m0.6000\u001b[0m            \u001b[35m0.5501\u001b[0m            \u001b[31m0.6000\u001b[0m        \u001b[94m0.6519\u001b[0m     +  5.8824\n",
      "      2        \u001b[36m0.6481\u001b[0m       \u001b[32m0.6347\u001b[0m            \u001b[35m0.5867\u001b[0m            \u001b[31m0.6347\u001b[0m        \u001b[94m0.6369\u001b[0m     +  5.9923\n",
      "      3        \u001b[36m0.6373\u001b[0m       \u001b[32m0.6576\u001b[0m            \u001b[35m0.6327\u001b[0m            \u001b[31m0.6576\u001b[0m        \u001b[94m0.6260\u001b[0m     +  5.8702\n",
      "      4        \u001b[36m0.6316\u001b[0m       0.6510            \u001b[35m0.6337\u001b[0m            0.6510        \u001b[94m0.6204\u001b[0m     +  6.0379\n",
      "      5        \u001b[36m0.6225\u001b[0m       0.6502            0.6332            0.6502        0.6274        5.8779\n",
      "      6        \u001b[36m0.6157\u001b[0m       0.6061            0.5185            0.6061        0.6789        6.0596\n",
      "      7        0.6159       0.5649            0.5544            0.5649        0.6651        5.9383\n",
      "      8        \u001b[36m0.6131\u001b[0m       \u001b[32m0.6584\u001b[0m            \u001b[35m0.6447\u001b[0m            \u001b[31m0.6584\u001b[0m        0.6309     +  5.9357\n",
      "      9        \u001b[36m0.6082\u001b[0m       0.6257            0.6216            0.6257        0.6433        6.0737\n",
      "     10        0.6114       0.6453            0.5786            0.6453        0.6327        6.0124\n",
      "     11        \u001b[36m0.6022\u001b[0m       0.5788            0.5716            0.5788        0.6851        6.0698\n",
      "     12        \u001b[36m0.6014\u001b[0m       0.5808            0.5719            0.5808        0.6899        5.8719\n",
      "     13        \u001b[36m0.5910\u001b[0m       0.6094            0.6088            0.6094        0.6444        6.1852\n",
      "     14        0.5987       0.6282            0.6279            0.6282        0.6549        5.8373\n",
      "     15        0.5919       0.6506            0.5983            0.6506        0.6249        6.3450\n",
      "     16        \u001b[36m0.5804\u001b[0m       0.6441            0.6284            0.6441        0.6293        5.8999\n",
      "     17        0.5837       0.6237            0.5287            0.6237        0.7192        6.3062\n",
      "     18        \u001b[36m0.5745\u001b[0m       0.6531            0.6418            0.6531        0.6458        5.8569\n",
      "     19        \u001b[36m0.5696\u001b[0m       \u001b[32m0.6612\u001b[0m            0.6417            \u001b[31m0.6612\u001b[0m        0.6291        6.1181\n",
      "     20        \u001b[36m0.5672\u001b[0m       0.6527            \u001b[35m0.6495\u001b[0m            0.6527        0.6392     +  5.9458\n",
      "     21        0.5687       0.6555            \u001b[35m0.6508\u001b[0m            0.6555        0.6574     +  6.3248\n",
      "     22        \u001b[36m0.5607\u001b[0m       0.6412            0.6371            0.6412        0.6565        5.8921\n",
      "     23        0.5621       0.6457            0.6091            0.6457        0.6677        5.9923\n",
      "     24        \u001b[36m0.5518\u001b[0m       0.6318            0.5915            0.6318        0.6701        6.0615\n",
      "     25        \u001b[36m0.5440\u001b[0m       0.6363            0.6363            0.6363        0.6796        6.0537\n",
      "     26        0.5479       0.6420            0.6273            0.6420        0.6476        6.1344\n",
      "     27        \u001b[36m0.5356\u001b[0m       0.6539            0.6479            0.6539        0.6386        5.9776\n",
      "     28        \u001b[36m0.5312\u001b[0m       0.6167            0.6166            0.6167        0.6985        6.2696\n",
      "     29        0.5319       0.5216            0.4949            0.5216        0.8449        5.8502\n",
      "     30        \u001b[36m0.5203\u001b[0m       0.6490            0.5981            0.6490        0.7608        6.2586\n",
      "     31        \u001b[36m0.5085\u001b[0m       0.6510            0.6445            0.6510        0.6614        5.7789\n",
      "     32        \u001b[36m0.5019\u001b[0m       0.6408            0.6207            0.6408        0.7004        6.4003\n",
      "     33        \u001b[36m0.4986\u001b[0m       0.6408            0.6355            0.6408        0.6653        5.7539\n",
      "     34        \u001b[36m0.4812\u001b[0m       0.6482            0.6199            0.6482        0.6958        6.1207\n",
      "     35        \u001b[36m0.4767\u001b[0m       0.6306            0.6210            0.6306        0.7689        5.8415\n",
      "     36        \u001b[36m0.4709\u001b[0m       0.5347            0.5115            0.5347        0.9995        6.1502\n",
      "     37        \u001b[36m0.4627\u001b[0m       0.5784            0.5783            0.5784        0.8111        5.8340\n",
      "     38        \u001b[36m0.4550\u001b[0m       0.6490            0.6335            0.6490        0.7464        6.0246\n",
      "     39        \u001b[36m0.4397\u001b[0m       0.6408            0.6363            0.6408        0.7557        5.9877\n",
      "     40        0.4401       0.6253            0.5727            0.6253        0.9569        6.0371\n",
      "     41        \u001b[36m0.4302\u001b[0m       0.6310            0.6154            0.6310        0.7592        6.0303\n",
      "     42        \u001b[36m0.4186\u001b[0m       0.6192            0.6048            0.6192        0.8014        5.9243\n",
      "     43        \u001b[36m0.4012\u001b[0m       0.6363            0.6212            0.6363        0.7799        6.0049\n",
      "     44        \u001b[36m0.3847\u001b[0m       0.6176            0.6170            0.6176        0.8493        5.8843\n",
      "     45        \u001b[36m0.3829\u001b[0m       0.6106            0.6060            0.6106        0.8025        6.1114\n",
      "     46        \u001b[36m0.3744\u001b[0m       0.6429            0.6342            0.6429        0.7839        5.8920\n",
      "     47        \u001b[36m0.3555\u001b[0m       0.6286            0.5987            0.6286        0.9413        6.1598\n",
      "     48        \u001b[36m0.3459\u001b[0m       0.5518            0.5439            0.5518        1.0683        5.9148\n",
      "     49        \u001b[36m0.3296\u001b[0m       0.6327            0.6292            0.6327        0.8825        6.1649\n",
      "     50        0.3298       0.6045            0.6023            0.6045        0.8927        5.7975\n",
      "     51        \u001b[36m0.3071\u001b[0m       0.6490            0.6226            0.6490        0.9710        6.0088\n",
      "     52        \u001b[36m0.3025\u001b[0m       0.6355            0.5891            0.6355        1.1528        5.8601\n",
      "     53        \u001b[36m0.2993\u001b[0m       0.6371            0.6096            0.6371        1.0492        6.1327\n",
      "     54        \u001b[36m0.2903\u001b[0m       0.6233            0.6213            0.6233        1.0066        6.0875\n",
      "     55        \u001b[36m0.2641\u001b[0m       0.5620            0.5595            0.5620        1.2922        5.9945\n",
      "     56        \u001b[36m0.2418\u001b[0m       0.6310            0.6080            0.6310        1.1692        6.0183\n",
      "     57        0.2514       0.6163            0.6139            0.6163        1.1562        6.0219\n",
      "     58        \u001b[36m0.2378\u001b[0m       0.6220            0.6174            0.6220        1.0420        6.2403\n",
      "     59        \u001b[36m0.2287\u001b[0m       0.6073            0.6051            0.6073        1.0439        5.7940\n",
      "     60        \u001b[36m0.2190\u001b[0m       0.6122            0.6067            0.6122        1.1602        6.1570\n",
      "     61        \u001b[36m0.2088\u001b[0m       0.6343            0.6153            0.6343        1.0929        5.8012\n",
      "     62        \u001b[36m0.2041\u001b[0m       0.6306            0.6182            0.6306        1.1278        6.2188\n",
      "     63        \u001b[36m0.1947\u001b[0m       0.6273            0.6234            0.6273        1.1371        5.7483\n",
      "     64        \u001b[36m0.1741\u001b[0m       0.6078            0.6065            0.6078        1.3075        6.0802\n",
      "     65        0.1784       0.6135            0.5904            0.6135        1.3048        5.8849\n",
      "     66        \u001b[36m0.1717\u001b[0m       0.6216            0.6137            0.6216        1.2392        6.0966\n",
      "     67        \u001b[36m0.1575\u001b[0m       0.6273            0.6037            0.6273        1.3775        5.9883\n",
      "     68        0.1608       0.6355            0.6208            0.6355        1.2177        6.0411\n",
      "     69        \u001b[36m0.1462\u001b[0m       0.6224            0.6038            0.6224        1.3496        6.1428\n",
      "     70        \u001b[36m0.1418\u001b[0m       0.6388            0.6192            0.6388        1.3722        6.0222\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4945]), 'p01': tensor([2.5289]), 'p05': tensor([2.8081]), 'p25': tensor([3.0940]), 'p50': tensor([3.1465]), 'p75': tensor([3.1875]), 'p95': tensor([3.4523]), 'p99': tensor([3.7478]), 'max': tensor([5.2376]), 'mean': tensor([3.1398]), 'std': tensor([0.1972])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6874\u001b[0m       \u001b[32m0.6024\u001b[0m            \u001b[35m0.5825\u001b[0m            \u001b[31m0.6024\u001b[0m        \u001b[94m0.6617\u001b[0m     +  5.8713\n",
      "      2        \u001b[36m0.6474\u001b[0m       \u001b[32m0.6245\u001b[0m            0.5480            \u001b[31m0.6245\u001b[0m        \u001b[94m0.6435\u001b[0m        5.9895\n",
      "      3        \u001b[36m0.6311\u001b[0m       \u001b[32m0.6286\u001b[0m            \u001b[35m0.6137\u001b[0m            \u001b[31m0.6286\u001b[0m        0.6507     +  5.9938\n",
      "      4        \u001b[36m0.6301\u001b[0m       0.6286            0.6032            0.6286        \u001b[94m0.6369\u001b[0m        6.0167\n",
      "      5        \u001b[36m0.6226\u001b[0m       \u001b[32m0.6343\u001b[0m            0.5712            \u001b[31m0.6343\u001b[0m        \u001b[94m0.6330\u001b[0m        6.0419\n",
      "      6        \u001b[36m0.6136\u001b[0m       0.6122            0.6122            0.6122        0.6982        6.0715\n",
      "      7        0.6139       \u001b[32m0.6371\u001b[0m            0.5644            \u001b[31m0.6371\u001b[0m        0.6880        5.8621\n",
      "      8        \u001b[36m0.6131\u001b[0m       0.6245            0.5060            0.6245        0.6598        6.1068\n",
      "      9        \u001b[36m0.6097\u001b[0m       \u001b[32m0.6518\u001b[0m            \u001b[35m0.6446\u001b[0m            \u001b[31m0.6518\u001b[0m        \u001b[94m0.6305\u001b[0m     +  5.8697\n",
      "     10        \u001b[36m0.6021\u001b[0m       0.6094            0.4906            0.6094        0.7039        6.1013\n",
      "     11        \u001b[36m0.6013\u001b[0m       0.6237            0.5291            0.6237        0.7075        5.8959\n",
      "     12        \u001b[36m0.5952\u001b[0m       0.5955            0.4794            0.5955        0.7731        6.0668\n",
      "     13        0.5974       0.6490            0.6413            0.6490        0.6333        5.7493\n",
      "     14        \u001b[36m0.5868\u001b[0m       0.5947            0.5752            0.5947        0.6836        6.1075\n",
      "     15        \u001b[36m0.5859\u001b[0m       0.6453            0.6437            0.6453        0.6342        5.8017\n",
      "     16        \u001b[36m0.5813\u001b[0m       \u001b[32m0.6551\u001b[0m            0.6240            \u001b[31m0.6551\u001b[0m        0.6437        6.1250\n",
      "     17        0.5851       0.6473            0.6288            0.6473        \u001b[94m0.6210\u001b[0m        5.9559\n",
      "     18        \u001b[36m0.5746\u001b[0m       \u001b[32m0.6661\u001b[0m            \u001b[35m0.6469\u001b[0m            \u001b[31m0.6661\u001b[0m        0.6642     +  6.0691\n",
      "     19        0.5763       0.6527            0.6444            0.6527        \u001b[94m0.6173\u001b[0m        5.8611\n",
      "     20        \u001b[36m0.5739\u001b[0m       0.6555            0.6278            0.6555        0.6222        6.0554\n",
      "     21        \u001b[36m0.5610\u001b[0m       0.6380            0.5904            0.6380        0.6594        6.0092\n",
      "     22        0.5685       0.6576            0.6243            0.6576        0.6380        5.9170\n",
      "     23        \u001b[36m0.5558\u001b[0m       0.6486            0.6113            0.6486        0.6926        6.2465\n",
      "     24        \u001b[36m0.5533\u001b[0m       0.6204            0.6203            0.6204        0.7068        5.8519\n",
      "     25        \u001b[36m0.5525\u001b[0m       0.6200            0.6199            0.6200        0.6712        6.0026\n",
      "     26        \u001b[36m0.5413\u001b[0m       0.6437            0.6301            0.6437        0.6411        5.7149\n",
      "     27        \u001b[36m0.5373\u001b[0m       0.6506            0.6358            0.6506        0.6572        6.1792\n",
      "     28        \u001b[36m0.5333\u001b[0m       0.6118            0.6118            0.6118        0.6664        5.7128\n",
      "     29        \u001b[36m0.5275\u001b[0m       0.6559            0.6150            0.6559        0.7046        6.0577\n",
      "     30        \u001b[36m0.5225\u001b[0m       0.6559            0.6456            0.6559        0.6537        5.8116\n",
      "     31        \u001b[36m0.5177\u001b[0m       0.6416            0.6320            0.6416        0.6885        6.0232\n",
      "     32        \u001b[36m0.5166\u001b[0m       0.6245            0.5877            0.6245        0.7243        5.9190\n",
      "     33        \u001b[36m0.5056\u001b[0m       0.6245            0.5771            0.6245        0.7722        6.0009\n",
      "     34        \u001b[36m0.4931\u001b[0m       0.6482            0.6368            0.6482        0.7349        6.0131\n",
      "     35        0.5016       0.5861            0.5771            0.5861        0.7551        5.9784\n",
      "     36        \u001b[36m0.4847\u001b[0m       0.6245            0.6210            0.6245        0.7480        5.9356\n",
      "     37        \u001b[36m0.4686\u001b[0m       0.6041            0.5571            0.6041        0.8731        6.0319\n",
      "     38        \u001b[36m0.4598\u001b[0m       0.6306            0.5900            0.6306        0.7802        6.0759\n",
      "     39        \u001b[36m0.4515\u001b[0m       0.6429            0.6273            0.6429        0.7340        5.9772\n",
      "     40        \u001b[36m0.4335\u001b[0m       0.6114            0.6102            0.6114        0.7306        6.0280\n",
      "     41        0.4416       \u001b[32m0.6682\u001b[0m            \u001b[35m0.6584\u001b[0m            \u001b[31m0.6682\u001b[0m        0.6790     +  5.9628\n",
      "     42        \u001b[36m0.4226\u001b[0m       0.6461            0.6404            0.6461        0.7324        6.1965\n",
      "     43        \u001b[36m0.4070\u001b[0m       0.6396            0.6052            0.6396        0.8512        5.8174\n",
      "     44        0.4104       0.6114            0.6090            0.6114        0.7620        6.0330\n",
      "     45        \u001b[36m0.3974\u001b[0m       0.6449            0.6381            0.6449        0.8221        5.8915\n",
      "     46        \u001b[36m0.3815\u001b[0m       0.6412            0.6321            0.6412        0.7684        6.3159\n",
      "     47        \u001b[36m0.3683\u001b[0m       0.6547            0.6251            0.6547        0.8447        5.8291\n",
      "     48        \u001b[36m0.3587\u001b[0m       0.6588            0.6528            0.6588        0.7952        6.1578\n",
      "     49        \u001b[36m0.3343\u001b[0m       0.6571            0.6406            0.6571        0.8351        5.8809\n",
      "     50        \u001b[36m0.3327\u001b[0m       0.6318            0.6189            0.6318        0.8045        6.1890\n",
      "     51        \u001b[36m0.3190\u001b[0m       0.6335            0.6256            0.6335        0.9670        5.9184\n",
      "     52        \u001b[36m0.3077\u001b[0m       0.6327            0.6258            0.6327        0.9857        6.1570\n",
      "     53        \u001b[36m0.2986\u001b[0m       0.6229            0.5971            0.6229        0.8976        6.0796\n",
      "     54        \u001b[36m0.2944\u001b[0m       0.6286            0.6259            0.6286        0.9299        6.0444\n",
      "     55        \u001b[36m0.2883\u001b[0m       0.6408            0.6210            0.6408        0.9003        6.2860\n",
      "     56        \u001b[36m0.2686\u001b[0m       0.6363            0.5906            0.6363        1.0496        5.8991\n",
      "     57        \u001b[36m0.2566\u001b[0m       0.6363            0.6256            0.6363        0.9666        6.1544\n",
      "     58        \u001b[36m0.2366\u001b[0m       0.6347            0.6154            0.6347        1.0864        5.8196\n",
      "     59        \u001b[36m0.2322\u001b[0m       0.6249            0.6017            0.6249        1.1336        6.1651\n",
      "     60        \u001b[36m0.2201\u001b[0m       0.6037            0.5848            0.6037        1.4636        5.6694\n",
      "     61        0.2229       0.6180            0.6164            0.6180        1.0296        6.3560\n",
      "     62        \u001b[36m0.2036\u001b[0m       0.6457            0.6414            0.6457        1.1491        5.8011\n",
      "     63        \u001b[36m0.1930\u001b[0m       0.6514            0.6307            0.6514        1.2168        6.0613\n",
      "     64        \u001b[36m0.1861\u001b[0m       0.6420            0.6215            0.6420        1.2174        5.9212\n",
      "     65        \u001b[36m0.1851\u001b[0m       0.6086            0.6034            0.6086        1.1364        6.1027\n",
      "     66        \u001b[36m0.1714\u001b[0m       0.6335            0.6064            0.6335        1.2791        5.9461\n",
      "     67        \u001b[36m0.1662\u001b[0m       0.6253            0.6203            0.6253        1.1589        5.9278\n",
      "     68        \u001b[36m0.1582\u001b[0m       0.6335            0.6228            0.6335        1.3375        6.1383\n",
      "     69        0.1627       0.6257            0.6116            0.6257        1.2405        5.9183\n",
      "     70        \u001b[36m0.1457\u001b[0m       0.6257            0.6227            0.6257        1.4772        5.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     71        \u001b[36m0.1435\u001b[0m       0.6343            0.6123            0.6343        1.3053        5.8742\n",
      "     72        \u001b[36m0.1401\u001b[0m       0.6445            0.6128            0.6445        1.4085        6.0547\n",
      "     73        \u001b[36m0.1294\u001b[0m       0.6155            0.6079            0.6155        1.2861        5.8661\n",
      "     74        0.1360       0.6061            0.5926            0.6061        1.5407        6.1935\n",
      "     75        0.1350       0.6216            0.6062            0.6216        1.3306        5.7492\n",
      "     76        \u001b[36m0.1224\u001b[0m       0.6249            0.6109            0.6249        1.4400        6.3215\n",
      "     77        \u001b[36m0.1186\u001b[0m       0.6359            0.6202            0.6359        1.5228        5.9605\n",
      "     78        \u001b[36m0.1147\u001b[0m       0.6339            0.6209            0.6339        1.4999        6.3252\n",
      "     79        \u001b[36m0.1094\u001b[0m       0.6188            0.6051            0.6188        1.3953        5.7918\n",
      "     80        \u001b[36m0.0984\u001b[0m       0.6396            0.6301            0.6396        1.5070        5.8204\n",
      "     81        0.1011       0.6102            0.5979            0.6102        1.4741        5.8576\n",
      "     82        0.1036       0.6241            0.5957            0.6241        1.5052        6.1581\n",
      "     83        \u001b[36m0.0926\u001b[0m       0.6457            0.6386            0.6457        1.4572        5.9068\n",
      "     84        \u001b[36m0.0855\u001b[0m       0.6331            0.6203            0.6331        1.5620        5.9515\n",
      "     85        0.0953       0.6257            0.6121            0.6257        1.5316        5.8704\n",
      "     86        \u001b[36m0.0841\u001b[0m       0.6404            0.6247            0.6404        1.5244        5.9082\n",
      "     87        \u001b[36m0.0817\u001b[0m       0.6290            0.6217            0.6290        1.5599        5.8888\n",
      "     88        \u001b[36m0.0798\u001b[0m       0.6429            0.6294            0.6429        1.6999        5.8514\n",
      "     89        0.0831       0.6327            0.6173            0.6327        1.6890        6.0064\n",
      "     90        0.0833       0.6339            0.6293            0.6339        1.7250        5.8064\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.4757]), 'p01': tensor([2.5295]), 'p05': tensor([2.8071]), 'p25': tensor([3.0940]), 'p50': tensor([3.1461]), 'p75': tensor([3.1876]), 'p95': tensor([3.4514]), 'p99': tensor([3.7498]), 'max': tensor([5.2048]), 'mean': tensor([3.1395]), 'std': tensor([0.1973])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6947\u001b[0m       \u001b[32m0.6057\u001b[0m            \u001b[35m0.5089\u001b[0m            \u001b[31m0.6057\u001b[0m        \u001b[94m0.6669\u001b[0m     +  5.8678\n",
      "      2        \u001b[36m0.6474\u001b[0m       0.5980            0.4773            0.5980        \u001b[94m0.6643\u001b[0m        5.9429\n",
      "      3        \u001b[36m0.6299\u001b[0m       \u001b[32m0.6355\u001b[0m            \u001b[35m0.6065\u001b[0m            \u001b[31m0.6355\u001b[0m        \u001b[94m0.6402\u001b[0m     +  5.9010\n",
      "      4        \u001b[36m0.6299\u001b[0m       0.6233            0.5939            0.6233        0.6425        5.8150\n",
      "      5        \u001b[36m0.6199\u001b[0m       0.6278            \u001b[35m0.6232\u001b[0m            0.6278        \u001b[94m0.6383\u001b[0m     +  5.8296\n",
      "      6        \u001b[36m0.6133\u001b[0m       \u001b[32m0.6469\u001b[0m            0.5956            \u001b[31m0.6469\u001b[0m        0.6912        5.8708\n",
      "      7        \u001b[36m0.6062\u001b[0m       0.6404            0.5887            0.6404        0.6428        5.9524\n",
      "      8        0.6067       \u001b[32m0.6478\u001b[0m            0.5963            \u001b[31m0.6478\u001b[0m        \u001b[94m0.6379\u001b[0m        5.9286\n",
      "      9        \u001b[36m0.6037\u001b[0m       0.5727            0.5716            0.5727        0.6943        5.9968\n",
      "     10        \u001b[36m0.5978\u001b[0m       0.6220            0.5500            0.6220        0.6594        5.8573\n",
      "     11        \u001b[36m0.5861\u001b[0m       0.6433            \u001b[35m0.6368\u001b[0m            0.6433        \u001b[94m0.6334\u001b[0m     +  5.9270\n",
      "     12        0.5877       0.6278            0.6271            0.6278        0.6813        5.7954\n",
      "     13        \u001b[36m0.5857\u001b[0m       0.6229            0.5376            0.6229        0.6687        5.8609\n",
      "     14        \u001b[36m0.5793\u001b[0m       0.6420            \u001b[35m0.6379\u001b[0m            0.6420        0.6431     +  5.9056\n",
      "     15        \u001b[36m0.5734\u001b[0m       0.6094            0.6085            0.6094        0.6598        5.9420\n",
      "     16        0.5744       \u001b[32m0.6571\u001b[0m            0.6366            \u001b[31m0.6571\u001b[0m        0.6656        5.8712\n",
      "     17        \u001b[36m0.5724\u001b[0m       0.6527            0.6323            0.6527        \u001b[94m0.6316\u001b[0m        5.8380\n",
      "     18        \u001b[36m0.5621\u001b[0m       0.6371            0.5804            0.6371        0.6541        5.8535\n",
      "     19        \u001b[36m0.5608\u001b[0m       0.6151            0.5763            0.6151        0.6715        5.8897\n",
      "     20        \u001b[36m0.5553\u001b[0m       0.6424            0.6042            0.6424        0.6484        5.8969\n",
      "     21        \u001b[36m0.5495\u001b[0m       0.6543            0.6297            0.6543        0.6377        5.8809\n",
      "     22        \u001b[36m0.5457\u001b[0m       \u001b[32m0.6616\u001b[0m            \u001b[35m0.6502\u001b[0m            \u001b[31m0.6616\u001b[0m        0.6393     +  5.8689\n",
      "     23        0.5501       0.6437            0.6305            0.6437        0.6678        5.9654\n",
      "     24        \u001b[36m0.5427\u001b[0m       0.6555            0.6429            0.6555        0.6402        5.9252\n",
      "     25        \u001b[36m0.5392\u001b[0m       0.6233            0.6007            0.6233        0.6634        5.9861\n",
      "     26        \u001b[36m0.5310\u001b[0m       0.6192            0.5403            0.6192        0.7319        5.9993\n",
      "     27        \u001b[36m0.5264\u001b[0m       0.6404            0.5954            0.6404        0.7179        5.9003\n",
      "     28        \u001b[36m0.5236\u001b[0m       0.6347            0.6326            0.6347        0.6695        5.9856\n",
      "     29        \u001b[36m0.5172\u001b[0m       0.6249            0.6179            0.6249        0.7027        5.8309\n",
      "     30        \u001b[36m0.5020\u001b[0m       0.6339            0.6104            0.6339        0.8024        6.2287\n",
      "     31        0.5060       0.5498            0.5484            0.5498        0.7623        5.8385\n",
      "     32        \u001b[36m0.4919\u001b[0m       0.5698            0.5691            0.5698        0.7687        5.8605\n",
      "     33        \u001b[36m0.4782\u001b[0m       0.6257            0.5860            0.6257        0.7705        5.8155\n",
      "     34        \u001b[36m0.4774\u001b[0m       0.5988            0.5984            0.5988        0.7902        5.9291\n",
      "     35        \u001b[36m0.4637\u001b[0m       0.6143            0.6142            0.6143        0.7196        5.9117\n",
      "     36        \u001b[36m0.4525\u001b[0m       0.6510            0.6388            0.6510        0.7220        5.8948\n",
      "     37        \u001b[36m0.4416\u001b[0m       0.6322            0.6257            0.6322        0.7943        5.8540\n",
      "     38        \u001b[36m0.4309\u001b[0m       0.5947            0.5944            0.5947        0.7873        5.9039\n",
      "     39        \u001b[36m0.4229\u001b[0m       0.6290            0.6209            0.6290        0.7782        5.8551\n",
      "     40        \u001b[36m0.4181\u001b[0m       0.6069            0.5943            0.6069        0.7670        5.8116\n",
      "     41        \u001b[36m0.3975\u001b[0m       0.6253            0.6032            0.6253        0.7851        5.9245\n",
      "     42        0.4070       0.6302            0.6015            0.6302        0.8518        5.9154\n",
      "     43        \u001b[36m0.3881\u001b[0m       0.6441            0.6053            0.6441        0.8671        5.9026\n",
      "     44        \u001b[36m0.3714\u001b[0m       0.6335            0.6104            0.6335        0.8499        5.8264\n",
      "     45        \u001b[36m0.3592\u001b[0m       0.6188            0.5903            0.6188        0.9049        5.9184\n",
      "     46        0.3630       0.6061            0.5798            0.6061        0.8721        5.8481\n",
      "     47        \u001b[36m0.3494\u001b[0m       0.6163            0.6132            0.6163        0.8590        5.8250\n",
      "     48        \u001b[36m0.3317\u001b[0m       0.6012            0.6011            0.6012        1.0477        5.9439\n",
      "     49        \u001b[36m0.3220\u001b[0m       0.6363            0.6279            0.6363        0.9392        5.9101\n",
      "     50        \u001b[36m0.3163\u001b[0m       0.6367            0.6303            0.6367        0.9312        5.9477\n",
      "     51        \u001b[36m0.2994\u001b[0m       0.6200            0.6154            0.6200        0.9726        6.0206\n",
      "     52        \u001b[36m0.2800\u001b[0m       0.6155            0.6107            0.6155        1.1053        5.9173\n",
      "     53        \u001b[36m0.2704\u001b[0m       0.6135            0.6134            0.6135        1.0817        5.8264\n",
      "     54        \u001b[36m0.2628\u001b[0m       0.6078            0.6031            0.6078        0.9667        5.8988\n",
      "     55        \u001b[36m0.2412\u001b[0m       0.6318            0.6162            0.6318        1.1426        5.9331\n",
      "     56        \u001b[36m0.2231\u001b[0m       0.6322            0.6191            0.6322        1.0893        5.9200\n",
      "     57        0.2368       0.6184            0.6152            0.6184        1.0577        5.9322\n",
      "     58        \u001b[36m0.2222\u001b[0m       0.6180            0.5986            0.6180        1.0740        5.9329\n",
      "     59        \u001b[36m0.2029\u001b[0m       0.6151            0.6030            0.6151        1.1491        5.9152\n",
      "     60        0.2063       0.6114            0.5958            0.6114        1.2352        5.8118\n",
      "     61        \u001b[36m0.1930\u001b[0m       0.6257            0.6165            0.6257        1.1747        5.8577\n",
      "     62        \u001b[36m0.1851\u001b[0m       0.6310            0.6303            0.6310        1.3709        5.8464\n",
      "     63        \u001b[36m0.1792\u001b[0m       0.6327            0.6279            0.6327        1.3016        5.9847\n",
      "     64        \u001b[36m0.1596\u001b[0m       0.6000            0.5997            0.6000        1.4633        5.9719\n",
      "     65        0.1621       0.6278            0.5811            0.6278        1.3230        5.8784\n",
      "     66        \u001b[36m0.1543\u001b[0m       0.6265            0.6235            0.6265        1.3962        5.8977\n",
      "     67        \u001b[36m0.1460\u001b[0m       0.6106            0.5998            0.6106        1.3148        5.8868\n",
      "     68        0.1515       0.6147            0.6027            0.6147        1.4566        5.9283\n",
      "     69        \u001b[36m0.1413\u001b[0m       0.6057            0.5981            0.6057        1.4713        5.8467\n",
      "     70        \u001b[36m0.1327\u001b[0m       0.6269            0.6176            0.6269        1.4517        5.8950\n",
      "     71        0.1374       0.6159            0.5955            0.6159        1.5227        5.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([1.5383]), 'p01': tensor([2.5298]), 'p05': tensor([2.8084]), 'p25': tensor([3.0936]), 'p50': tensor([3.1463]), 'p75': tensor([3.1878]), 'p95': tensor([3.4512]), 'p99': tensor([3.7484]), 'max': tensor([5.2319]), 'mean': tensor([3.1397]), 'std': tensor([0.1969])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6986\u001b[0m       \u001b[32m0.6237\u001b[0m            \u001b[35m0.5201\u001b[0m            \u001b[31m0.6237\u001b[0m        \u001b[94m0.6553\u001b[0m     +  5.8980\n",
      "      2        \u001b[36m0.6484\u001b[0m       0.6065            \u001b[35m0.6008\u001b[0m            0.6065        \u001b[94m0.6533\u001b[0m     +  5.9158\n",
      "      3        \u001b[36m0.6393\u001b[0m       0.5527            0.5476            0.5527        0.6872        5.7834\n",
      "      4        \u001b[36m0.6247\u001b[0m       \u001b[32m0.6310\u001b[0m            0.5631            \u001b[31m0.6310\u001b[0m        0.6563        5.8743\n",
      "      5        0.6247       \u001b[32m0.6449\u001b[0m            \u001b[35m0.6182\u001b[0m            \u001b[31m0.6449\u001b[0m        \u001b[94m0.6278\u001b[0m     +  6.0507\n",
      "      6        \u001b[36m0.6116\u001b[0m       0.6306            0.5719            0.6306        0.6464        5.8660\n",
      "      7        \u001b[36m0.6068\u001b[0m       \u001b[32m0.6461\u001b[0m            0.6088            \u001b[31m0.6461\u001b[0m        0.6480        5.9139\n",
      "      8        \u001b[36m0.6048\u001b[0m       0.6049            0.6048            0.6049        0.6852        5.9187\n",
      "      9        \u001b[36m0.6021\u001b[0m       0.5314            0.5210            0.5314        0.7492        5.8667\n",
      "     10        \u001b[36m0.6011\u001b[0m       0.5996            0.5984            0.5996        0.6769        5.8393\n",
      "     11        \u001b[36m0.6010\u001b[0m       0.5992            0.5239            0.5992        0.7155        5.9292\n",
      "     12        \u001b[36m0.5908\u001b[0m       0.6318            0.6139            0.6318        0.6467        5.9224\n",
      "     13        \u001b[36m0.5855\u001b[0m       0.6404            0.5981            0.6404        0.6463        5.9465\n",
      "     14        \u001b[36m0.5846\u001b[0m       0.6461            \u001b[35m0.6288\u001b[0m            0.6461        0.6390     +  5.8742\n",
      "     15        \u001b[36m0.5813\u001b[0m       0.5367            0.5307            0.5367        0.7015        5.9132\n",
      "     16        0.5889       0.6167            0.6166            0.6167        0.6805        5.8704\n",
      "     17        \u001b[36m0.5712\u001b[0m       \u001b[32m0.6531\u001b[0m            \u001b[35m0.6445\u001b[0m            \u001b[31m0.6531\u001b[0m        0.6503     +  5.9763\n",
      "     18        \u001b[36m0.5678\u001b[0m       0.6433            0.6219            0.6433        0.6387        6.1119\n",
      "     19        \u001b[36m0.5678\u001b[0m       0.6143            0.6024            0.6143        0.6979        5.8848\n",
      "     20        \u001b[36m0.5650\u001b[0m       0.6429            0.6296            0.6429        0.6321        5.8558\n",
      "     21        \u001b[36m0.5548\u001b[0m       0.6359            0.6275            0.6359        0.6668        5.9102\n",
      "     22        \u001b[36m0.5509\u001b[0m       0.6355            0.5842            0.6355        0.6897        5.9032\n",
      "     23        0.5518       0.6437            0.6375            0.6437        0.6349        5.8860\n",
      "     24        \u001b[36m0.5398\u001b[0m       0.6282            0.6183            0.6282        0.6774        5.8580\n",
      "     25        0.5401       0.6196            0.5754            0.6196        0.6780        5.9163\n",
      "     26        \u001b[36m0.5308\u001b[0m       0.6049            0.5931            0.6049        0.6841        5.8922\n",
      "     27        0.5319       0.6147            0.6128            0.6147        0.6914        6.0182\n",
      "     28        \u001b[36m0.5228\u001b[0m       0.6073            0.6060            0.6073        0.7255        5.9826\n",
      "     29        \u001b[36m0.5174\u001b[0m       0.6302            0.6271            0.6302        0.7086        5.9271\n",
      "     30        0.5181       0.6457            0.6161            0.6457        0.6987        5.9254\n",
      "     31        \u001b[36m0.5056\u001b[0m       0.5698            0.5666            0.5698        0.7807        5.8463\n",
      "     32        \u001b[36m0.4928\u001b[0m       0.6229            0.5972            0.6229        0.7286        5.8477\n",
      "     33        \u001b[36m0.4891\u001b[0m       0.6449            0.6209            0.6449        0.7446        5.9043\n",
      "     34        \u001b[36m0.4791\u001b[0m       0.6257            0.6203            0.6257        0.6997        5.9414\n",
      "     35        \u001b[36m0.4730\u001b[0m       0.6216            0.5944            0.6216        0.7953        5.9766\n",
      "     36        \u001b[36m0.4586\u001b[0m       0.6122            0.5875            0.6122        0.7535        5.8162\n",
      "     37        0.4602       0.6339            0.6263            0.6339        0.7864        5.9090\n",
      "     38        0.4594       0.6208            0.6158            0.6208        0.7447        5.8852\n",
      "     39        \u001b[36m0.4349\u001b[0m       0.6506            0.6330            0.6506        0.7950        5.9400\n",
      "     40        \u001b[36m0.4306\u001b[0m       0.6212            0.6005            0.6212        0.7818        5.9790\n",
      "     41        \u001b[36m0.4160\u001b[0m       0.6196            0.6147            0.6196        0.7782        5.8846\n",
      "     42        \u001b[36m0.4126\u001b[0m       0.6318            0.6183            0.6318        0.8026        5.8727\n",
      "     43        \u001b[36m0.4066\u001b[0m       0.6327            0.6231            0.6327        0.8309        5.9013\n",
      "     44        \u001b[36m0.3905\u001b[0m       0.6351            0.6125            0.6351        0.9714        5.8916\n",
      "     45        \u001b[36m0.3749\u001b[0m       0.6057            0.5937            0.6057        0.8311        5.9110\n",
      "     46        \u001b[36m0.3569\u001b[0m       0.6237            0.6003            0.6237        0.8540        5.9004\n",
      "     47        \u001b[36m0.3472\u001b[0m       0.5984            0.5916            0.5984        0.9421        5.8729\n",
      "     48        \u001b[36m0.3399\u001b[0m       0.6057            0.5764            0.6057        1.0014        5.9528\n",
      "     49        \u001b[36m0.3254\u001b[0m       0.6208            0.6106            0.6208        0.9872        5.8697\n",
      "     50        \u001b[36m0.3204\u001b[0m       0.6310            0.6177            0.6310        1.0025        5.8458\n",
      "     51        \u001b[36m0.3090\u001b[0m       0.5988            0.5974            0.5988        1.0368        5.8915\n",
      "     52        \u001b[36m0.2975\u001b[0m       0.6335            0.6017            0.6335        1.0451        5.9048\n",
      "     53        0.3063       0.6351            0.6213            0.6351        0.9730        5.8596\n",
      "     54        \u001b[36m0.2702\u001b[0m       0.6029            0.5912            0.6029        1.0764        5.9040\n",
      "     55        \u001b[36m0.2620\u001b[0m       0.6233            0.5833            0.6233        1.1834        6.0876\n",
      "     56        \u001b[36m0.2343\u001b[0m       0.6429            0.6364            0.6429        1.1242        5.8718\n",
      "     57        0.2371       0.6220            0.6073            0.6220        1.1242        5.8770\n",
      "     58        \u001b[36m0.2339\u001b[0m       0.6257            0.5973            0.6257        1.3134        5.8744\n",
      "     59        \u001b[36m0.2242\u001b[0m       0.6420            0.6272            0.6420        1.1670        5.8436\n",
      "     60        \u001b[36m0.2137\u001b[0m       0.6053            0.6016            0.6053        1.1650        5.9276\n",
      "     61        \u001b[36m0.1985\u001b[0m       0.6114            0.6091            0.6114        1.3093        5.9604\n",
      "     62        0.2076       0.6082            0.5531            0.6082        1.2821        5.9350\n",
      "     63        0.2313       0.6151            0.6130            0.6151        1.1433        5.8345\n",
      "     64        \u001b[36m0.1964\u001b[0m       0.6016            0.5997            0.6016        1.3709        5.9410\n",
      "     65        \u001b[36m0.1736\u001b[0m       0.6216            0.6127            0.6216        1.3095        5.9152\n",
      "     66        \u001b[36m0.1583\u001b[0m       0.6245            0.6058            0.6245        1.2857        5.8634\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n",
      "GuidedGradCAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0170]), 'p05': tensor([0.0272]), 'p25': tensor([0.0483]), 'p50': tensor([0.0758]), 'p75': tensor([0.1620]), 'p95': tensor([0.7778]), 'p99': tensor([2.1694]), 'max': tensor([247.5107]), 'mean': tensor([0.2220]), 'std': tensor([1.9308])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2984\u001b[0m       \u001b[32m0.8976\u001b[0m            \u001b[35m0.8956\u001b[0m            \u001b[31m0.8976\u001b[0m        \u001b[94m0.2319\u001b[0m     +  5.8453\n",
      "      2        \u001b[36m0.2127\u001b[0m       \u001b[32m0.9061\u001b[0m            \u001b[35m0.9013\u001b[0m            \u001b[31m0.9061\u001b[0m        \u001b[94m0.2018\u001b[0m     +  5.9130\n",
      "      3        \u001b[36m0.2028\u001b[0m       0.8776            0.8772            0.8776        0.2909        5.9545\n",
      "      4        \u001b[36m0.1833\u001b[0m       \u001b[32m0.9396\u001b[0m            \u001b[35m0.9381\u001b[0m            \u001b[31m0.9396\u001b[0m        \u001b[94m0.1453\u001b[0m     +  5.8756\n",
      "      5        \u001b[36m0.1701\u001b[0m       0.8457            0.8457            0.8457        0.3540        5.7663\n",
      "      6        \u001b[36m0.1688\u001b[0m       0.8347            0.8347            0.8347        0.3643        5.8705\n",
      "      7        \u001b[36m0.1646\u001b[0m       0.9200            0.9192            0.9200        0.2055        5.9401\n",
      "      8        \u001b[36m0.1540\u001b[0m       0.9167            0.9160            0.9167        0.1984        5.9517\n",
      "      9        0.1589       0.9208            0.9199            0.9208        0.1901        5.9575\n",
      "     10        \u001b[36m0.1532\u001b[0m       0.9396            \u001b[35m0.9382\u001b[0m            0.9396        \u001b[94m0.1417\u001b[0m     +  5.9669\n",
      "     11        \u001b[36m0.1420\u001b[0m       0.9012            0.9005            0.9012        0.2465        5.8612\n",
      "     12        0.1449       0.8833            0.8829            0.8833        0.2579        5.8426\n",
      "     13        \u001b[36m0.1413\u001b[0m       0.9269            0.9255            0.9269        0.1883        5.8366\n",
      "     14        \u001b[36m0.1351\u001b[0m       0.9286            0.9272            0.9286        0.1944        5.8966\n",
      "     15        0.1353       \u001b[32m0.9441\u001b[0m            \u001b[35m0.9424\u001b[0m            \u001b[31m0.9441\u001b[0m        \u001b[94m0.1379\u001b[0m     +  5.9385\n",
      "     16        0.1394       0.9253            0.9243            0.9253        0.1778        5.9161\n",
      "     17        \u001b[36m0.1288\u001b[0m       0.9204            0.9196            0.9204        0.1813        6.0093\n",
      "     18        \u001b[36m0.1239\u001b[0m       0.9416            0.9406            0.9416        0.1467        5.9146\n",
      "     19        0.1301       0.9351            0.9341            0.9351        0.1479        5.9255\n",
      "     20        \u001b[36m0.1197\u001b[0m       \u001b[32m0.9473\u001b[0m            \u001b[35m0.9458\u001b[0m            \u001b[31m0.9473\u001b[0m        0.1396     +  5.9139\n",
      "     21        0.1238       0.9420            0.9402            0.9420        \u001b[94m0.1362\u001b[0m        5.8978\n",
      "     22        0.1225       0.9224            0.9216            0.9224        0.1907        5.8956\n",
      "     23        \u001b[36m0.1144\u001b[0m       \u001b[32m0.9486\u001b[0m            \u001b[35m0.9475\u001b[0m            \u001b[31m0.9486\u001b[0m        0.1374     +  5.8722\n",
      "     24        0.1210       0.9220            0.9213            0.9220        0.2070        5.8388\n",
      "     25        \u001b[36m0.1082\u001b[0m       0.9273            0.9263            0.9273        0.2178        5.8279\n",
      "     26        0.1095       0.9241            0.9233            0.9241        0.1934        5.9469\n",
      "     27        0.1107       0.9465            0.9452            0.9465        \u001b[94m0.1281\u001b[0m        5.8898\n",
      "     28        0.1121       \u001b[32m0.9535\u001b[0m            \u001b[35m0.9522\u001b[0m            \u001b[31m0.9535\u001b[0m        \u001b[94m0.1234\u001b[0m     +  5.9492\n",
      "     29        \u001b[36m0.1005\u001b[0m       0.9184            0.9175            0.9184        0.2461        5.9828\n",
      "     30        0.1008       0.9465            0.9454            0.9465        0.1424        5.9731\n",
      "     31        \u001b[36m0.1000\u001b[0m       0.9424            0.9414            0.9424        0.1494        5.8783\n",
      "     32        \u001b[36m0.0999\u001b[0m       0.9457            0.9441            0.9457        0.1443        5.9677\n",
      "     33        \u001b[36m0.0934\u001b[0m       0.9249            0.9234            0.9249        0.2100        5.9650\n",
      "     34        0.1156       0.9441            0.9429            0.9441        0.1398        5.8617\n",
      "     35        0.1049       0.9327            0.9315            0.9327        0.1684        5.8990\n",
      "     36        \u001b[36m0.0908\u001b[0m       0.9486            0.9469            0.9486        0.1401        6.0209\n",
      "     37        0.0966       0.9388            0.9367            0.9388        0.1450        5.8861\n",
      "     38        0.0918       0.9469            0.9453            0.9469        0.1349        6.0800\n",
      "     39        \u001b[36m0.0870\u001b[0m       0.9237            0.9229            0.9237        0.1964        5.8931\n",
      "     40        \u001b[36m0.0863\u001b[0m       0.9404            0.9391            0.9404        0.1477        5.8876\n",
      "     41        \u001b[36m0.0824\u001b[0m       0.9482            0.9467            0.9482        0.1323        6.0130\n",
      "     42        0.0878       0.9359            0.9344            0.9359        0.1581        5.8540\n",
      "     43        0.0845       0.9388            0.9377            0.9388        0.1641        5.8225\n",
      "     44        \u001b[36m0.0803\u001b[0m       0.9216            0.9206            0.9216        0.2086        5.9198\n",
      "     45        \u001b[36m0.0747\u001b[0m       0.9086            0.9076            0.9086        0.2946        5.9457\n",
      "     46        0.0846       0.9388            0.9366            0.9388        0.1624        5.9468\n",
      "     47        0.0807       0.9457            0.9443            0.9457        0.1510        5.8634\n",
      "     48        0.0749       0.9261            0.9253            0.9261        0.2009        5.9886\n",
      "     49        \u001b[36m0.0731\u001b[0m       0.9376            0.9365            0.9376        0.1593        5.8755\n",
      "     50        0.0766       0.9445            0.9434            0.9445        0.1541        5.8697\n",
      "     51        \u001b[36m0.0684\u001b[0m       0.9343            0.9333            0.9343        0.1888        5.9736\n",
      "     52        0.0765       0.9473            0.9463            0.9473        0.1445        5.9998\n",
      "     53        \u001b[36m0.0653\u001b[0m       0.9404            0.9394            0.9404        0.1685        5.9220\n",
      "     54        0.0670       0.9396            0.9383            0.9396        0.1664        5.9137\n",
      "     55        \u001b[36m0.0645\u001b[0m       0.9424            0.9412            0.9424        0.1746        5.7689\n",
      "     56        \u001b[36m0.0625\u001b[0m       0.9355            0.9343            0.9355        0.2040        5.8117\n",
      "     57        \u001b[36m0.0621\u001b[0m       0.9433            0.9421            0.9433        0.1566        5.8211\n",
      "     58        \u001b[36m0.0585\u001b[0m       0.9473            0.9458            0.9473        0.1503        5.8825\n",
      "     59        0.0588       0.9518            0.9505            0.9518        0.1554        5.9119\n",
      "     60        0.0632       0.9486            0.9473            0.9486        0.1576        5.8663\n",
      "     61        \u001b[36m0.0573\u001b[0m       0.9367            0.9357            0.9367        0.2035        5.9768\n",
      "     62        \u001b[36m0.0565\u001b[0m       0.9424            0.9412            0.9424        0.1980        5.9206\n",
      "     63        \u001b[36m0.0562\u001b[0m       0.9449            0.9438            0.9449        0.1841        5.9532\n",
      "     64        \u001b[36m0.0538\u001b[0m       0.9502            0.9487            0.9502        0.1728        5.8763\n",
      "     65        \u001b[36m0.0535\u001b[0m       0.9429            0.9411            0.9429        0.1795        5.8793\n",
      "     66        \u001b[36m0.0523\u001b[0m       0.9478            0.9465            0.9478        0.1738        5.8576\n",
      "     67        0.0544       0.9367            0.9358            0.9367        0.1913        6.0581\n",
      "     68        \u001b[36m0.0513\u001b[0m       0.9465            0.9452            0.9465        0.1841        5.9086\n",
      "     69        0.0563       0.9261            0.9252            0.9261        0.2306        5.9927\n",
      "     70        \u001b[36m0.0447\u001b[0m       0.9371            0.9358            0.9371        0.2383        5.8905\n",
      "     71        0.0503       0.9465            0.9450            0.9465        0.1565        5.8501\n",
      "     72        0.0730       0.9147            0.9136            0.9147        0.2657        5.9223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        0.1695       0.9376            0.9360            0.9376        0.1513        5.9609\n",
      "     74        0.0952       0.9380            0.9367            0.9380        0.1581        5.8979\n",
      "     75        0.0792       0.9469            0.9457            0.9469        0.1565        5.8416\n",
      "     76        0.0653       0.9527            0.9513            0.9527        0.1415        5.9535\n",
      "     77        0.0512       0.9478            0.9465            0.9478        0.1515        5.9099\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0169]), 'p05': tensor([0.0272]), 'p25': tensor([0.0480]), 'p50': tensor([0.0762]), 'p75': tensor([0.1629]), 'p95': tensor([0.7811]), 'p99': tensor([2.1453]), 'max': tensor([250.7375]), 'mean': tensor([0.2232]), 'std': tensor([2.0162])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3078\u001b[0m       \u001b[32m0.8241\u001b[0m            \u001b[35m0.8240\u001b[0m            \u001b[31m0.8241\u001b[0m        \u001b[94m0.4118\u001b[0m     +  5.9085\n",
      "      2        \u001b[36m0.2170\u001b[0m       \u001b[32m0.8376\u001b[0m            \u001b[35m0.8375\u001b[0m            \u001b[31m0.8376\u001b[0m        \u001b[94m0.3875\u001b[0m     +  5.9793\n",
      "      3        \u001b[36m0.2026\u001b[0m       \u001b[32m0.8927\u001b[0m            \u001b[35m0.8907\u001b[0m            \u001b[31m0.8927\u001b[0m        \u001b[94m0.2716\u001b[0m     +  5.9200\n",
      "      4        \u001b[36m0.1963\u001b[0m       \u001b[32m0.9282\u001b[0m            \u001b[35m0.9268\u001b[0m            \u001b[31m0.9282\u001b[0m        \u001b[94m0.1732\u001b[0m     +  5.9183\n",
      "      5        \u001b[36m0.1828\u001b[0m       0.8963            0.8955            0.8963        0.2320        5.8685\n",
      "      6        \u001b[36m0.1691\u001b[0m       0.9135            0.9126            0.9135        0.2129        5.8801\n",
      "      7        0.1754       0.8824            0.8817            0.8824        0.3015        6.0081\n",
      "      8        \u001b[36m0.1541\u001b[0m       0.8980            0.8973            0.8980        0.2421        5.9801\n",
      "      9        0.1595       0.9000            0.8994            0.9000        0.2743        5.8756\n",
      "     10        \u001b[36m0.1537\u001b[0m       \u001b[32m0.9290\u001b[0m            \u001b[35m0.9277\u001b[0m            \u001b[31m0.9290\u001b[0m        \u001b[94m0.1637\u001b[0m     +  5.8824\n",
      "     11        \u001b[36m0.1455\u001b[0m       0.9061            0.9055            0.9061        0.2421        6.0360\n",
      "     12        \u001b[36m0.1406\u001b[0m       0.9163            0.9153            0.9163        0.1836        5.9041\n",
      "     13        0.1478       0.9098            0.9089            0.9098        0.2063        5.9671\n",
      "     14        \u001b[36m0.1356\u001b[0m       0.8976            0.8971            0.8976        0.2814        5.9044\n",
      "     15        \u001b[36m0.1277\u001b[0m       \u001b[32m0.9327\u001b[0m            \u001b[35m0.9309\u001b[0m            \u001b[31m0.9327\u001b[0m        0.1740     +  5.8683\n",
      "     16        0.1329       0.9257            0.9247            0.9257        0.1803        5.9198\n",
      "     17        0.1349       \u001b[32m0.9420\u001b[0m            \u001b[35m0.9403\u001b[0m            \u001b[31m0.9420\u001b[0m        \u001b[94m0.1568\u001b[0m     +  5.9713\n",
      "     18        \u001b[36m0.1247\u001b[0m       0.9106            0.9097            0.9106        0.2470        5.9309\n",
      "     19        0.1321       0.9167            0.9158            0.9167        0.2237        6.0088\n",
      "     20        \u001b[36m0.1239\u001b[0m       0.9327            0.9315            0.9327        0.1669        5.9208\n",
      "     21        \u001b[36m0.1163\u001b[0m       0.9400            0.9381            0.9400        0.1725        5.9393\n",
      "     22        0.1252       0.9388            0.9376            0.9388        0.1744        5.9185\n",
      "     23        0.1173       0.9184            0.9162            0.9184        0.2864        5.9636\n",
      "     24        0.1189       0.9400            0.9382            0.9400        \u001b[94m0.1527\u001b[0m        5.8851\n",
      "     25        \u001b[36m0.1094\u001b[0m       0.9188            0.9180            0.9188        0.2242        5.8880\n",
      "     26        \u001b[36m0.1084\u001b[0m       0.9327            0.9313            0.9327        0.1904        5.8135\n",
      "     27        \u001b[36m0.1076\u001b[0m       0.9363            0.9348            0.9363        0.1703        5.8127\n",
      "     28        0.1110       0.9273            0.9263            0.9273        0.2015        5.8813\n",
      "     29        \u001b[36m0.1073\u001b[0m       0.9265            0.9253            0.9265        0.2146        5.8707\n",
      "     30        0.1074       0.8967            0.8960            0.8967        0.2268        5.9205\n",
      "     31        \u001b[36m0.1027\u001b[0m       0.9392            0.9377            0.9392        0.1639        5.9241\n",
      "     32        0.1058       0.9376            0.9363            0.9376        0.1682        5.8616\n",
      "     33        0.1038       \u001b[32m0.9441\u001b[0m            \u001b[35m0.9423\u001b[0m            \u001b[31m0.9441\u001b[0m        \u001b[94m0.1494\u001b[0m     +  5.9079\n",
      "     34        0.1047       0.9273            0.9252            0.9273        0.2502        5.9518\n",
      "     35        0.1033       0.9367            0.9357            0.9367        0.1790        5.9736\n",
      "     36        \u001b[36m0.0970\u001b[0m       0.9376            0.9364            0.9376        0.1785        5.9089\n",
      "     37        \u001b[36m0.0966\u001b[0m       0.9216            0.9209            0.9216        0.2043        5.8849\n",
      "     38        \u001b[36m0.0951\u001b[0m       0.9404            0.9394            0.9404        0.1618        5.9528\n",
      "     39        \u001b[36m0.0877\u001b[0m       0.9392            0.9381            0.9392        0.1570        5.8799\n",
      "     40        \u001b[36m0.0856\u001b[0m       0.9229            0.9219            0.9229        0.2121        5.9893\n",
      "     41        0.0874       0.9261            0.9251            0.9261        0.1987        6.0601\n",
      "     42        0.1156       0.9176            0.9164            0.9176        0.2060        5.9924\n",
      "     43        0.1102       0.9400            0.9381            0.9400        0.1580        5.8157\n",
      "     44        0.1089       0.9400            0.9389            0.9400        0.1658        5.8335\n",
      "     45        0.0922       0.9171            0.9152            0.9171        0.1962        5.8619\n",
      "     46        0.0872       0.9347            0.9330            0.9347        0.1691        5.9040\n",
      "     47        \u001b[36m0.0705\u001b[0m       0.9437            \u001b[35m0.9424\u001b[0m            0.9437        0.1701     +  5.8805\n",
      "     48        \u001b[36m0.0632\u001b[0m       \u001b[32m0.9457\u001b[0m            \u001b[35m0.9443\u001b[0m            \u001b[31m0.9457\u001b[0m        0.1572     +  5.9600\n",
      "     49        \u001b[36m0.0597\u001b[0m       0.9437            0.9424            0.9437        0.1892        5.9164\n",
      "     50        \u001b[36m0.0577\u001b[0m       0.9437            0.9424            0.9437        0.1771        5.9664\n",
      "     51        \u001b[36m0.0565\u001b[0m       0.9412            0.9400            0.9412        0.1832        5.9048\n",
      "     52        \u001b[36m0.0552\u001b[0m       0.9441            0.9429            0.9441        0.1928        5.8703\n",
      "     53        \u001b[36m0.0540\u001b[0m       \u001b[32m0.9486\u001b[0m            \u001b[35m0.9473\u001b[0m            \u001b[31m0.9486\u001b[0m        0.1897     +  5.8995\n",
      "     54        \u001b[36m0.0512\u001b[0m       0.9441            0.9427            0.9441        0.1781        5.8563\n",
      "     55        0.0532       0.9371            0.9358            0.9371        0.1934        5.8831\n",
      "     56        \u001b[36m0.0494\u001b[0m       \u001b[32m0.9506\u001b[0m            \u001b[35m0.9495\u001b[0m            \u001b[31m0.9506\u001b[0m        0.1815     +  5.8946\n",
      "     57        0.0509       0.9420            0.9408            0.9420        0.1927        5.9773\n",
      "     58        \u001b[36m0.0483\u001b[0m       0.9416            0.9406            0.9416        0.2074        5.9169\n",
      "     59        \u001b[36m0.0465\u001b[0m       0.9343            0.9328            0.9343        0.2376        5.8764\n",
      "     60        0.0471       0.9384            0.9374            0.9384        0.2438        6.0176\n",
      "     61        \u001b[36m0.0424\u001b[0m       0.9465            0.9452            0.9465        0.2492        5.9332\n",
      "     62        0.0508       0.9429            0.9415            0.9429        0.2004        5.8578\n",
      "     63        0.0451       0.9380            0.9366            0.9380        0.2103        5.9216\n",
      "     64        0.0431       0.9478            0.9467            0.9478        0.2183        5.9329\n",
      "     65        \u001b[36m0.0420\u001b[0m       0.9433            0.9419            0.9433        0.2265        5.9741\n",
      "     66        0.0425       0.9461            0.9450            0.9461        0.2037        5.9848\n",
      "     67        \u001b[36m0.0406\u001b[0m       0.9498            0.9486            0.9498        0.2075        5.8885\n",
      "     68        \u001b[36m0.0358\u001b[0m       0.9388            0.9376            0.9388        0.2231        6.0678\n",
      "     69        0.0412       0.9404            0.9393            0.9404        0.2297        5.9280\n",
      "     70        0.0392       0.9404            0.9391            0.9404        0.2542        5.8751\n",
      "     71        0.0404       0.9441            0.9427            0.9441        0.1930        6.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.0350\u001b[0m       0.9384            0.9373            0.9384        0.2971        5.9174\n",
      "     73        0.0356       0.9404            0.9389            0.9404        0.2320        5.9657\n",
      "     74        \u001b[36m0.0339\u001b[0m       0.9408            0.9396            0.9408        0.2465        5.7850\n",
      "     75        0.0343       0.9331            0.9319            0.9331        0.2948        5.8297\n",
      "     76        0.0381       0.9424            0.9412            0.9424        0.2425        5.8893\n",
      "     77        0.0359       0.9420            0.9407            0.9420        0.2199        5.9318\n",
      "     78        \u001b[36m0.0294\u001b[0m       0.9429            0.9416            0.9429        0.2531        5.9535\n",
      "     79        0.0355       0.9376            0.9362            0.9376        0.2798        6.0183\n",
      "     80        0.0299       0.9441            0.9425            0.9441        0.2201        6.0120\n",
      "     81        0.0307       0.9429            0.9416            0.9429        0.2474        5.8800\n",
      "     82        0.0341       0.9424            0.9411            0.9424        0.2342        5.8781\n",
      "     83        \u001b[36m0.0278\u001b[0m       0.9453            0.9439            0.9453        0.2450        5.9066\n",
      "     84        0.0291       0.9273            0.9263            0.9273        0.2579        5.9505\n",
      "     85        0.0345       0.9457            0.9444            0.9457        0.2083        5.9797\n",
      "     86        \u001b[36m0.0235\u001b[0m       0.9437            0.9423            0.9437        0.2461        6.0112\n",
      "     87        0.0330       0.9412            0.9400            0.9412        0.1992        5.9473\n",
      "     88        0.0297       0.9429            0.9416            0.9429        0.2359        5.8463\n",
      "     89        0.0267       0.9298            0.9286            0.9298        0.2782        5.8798\n",
      "     90        0.0266       0.9388            0.9375            0.9388        0.2703        5.8757\n",
      "     91        0.0254       0.9408            0.9394            0.9408        0.2364        5.9081\n",
      "     92        0.0273       0.9412            0.9399            0.9412        0.2044        5.9444\n",
      "     93        \u001b[36m0.0179\u001b[0m       0.9457            0.9445            0.9457        0.2206        5.9459\n",
      "     94        \u001b[36m0.0131\u001b[0m       0.9396            0.9383            0.9396        0.2683        6.0677\n",
      "     95        \u001b[36m0.0103\u001b[0m       0.9429            0.9417            0.9429        0.2989        5.9033\n",
      "     96        0.0162       0.9429            0.9416            0.9429        0.2700        5.8668\n",
      "     97        0.0112       0.9429            0.9415            0.9429        0.2757        5.9367\n",
      "     98        0.0104       0.9429            0.9417            0.9429        0.2993        5.9064\n",
      "     99        0.0120       0.9449            0.9436            0.9449        0.2836        5.8343\n",
      "    100        0.0106       0.9392            0.9378            0.9392        0.2957        5.9185\n",
      "    101        0.0116       0.9445            0.9431            0.9445        0.2762        5.9556\n",
      "    102        \u001b[36m0.0072\u001b[0m       0.9453            0.9440            0.9453        0.2808        5.9458\n",
      "    103        \u001b[36m0.0057\u001b[0m       0.9437            0.9424            0.9437        0.3043        5.9676\n",
      "    104        0.0070       0.9449            0.9436            0.9449        0.3055        5.8764\n",
      "    105        0.0066       0.9433            0.9418            0.9433        0.3037        5.8747\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0172]), 'p05': tensor([0.0271]), 'p25': tensor([0.0482]), 'p50': tensor([0.0761]), 'p75': tensor([0.1647]), 'p95': tensor([0.7964]), 'p99': tensor([2.2115]), 'max': tensor([247.5681]), 'mean': tensor([0.2254]), 'std': tensor([1.9382])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3014\u001b[0m       \u001b[32m0.8588\u001b[0m            \u001b[35m0.8575\u001b[0m            \u001b[31m0.8588\u001b[0m        \u001b[94m0.3413\u001b[0m     +  6.8094\n",
      "      2        \u001b[36m0.2176\u001b[0m       0.8376            0.8375            0.8376        0.4049        5.9008\n",
      "      3        \u001b[36m0.1817\u001b[0m       \u001b[32m0.8833\u001b[0m            \u001b[35m0.8829\u001b[0m            \u001b[31m0.8833\u001b[0m        \u001b[94m0.3331\u001b[0m     +  5.8509\n",
      "      4        \u001b[36m0.1790\u001b[0m       0.8714            0.8707            0.8714        0.4043        5.9522\n",
      "      5        \u001b[36m0.1745\u001b[0m       \u001b[32m0.8906\u001b[0m            \u001b[35m0.8901\u001b[0m            \u001b[31m0.8906\u001b[0m        \u001b[94m0.2840\u001b[0m     +  5.9013\n",
      "      6        0.1754       0.8718            0.8716            0.8718        0.2991        5.9046\n",
      "      7        \u001b[36m0.1704\u001b[0m       \u001b[32m0.9200\u001b[0m            \u001b[35m0.9187\u001b[0m            \u001b[31m0.9200\u001b[0m        \u001b[94m0.1727\u001b[0m     +  5.9488\n",
      "      8        \u001b[36m0.1579\u001b[0m       0.9086            0.9078            0.9086        0.2353        5.8535\n",
      "      9        \u001b[36m0.1516\u001b[0m       \u001b[32m0.9335\u001b[0m            \u001b[35m0.9324\u001b[0m            \u001b[31m0.9335\u001b[0m        \u001b[94m0.1632\u001b[0m     +  5.9431\n",
      "     10        \u001b[36m0.1456\u001b[0m       0.9241            0.9228            0.9241        0.1811        5.8588\n",
      "     11        \u001b[36m0.1446\u001b[0m       0.9110            0.9102            0.9110        0.2325        5.8454\n",
      "     12        \u001b[36m0.1361\u001b[0m       0.9139            0.9128            0.9139        0.2188        5.9017\n",
      "     13        0.1415       0.9192            0.9181            0.9192        0.2434        5.8330\n",
      "     14        \u001b[36m0.1335\u001b[0m       \u001b[32m0.9404\u001b[0m            \u001b[35m0.9389\u001b[0m            \u001b[31m0.9404\u001b[0m        \u001b[94m0.1417\u001b[0m     +  5.9996\n",
      "     15        \u001b[36m0.1312\u001b[0m       0.9159            0.9152            0.9159        0.2161        5.8655\n",
      "     16        \u001b[36m0.1290\u001b[0m       0.8490            0.8490            0.8490        0.3736        5.8831\n",
      "     17        \u001b[36m0.1206\u001b[0m       \u001b[32m0.9473\u001b[0m            \u001b[35m0.9459\u001b[0m            \u001b[31m0.9473\u001b[0m        \u001b[94m0.1279\u001b[0m     +  5.8490\n",
      "     18        0.1218       0.9359            0.9343            0.9359        0.1624        5.8905\n",
      "     19        0.1251       0.9465            0.9448            0.9465        0.1348        5.8889\n",
      "     20        0.1247       0.8820            0.8817            0.8820        0.2932        6.0352\n",
      "     21        0.1260       0.9473            \u001b[35m0.9459\u001b[0m            0.9473        0.1342     +  5.9344\n",
      "     22        \u001b[36m0.1149\u001b[0m       0.9461            0.9447            0.9461        0.1383        5.9955\n",
      "     23        0.1192       0.9376            0.9366            0.9376        0.1543        5.8331\n",
      "     24        \u001b[36m0.1045\u001b[0m       0.9416            0.9405            0.9416        0.1463        5.7924\n",
      "     25        0.1232       0.9139            0.9131            0.9139        0.2329        5.9239\n",
      "     26        0.1127       0.9396            0.9381            0.9396        0.1455        5.8912\n",
      "     27        0.1094       0.9420            0.9400            0.9420        0.1513        5.9931\n",
      "     28        \u001b[36m0.0996\u001b[0m       0.9343            0.9332            0.9343        0.1696        5.8656\n",
      "     29        0.1003       \u001b[32m0.9506\u001b[0m            \u001b[35m0.9494\u001b[0m            \u001b[31m0.9506\u001b[0m        0.1430     +  5.9468\n",
      "     30        0.1872       0.9212            0.9200            0.9212        0.2015        5.9248\n",
      "     31        0.1414       0.9269            0.9259            0.9269        0.1830        5.8761\n",
      "     32        0.1235       0.9233            0.9223            0.9233        0.1809        5.6720\n",
      "     33        0.1219       0.9327            0.9314            0.9327        0.1886        5.6245\n",
      "     34        0.1104       0.9482            0.9468            0.9482        0.1488        5.6788\n",
      "     35        \u001b[36m0.0995\u001b[0m       0.9384            0.9374            0.9384        0.1589        5.7043\n",
      "     36        \u001b[36m0.0877\u001b[0m       0.9449            0.9437            0.9449        0.1360        5.7170\n",
      "     37        0.0955       0.9478            0.9462            0.9478        0.1315        5.6431\n",
      "     38        \u001b[36m0.0808\u001b[0m       0.9441            0.9422            0.9441        0.1675        5.7304\n",
      "     39        0.0842       0.9506            \u001b[35m0.9495\u001b[0m            0.9506        0.1305     +  5.6397\n",
      "     40        \u001b[36m0.0806\u001b[0m       0.9457            0.9442            0.9457        0.1436        5.6008\n",
      "     41        \u001b[36m0.0801\u001b[0m       0.9392            0.9381            0.9392        0.1614        5.6148\n",
      "     42        \u001b[36m0.0773\u001b[0m       0.9241            0.9232            0.9241        0.2182        5.7526\n",
      "     43        \u001b[36m0.0757\u001b[0m       0.9282            0.9272            0.9282        0.2118        5.6544\n",
      "     44        \u001b[36m0.0705\u001b[0m       0.9298            0.9287            0.9298        0.2174        5.5800\n",
      "     45        0.0739       0.9449            0.9439            0.9449        0.1541        5.5999\n",
      "     46        \u001b[36m0.0681\u001b[0m       0.9494            0.9481            0.9494        0.1623        5.6642\n",
      "     47        0.0719       0.9457            0.9443            0.9457        0.1529        5.6452\n",
      "     48        \u001b[36m0.0641\u001b[0m       0.9486            0.9474            0.9486        0.1600        5.6391\n",
      "     49        0.0708       \u001b[32m0.9514\u001b[0m            \u001b[35m0.9502\u001b[0m            \u001b[31m0.9514\u001b[0m        0.1530     +  5.6963\n",
      "     50        \u001b[36m0.0628\u001b[0m       0.9441            0.9424            0.9441        0.1989        5.8629\n",
      "     51        0.0693       0.9420            0.9409            0.9420        0.1440        5.8428\n",
      "     52        0.0637       0.9473            0.9461            0.9473        0.1515        5.9172\n",
      "     53        \u001b[36m0.0620\u001b[0m       0.9498            0.9485            0.9498        0.1571        5.8078\n",
      "     54        \u001b[36m0.0581\u001b[0m       0.9445            0.9434            0.9445        0.1737        5.8611\n",
      "     55        \u001b[36m0.0577\u001b[0m       0.9465            0.9454            0.9465        0.1704        5.8311\n",
      "     56        \u001b[36m0.0550\u001b[0m       0.9371            0.9361            0.9371        0.2157        5.7295\n",
      "     57        \u001b[36m0.0499\u001b[0m       0.9445            0.9433            0.9445        0.1928        5.8434\n",
      "     58        0.0512       \u001b[32m0.9518\u001b[0m            \u001b[35m0.9504\u001b[0m            \u001b[31m0.9518\u001b[0m        0.1589     +  5.8490\n",
      "     59        0.0526       0.9433            0.9421            0.9433        0.1661        5.8062\n",
      "     60        \u001b[36m0.0494\u001b[0m       0.9486            0.9473            0.9486        0.1593        6.0417\n",
      "     61        0.0547       0.9204            0.9196            0.9204        0.2801        5.9460\n",
      "     62        \u001b[36m0.0486\u001b[0m       0.9465            0.9452            0.9465        0.1661        6.0862\n",
      "     63        \u001b[36m0.0484\u001b[0m       0.9478            0.9464            0.9478        0.1609        5.9703\n",
      "     64        0.0506       0.9453            0.9443            0.9453        0.1555        6.0486\n",
      "     65        \u001b[36m0.0434\u001b[0m       \u001b[32m0.9527\u001b[0m            \u001b[35m0.9513\u001b[0m            \u001b[31m0.9527\u001b[0m        0.1602     +  6.0193\n",
      "     66        0.0448       0.9400            0.9388            0.9400        0.2228        5.7373\n",
      "     67        0.0476       0.9510            0.9497            0.9510        0.1648        5.5213\n",
      "     68        \u001b[36m0.0419\u001b[0m       0.9273            0.9263            0.9273        0.2447        5.5816\n",
      "     69        \u001b[36m0.0418\u001b[0m       0.9498            0.9486            0.9498        0.2017        5.8560\n",
      "     70        \u001b[36m0.0394\u001b[0m       0.9396            0.9384            0.9396        0.1994        6.1299\n",
      "     71        0.0419       0.9420            0.9410            0.9420        0.1966        6.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        0.0435       0.9473            0.9460            0.9473        0.1690        6.0719\n",
      "     73        \u001b[36m0.0384\u001b[0m       0.9469            0.9458            0.9469        0.1842        5.9006\n",
      "     74        0.0446       0.9478            0.9466            0.9478        0.1780        5.6358\n",
      "     75        \u001b[36m0.0370\u001b[0m       0.9490            0.9476            0.9490        0.1960        5.7884\n",
      "     76        \u001b[36m0.0343\u001b[0m       0.9486            0.9475            0.9486        0.1852        5.6599\n",
      "     77        0.0380       0.9482            0.9470            0.9482        0.1745        5.6138\n",
      "     78        0.0362       0.9380            0.9369            0.9380        0.2477        5.6123\n",
      "     79        0.0386       0.9461            0.9449            0.9461        0.2080        5.6045\n",
      "     80        0.0367       0.9461            0.9448            0.9461        0.1792        5.6430\n",
      "     81        \u001b[36m0.0316\u001b[0m       0.9478            0.9462            0.9478        0.1943        5.6407\n",
      "     82        0.0318       0.9478            0.9464            0.9478        0.1886        5.7125\n",
      "     83        \u001b[36m0.0316\u001b[0m       0.9490            0.9478            0.9490        0.1983        5.6289\n",
      "     84        \u001b[36m0.0299\u001b[0m       0.9453            0.9440            0.9453        0.2215        5.5933\n",
      "     85        0.0317       0.9473            0.9461            0.9473        0.2010        5.6519\n",
      "     86        \u001b[36m0.0274\u001b[0m       0.9490            0.9478            0.9490        0.2210        5.6599\n",
      "     87        0.0312       0.9473            0.9458            0.9473        0.1937        5.6792\n",
      "     88        0.0321       0.9367            0.9355            0.9367        0.2073        5.5752\n",
      "     89        0.0288       0.9433            0.9420            0.9433        0.2363        5.7273\n",
      "     90        \u001b[36m0.0249\u001b[0m       0.9457            0.9444            0.9457        0.1979        5.6424\n",
      "     91        0.0300       0.9424            0.9412            0.9424        0.1880        5.6996\n",
      "     92        0.0334       0.9363            0.9352            0.9363        0.2548        5.6312\n",
      "     93        \u001b[36m0.0242\u001b[0m       0.9510            0.9498            0.9510        0.1979        5.7654\n",
      "     94        0.0262       0.9441            0.9430            0.9441        0.2008        5.6145\n",
      "     95        0.0258       0.9331            0.9320            0.9331        0.2896        5.6326\n",
      "     96        \u001b[36m0.0241\u001b[0m       0.9465            0.9453            0.9465        0.2438        5.7134\n",
      "     97        \u001b[36m0.0235\u001b[0m       0.9420            0.9407            0.9420        0.2287        5.7081\n",
      "     98        0.0295       0.9482            0.9469            0.9482        0.1827        5.6441\n",
      "     99        \u001b[36m0.0221\u001b[0m       \u001b[32m0.9535\u001b[0m            \u001b[35m0.9520\u001b[0m            \u001b[31m0.9535\u001b[0m        0.1995     +  5.6226\n",
      "    100        0.0235       0.9494            0.9481            0.9494        0.2045        5.5910\n",
      "    101        0.0265       0.9506            0.9492            0.9506        0.2115        5.7084\n",
      "    102        0.0235       0.9457            0.9441            0.9457        0.2666        5.5802\n",
      "    103        0.0265       0.9429            0.9410            0.9429        0.2433        5.6737\n",
      "    104        0.0308       0.9461            0.9447            0.9461        0.2009        5.6761\n",
      "    105        0.0230       0.9367            0.9356            0.9367        0.2554        5.5919\n",
      "    106        \u001b[36m0.0152\u001b[0m       0.9482            0.9468            0.9482        0.2357        5.6904\n",
      "    107        \u001b[36m0.0121\u001b[0m       0.9429            0.9416            0.9429        0.2723        5.5933\n",
      "    108        \u001b[36m0.0106\u001b[0m       0.9469            0.9457            0.9469        0.2680        5.5884\n",
      "    109        \u001b[36m0.0084\u001b[0m       0.9469            0.9455            0.9469        0.2809        5.6175\n",
      "    110        0.0108       0.9416            0.9403            0.9416        0.2932        5.5794\n",
      "    111        \u001b[36m0.0084\u001b[0m       0.9482            0.9468            0.9482        0.2881        5.6308\n",
      "    112        0.0095       0.9494            0.9480            0.9494        0.2842        5.6196\n",
      "    113        0.0103       0.9502            0.9490            0.9502        0.2642        5.5484\n",
      "    114        0.0102       0.9473            0.9459            0.9473        0.2876        5.6107\n",
      "    115        \u001b[36m0.0081\u001b[0m       0.9498            0.9485            0.9498        0.2651        5.5782\n",
      "    116        \u001b[36m0.0070\u001b[0m       0.9478            0.9465            0.9478        0.2916        5.6003\n",
      "    117        0.0075       0.9465            0.9452            0.9465        0.3073        5.6127\n",
      "    118        0.0103       0.9384            0.9373            0.9384        0.3544        5.5111\n",
      "    119        0.0074       0.9502            0.9488            0.9502        0.2853        5.5935\n",
      "    120        0.0074       0.9437            0.9426            0.9437        0.3249        5.6182\n",
      "    121        \u001b[36m0.0061\u001b[0m       0.9478            0.9464            0.9478        0.3049        5.6206\n",
      "    122        0.0087       0.9457            0.9444            0.9457        0.2807        5.5384\n",
      "    123        0.0069       0.9437            0.9425            0.9437        0.3502        5.5818\n",
      "    124        0.0095       0.9502            0.9490            0.9502        0.2652        5.6220\n",
      "    125        0.0085       0.9469            0.9456            0.9469        0.2699        5.6114\n",
      "    126        0.0067       0.9498            0.9485            0.9498        0.2910        5.5892\n",
      "    127        \u001b[36m0.0058\u001b[0m       0.9514            0.9502            0.9514        0.2961        5.6140\n",
      "    128        0.0088       0.9486            0.9472            0.9486        0.2906        5.7097\n",
      "    129        0.0064       0.9453            0.9441            0.9453        0.3198        5.6801\n",
      "    130        0.0086       0.9473            0.9462            0.9473        0.2961        5.5974\n",
      "    131        0.0062       0.9514            0.9502            0.9514        0.2812        5.6363\n",
      "    132        0.0069       0.9478            0.9464            0.9478        0.2845        5.5549\n",
      "    133        \u001b[36m0.0054\u001b[0m       0.9461            0.9447            0.9461        0.3188        5.5175\n",
      "    134        0.0065       0.9465            0.9451            0.9465        0.3347        5.5611\n",
      "    135        0.0141       0.9473            0.9462            0.9473        0.2750        5.6534\n",
      "    136        0.0062       0.9518            0.9506            0.9518        0.2608        5.6108\n",
      "    137        \u001b[36m0.0052\u001b[0m       0.9465            0.9452            0.9465        0.2890        5.6142\n",
      "    138        0.0059       0.9506            0.9493            0.9506        0.3320        5.5588\n",
      "    139        0.0057       0.9514            0.9501            0.9514        0.3026        5.7107\n",
      "    140        0.0053       0.9461            0.9449            0.9461        0.3195        5.5129\n",
      "    141        0.0060       0.9388            0.9375            0.9388        0.3465        5.6513\n",
      "    142        0.0081       0.9441            0.9427            0.9441        0.2846        5.6074\n",
      "    143        0.0054       0.9486            0.9473            0.9486        0.3065        5.5900\n",
      "    144        0.0065       0.9473            0.9460            0.9473        0.2868        5.5875\n",
      "    145        \u001b[36m0.0024\u001b[0m       0.9469            0.9457            0.9469        0.3200        5.5408\n",
      "    146        \u001b[36m0.0022\u001b[0m       0.9424            0.9412            0.9424        0.3303        5.5683\n",
      "    147        0.0030       0.9522            0.9507            0.9522        0.3206        5.5017\n",
      "    148        0.0028       0.9465            0.9452            0.9465        0.3617        5.6058\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0172]), 'p05': tensor([0.0272]), 'p25': tensor([0.0482]), 'p50': tensor([0.0761]), 'p75': tensor([0.1634]), 'p95': tensor([0.7914]), 'p99': tensor([2.1942]), 'max': tensor([250.7378]), 'mean': tensor([0.2242]), 'std': tensor([1.9192])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3083\u001b[0m       \u001b[32m0.8800\u001b[0m            \u001b[35m0.8778\u001b[0m            \u001b[31m0.8800\u001b[0m        \u001b[94m0.2923\u001b[0m     +  5.4991\n",
      "      2        \u001b[36m0.2165\u001b[0m       0.8547            0.8542            0.8547        0.3461        5.5572\n",
      "      3        \u001b[36m0.1891\u001b[0m       0.8718            0.8715            0.8718        0.3205        5.6550\n",
      "      4        \u001b[36m0.1799\u001b[0m       \u001b[32m0.9167\u001b[0m            \u001b[35m0.9156\u001b[0m            \u001b[31m0.9167\u001b[0m        \u001b[94m0.2049\u001b[0m     +  5.5127\n",
      "      5        \u001b[36m0.1752\u001b[0m       0.8808            0.8799            0.8808        0.3037        5.5433\n",
      "      6        \u001b[36m0.1590\u001b[0m       0.8845            0.8840            0.8845        0.3258        5.5177\n",
      "      7        0.1681       0.8861            0.8848            0.8861        0.3094        5.5754\n",
      "      8        \u001b[36m0.1459\u001b[0m       0.9147            0.9134            0.9147        0.2331        5.5187\n",
      "      9        0.1465       \u001b[32m0.9273\u001b[0m            \u001b[35m0.9258\u001b[0m            \u001b[31m0.9273\u001b[0m        \u001b[94m0.2000\u001b[0m     +  5.5628\n",
      "     10        0.1534       \u001b[32m0.9298\u001b[0m            \u001b[35m0.9286\u001b[0m            \u001b[31m0.9298\u001b[0m        \u001b[94m0.1775\u001b[0m     +  5.4740\n",
      "     11        \u001b[36m0.1435\u001b[0m       0.8522            0.8520            0.8522        0.5010        5.5329\n",
      "     12        \u001b[36m0.1381\u001b[0m       0.8502            0.8502            0.8502        0.3600        5.5467\n",
      "     13        \u001b[36m0.1339\u001b[0m       0.9163            0.9151            0.9163        0.2465        5.5858\n",
      "     14        \u001b[36m0.1296\u001b[0m       0.9196            0.9184            0.9196        0.2363        5.5463\n",
      "     15        \u001b[36m0.1293\u001b[0m       0.9122            0.9114            0.9122        0.2481        5.6627\n",
      "     16        0.1298       0.9184            0.9174            0.9184        0.2484        5.5763\n",
      "     17        0.1298       0.9241            0.9226            0.9241        0.2135        5.6090\n",
      "     18        0.1334       0.9078            0.9048            0.9078        0.2573        5.4786\n",
      "     19        \u001b[36m0.1222\u001b[0m       0.9155            0.9142            0.9155        0.2111        5.5820\n",
      "     20        0.1317       \u001b[32m0.9335\u001b[0m            \u001b[35m0.9321\u001b[0m            \u001b[31m0.9335\u001b[0m        0.1807     +  5.5707\n",
      "     21        \u001b[36m0.1211\u001b[0m       \u001b[32m0.9339\u001b[0m            \u001b[35m0.9325\u001b[0m            \u001b[31m0.9339\u001b[0m        0.1841     +  5.6106\n",
      "     22        \u001b[36m0.1130\u001b[0m       0.9245            0.9236            0.9245        0.2380        5.6283\n",
      "     23        \u001b[36m0.1098\u001b[0m       0.9257            0.9235            0.9257        0.2071        5.5250\n",
      "     24        0.1110       0.9176            0.9165            0.9176        0.2223        5.5674\n",
      "     25        0.1160       \u001b[32m0.9363\u001b[0m            \u001b[35m0.9350\u001b[0m            \u001b[31m0.9363\u001b[0m        0.1865     +  5.7206\n",
      "     26        \u001b[36m0.1062\u001b[0m       0.9155            0.9147            0.9155        0.2842        5.5960\n",
      "     27        0.1085       \u001b[32m0.9404\u001b[0m            \u001b[35m0.9387\u001b[0m            \u001b[31m0.9404\u001b[0m        \u001b[94m0.1714\u001b[0m     +  5.5427\n",
      "     28        \u001b[36m0.1025\u001b[0m       0.9322            0.9308            0.9322        0.1921        5.5185\n",
      "     29        0.1056       0.9273            0.9260            0.9273        0.2027        5.5851\n",
      "     30        \u001b[36m0.0998\u001b[0m       0.9131            0.9120            0.9131        0.2664        5.4505\n",
      "     31        0.1074       0.9196            0.9187            0.9196        0.1839        5.5009\n",
      "     32        \u001b[36m0.0996\u001b[0m       0.9335            0.9324            0.9335        0.1943        5.5708\n",
      "     33        \u001b[36m0.0961\u001b[0m       \u001b[32m0.9416\u001b[0m            \u001b[35m0.9399\u001b[0m            \u001b[31m0.9416\u001b[0m        \u001b[94m0.1637\u001b[0m     +  5.5328\n",
      "     34        \u001b[36m0.0934\u001b[0m       0.9200            0.9189            0.9200        0.2446        5.5838\n",
      "     35        \u001b[36m0.0873\u001b[0m       0.9396            0.9379            0.9396        \u001b[94m0.1543\u001b[0m        5.5863\n",
      "     36        \u001b[36m0.0873\u001b[0m       0.9331            0.9317            0.9331        0.1931        5.5329\n",
      "     37        0.1043       \u001b[32m0.9465\u001b[0m            \u001b[35m0.9450\u001b[0m            \u001b[31m0.9465\u001b[0m        0.1649     +  5.5594\n",
      "     38        0.0953       0.9461            0.9445            0.9461        \u001b[94m0.1533\u001b[0m        5.6167\n",
      "     39        0.0916       0.9388            0.9375            0.9388        0.1549        5.5834\n",
      "     40        0.0898       0.9412            0.9400            0.9412        0.1542        5.5370\n",
      "     41        \u001b[36m0.0871\u001b[0m       0.9453            0.9438            0.9453        \u001b[94m0.1468\u001b[0m        5.5177\n",
      "     42        \u001b[36m0.0798\u001b[0m       0.9363            0.9352            0.9363        0.2105        5.6077\n",
      "     43        \u001b[36m0.0796\u001b[0m       0.9347            0.9334            0.9347        0.1985        5.6106\n",
      "     44        \u001b[36m0.0795\u001b[0m       0.9437            0.9422            0.9437        0.2195        5.5601\n",
      "     45        0.0831       0.9237            0.9227            0.9237        0.2253        5.5492\n",
      "     46        \u001b[36m0.0773\u001b[0m       0.9437            0.9421            0.9437        0.1631        5.5075\n",
      "     47        0.0794       0.9453            0.9441            0.9453        0.1739        5.5615\n",
      "     48        \u001b[36m0.0739\u001b[0m       0.9184            0.9172            0.9184        0.2535        5.6721\n",
      "     49        0.0775       0.9388            0.9376            0.9388        0.2151        5.6139\n",
      "     50        0.0934       0.9371            0.9357            0.9371        0.1767        5.6005\n",
      "     51        0.0779       0.9371            0.9357            0.9371        0.1979        5.5663\n",
      "     52        0.0746       0.9437            0.9424            0.9437        0.1672        5.5234\n",
      "     53        \u001b[36m0.0699\u001b[0m       0.9404            0.9389            0.9404        0.1958        5.5585\n",
      "     54        0.0725       0.9298            0.9287            0.9298        0.2207        5.5555\n",
      "     55        \u001b[36m0.0655\u001b[0m       0.9388            0.9371            0.9388        0.1985        5.5315\n",
      "     56        0.0678       0.9147            0.9139            0.9147        0.2801        5.6276\n",
      "     57        \u001b[36m0.0639\u001b[0m       0.9371            0.9354            0.9371        0.1936        5.5598\n",
      "     58        \u001b[36m0.0618\u001b[0m       0.9457            0.9443            0.9457        0.1763        5.6099\n",
      "     59        \u001b[36m0.0570\u001b[0m       0.9310            0.9299            0.9310        0.2859        5.6094\n",
      "     60        0.0605       0.9204            0.9188            0.9204        0.3143        5.5276\n",
      "     61        0.0597       0.9392            0.9379            0.9392        0.2175        5.5379\n",
      "     62        \u001b[36m0.0542\u001b[0m       \u001b[32m0.9469\u001b[0m            \u001b[35m0.9453\u001b[0m            \u001b[31m0.9469\u001b[0m        0.1878     +  5.6522\n",
      "     63        0.0550       0.9465            0.9451            0.9465        0.1917        5.5348\n",
      "     64        0.0568       0.9384            0.9369            0.9384        0.1799        5.5142\n",
      "     65        \u001b[36m0.0500\u001b[0m       0.9343            0.9325            0.9343        0.2149        5.5549\n",
      "     66        0.0595       0.9396            0.9382            0.9396        0.2020        5.5609\n",
      "     67        0.0532       0.9220            0.9206            0.9220        0.2615        5.5362\n",
      "     68        0.0563       0.9429            0.9414            0.9429        0.1902        5.5833\n",
      "     69        \u001b[36m0.0490\u001b[0m       0.9322            0.9307            0.9322        0.2591        5.5392\n",
      "     70        0.0524       0.9376            0.9364            0.9376        0.2040        5.5519\n",
      "     71        0.0500       0.9261            0.9252            0.9261        0.3048        5.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        \u001b[36m0.0473\u001b[0m       0.9351            0.9334            0.9351        0.2461        5.5304\n",
      "     73        0.0489       0.9359            0.9345            0.9359        0.2198        5.5693\n",
      "     74        \u001b[36m0.0447\u001b[0m       0.9453            0.9437            0.9453        0.2199        5.5501\n",
      "     75        \u001b[36m0.0416\u001b[0m       0.9306            0.9296            0.9306        0.2563        5.5557\n",
      "     76        0.0470       0.9318            0.9292            0.9318        0.2173        5.5635\n",
      "     77        0.0434       0.9392            0.9381            0.9392        0.2501        5.5660\n",
      "     78        0.0421       0.9437            0.9423            0.9437        0.2656        5.6148\n",
      "     79        \u001b[36m0.0393\u001b[0m       0.9257            0.9243            0.9257        0.3174        5.5871\n",
      "     80        0.0458       0.9380            0.9368            0.9380        0.2297        5.4800\n",
      "     81        0.0424       0.9282            0.9268            0.9282        0.3067        5.6473\n",
      "     82        0.0462       0.9424            0.9406            0.9424        0.1923        5.6496\n",
      "     83        \u001b[36m0.0348\u001b[0m       0.9380            0.9366            0.9380        0.2322        5.5964\n",
      "     84        0.0392       0.9376            0.9361            0.9376        0.2416        5.5945\n",
      "     85        \u001b[36m0.0322\u001b[0m       0.9335            0.9315            0.9335        0.2729        5.5152\n",
      "     86        0.0379       0.9376            0.9354            0.9376        0.2687        5.5597\n",
      "     87        0.0429       0.9392            0.9372            0.9392        0.2200        5.5598\n",
      "     88        0.0328       0.9420            0.9407            0.9420        0.2425        5.5560\n",
      "     89        0.0329       0.9404            0.9391            0.9404        0.2257        5.5623\n",
      "     90        \u001b[36m0.0279\u001b[0m       0.9367            0.9352            0.9367        0.2713        5.5938\n",
      "     91        0.0413       0.9416            0.9405            0.9416        0.2042        5.6155\n",
      "     92        0.0307       0.9208            0.9195            0.9208        0.3713        5.5595\n",
      "     93        0.0340       0.9388            0.9373            0.9388        0.2274        5.6294\n",
      "     94        0.0373       0.9429            0.9413            0.9429        0.2155        5.5624\n",
      "     95        0.0319       0.9449            0.9433            0.9449        0.2262        5.5707\n",
      "     96        0.0302       0.9437            0.9421            0.9437        0.2128        5.5221\n",
      "     97        \u001b[36m0.0203\u001b[0m       0.9441            0.9427            0.9441        0.2434        5.5712\n",
      "     98        \u001b[36m0.0150\u001b[0m       0.9339            0.9324            0.9339        0.3131        5.6097\n",
      "     99        0.0186       0.9420            0.9405            0.9420        0.2698        5.5316\n",
      "    100        \u001b[36m0.0116\u001b[0m       0.9445            0.9430            0.9445        0.2884        5.5518\n",
      "    101        0.0145       0.9441            0.9426            0.9441        0.2728        5.5144\n",
      "    102        0.0140       0.9433            0.9419            0.9433        0.2799        5.6009\n",
      "    103        0.0128       0.9420            0.9406            0.9420        0.2501        5.4706\n",
      "    104        \u001b[36m0.0086\u001b[0m       0.9404            0.9390            0.9404        0.3128        5.5760\n",
      "    105        0.0118       0.9408            0.9390            0.9408        0.2663        5.5524\n",
      "    106        0.0121       0.9465            0.9452            0.9465        0.2634        5.5709\n",
      "    107        0.0129       0.9457            0.9442            0.9457        0.2729        5.5694\n",
      "    108        0.0128       0.9433            0.9417            0.9433        0.3101        5.6374\n",
      "    109        0.0097       0.9437            0.9422            0.9437        0.3422        5.5521\n",
      "    110        0.0133       0.9384            0.9368            0.9384        0.2991        5.5718\n",
      "    111        0.0108       0.9429            0.9414            0.9429        0.3013        5.5744\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:09<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0.]), 'p01': tensor([0.0170]), 'p05': tensor([0.0272]), 'p25': tensor([0.0484]), 'p50': tensor([0.0764]), 'p75': tensor([0.1635]), 'p95': tensor([0.7942]), 'p99': tensor([2.1700]), 'max': tensor([250.7382]), 'mean': tensor([0.2241]), 'std': tensor([1.9374])}\n",
      "  epoch    train_loss    valid_acc    valid_f1_macro    valid_f1_micro    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ----------------  ----------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3016\u001b[0m       \u001b[32m0.9090\u001b[0m            \u001b[35m0.9067\u001b[0m            \u001b[31m0.9090\u001b[0m        \u001b[94m0.2489\u001b[0m     +  5.5331\n",
      "      2        \u001b[36m0.2077\u001b[0m       0.8849            0.8840            0.8849        0.2809        5.5577\n",
      "      3        \u001b[36m0.1824\u001b[0m       \u001b[32m0.9171\u001b[0m            \u001b[35m0.9160\u001b[0m            \u001b[31m0.9171\u001b[0m        \u001b[94m0.2160\u001b[0m     +  5.5997\n",
      "      4        \u001b[36m0.1770\u001b[0m       0.9110            0.9083            0.9110        \u001b[94m0.2148\u001b[0m        5.5457\n",
      "      5        \u001b[36m0.1660\u001b[0m       0.9167            0.9154            0.9167        \u001b[94m0.1826\u001b[0m        5.5753\n",
      "      6        \u001b[36m0.1567\u001b[0m       0.8959            0.8952            0.8959        0.2504        5.5337\n",
      "      7        \u001b[36m0.1566\u001b[0m       0.8498            0.8495            0.8498        0.3131        5.5558\n",
      "      8        0.1570       0.9098            0.9089            0.9098        0.2197        5.6029\n",
      "      9        \u001b[36m0.1480\u001b[0m       \u001b[32m0.9265\u001b[0m            \u001b[35m0.9253\u001b[0m            \u001b[31m0.9265\u001b[0m        \u001b[94m0.1734\u001b[0m     +  5.7127\n",
      "     10        \u001b[36m0.1429\u001b[0m       0.9086            0.9045            0.9086        0.2306        5.4970\n",
      "     11        \u001b[36m0.1404\u001b[0m       0.9261            0.9235            0.9261        0.1950        5.5396\n",
      "     12        \u001b[36m0.1404\u001b[0m       \u001b[32m0.9273\u001b[0m            0.9253            \u001b[31m0.9273\u001b[0m        \u001b[94m0.1723\u001b[0m        5.4897\n",
      "     13        \u001b[36m0.1329\u001b[0m       \u001b[32m0.9322\u001b[0m            \u001b[35m0.9308\u001b[0m            \u001b[31m0.9322\u001b[0m        0.1732     +  5.5326\n",
      "     14        0.1507       0.9245            0.9235            0.9245        0.1944        5.6795\n",
      "     15        0.1402       0.9229            0.9217            0.9229        0.1885        5.5621\n",
      "     16        \u001b[36m0.1278\u001b[0m       0.9245            0.9236            0.9245        0.1998        5.6376\n",
      "     17        0.1332       0.9188            0.9179            0.9188        0.1901        5.5801\n",
      "     18        \u001b[36m0.1191\u001b[0m       \u001b[32m0.9367\u001b[0m            \u001b[35m0.9352\u001b[0m            \u001b[31m0.9367\u001b[0m        0.1758     +  5.5770\n",
      "     19        0.1225       0.9322            0.9307            0.9322        \u001b[94m0.1665\u001b[0m        5.5157\n",
      "     20        0.1202       0.9016            0.9006            0.9016        0.2622        5.6377\n",
      "     21        \u001b[36m0.1170\u001b[0m       0.8902            0.8897            0.8902        0.2742        5.5370\n",
      "     22        \u001b[36m0.1104\u001b[0m       0.9163            0.9151            0.9163        0.2046        5.5669\n",
      "     23        \u001b[36m0.1094\u001b[0m       0.9343            0.9331            0.9343        \u001b[94m0.1653\u001b[0m        5.5847\n",
      "     24        0.1173       0.9253            0.9235            0.9253        0.1837        5.5948\n",
      "     25        0.1097       0.9037            0.9027            0.9037        0.2806        5.5827\n",
      "     26        0.1136       0.9143            0.9133            0.9143        0.1938        5.5569\n",
      "     27        0.1190       0.9302            0.9290            0.9302        0.1763        5.5270\n",
      "     28        0.1137       0.9216            0.9201            0.9216        0.1879        5.5886\n",
      "     29        \u001b[36m0.1023\u001b[0m       0.9339            0.9329            0.9339        0.1812        5.5457\n",
      "     30        \u001b[36m0.0977\u001b[0m       0.9359            0.9346            0.9359        0.1677        5.5557\n",
      "     31        \u001b[36m0.0928\u001b[0m       0.9363            0.9351            0.9363        \u001b[94m0.1638\u001b[0m        5.5375\n",
      "     32        0.0956       0.9339            0.9327            0.9339        0.1783        5.5491\n",
      "     33        0.0961       0.9367            \u001b[35m0.9354\u001b[0m            0.9367        0.1740     +  5.6622\n",
      "     34        0.0991       \u001b[32m0.9412\u001b[0m            \u001b[35m0.9396\u001b[0m            \u001b[31m0.9412\u001b[0m        \u001b[94m0.1459\u001b[0m     +  5.5599\n",
      "     35        \u001b[36m0.0900\u001b[0m       0.9265            0.9254            0.9265        0.1827        5.5408\n",
      "     36        0.0906       0.9302            0.9291            0.9302        0.1880        5.4922\n",
      "     37        \u001b[36m0.0864\u001b[0m       0.9245            0.9235            0.9245        0.2214        5.4988\n",
      "     38        \u001b[36m0.0810\u001b[0m       0.9392            0.9379            0.9392        0.1524        5.6516\n",
      "     39        0.0934       \u001b[32m0.9416\u001b[0m            \u001b[35m0.9400\u001b[0m            \u001b[31m0.9416\u001b[0m        0.1582     +  5.5823\n",
      "     40        0.0947       0.9412            \u001b[35m0.9400\u001b[0m            0.9412        0.1675     +  5.5668\n",
      "     41        0.0848       0.9233            0.9221            0.9233        0.2196        5.6054\n",
      "     42        0.0899       0.9318            0.9300            0.9318        0.1959        5.5537\n",
      "     43        0.0822       0.9371            0.9353            0.9371        0.1765        5.5759\n",
      "     44        \u001b[36m0.0733\u001b[0m       0.9302            0.9289            0.9302        0.1997        5.6188\n",
      "     45        0.0769       0.9351            0.9326            0.9351        0.1883        5.6479\n",
      "     46        0.0824       0.9265            0.9255            0.9265        0.2156        5.5921\n",
      "     47        0.0746       0.9298            0.9282            0.9298        0.1884        5.5956\n",
      "     48        0.0738       0.8539            0.8537            0.8539        0.3841        5.6254\n",
      "     49        \u001b[36m0.0650\u001b[0m       0.9363            0.9351            0.9363        0.1780        5.5259\n",
      "     50        0.0683       0.9245            0.9232            0.9245        0.2478        5.5790\n",
      "     51        0.0723       0.9404            0.9387            0.9404        0.1719        5.5727\n",
      "     52        0.0664       0.9298            0.9286            0.9298        0.1987        5.5868\n",
      "     53        \u001b[36m0.0639\u001b[0m       0.9396            0.9381            0.9396        0.1881        5.6559\n",
      "     54        0.0667       0.9347            0.9335            0.9347        0.2197        5.5646\n",
      "     55        0.0683       0.9367            0.9352            0.9367        0.2034        5.5342\n",
      "     56        0.0712       0.9286            0.9274            0.9286        0.1849        5.5198\n",
      "     57        0.0643       0.9314            0.9302            0.9314        0.1810        5.5118\n",
      "     58        \u001b[36m0.0587\u001b[0m       0.9286            0.9268            0.9286        0.1961        5.5496\n",
      "     59        0.0599       0.9367            0.9354            0.9367        0.2235        5.5909\n",
      "     60        0.0602       0.9376            0.9363            0.9376        0.1920        5.5824\n",
      "     61        0.0628       0.9388            0.9373            0.9388        0.1696        5.5878\n",
      "     62        \u001b[36m0.0571\u001b[0m       0.9392            0.9375            0.9392        0.1870        5.5181\n",
      "     63        \u001b[36m0.0542\u001b[0m       0.9216            0.9206            0.9216        0.2572        5.6386\n",
      "     64        \u001b[36m0.0539\u001b[0m       \u001b[32m0.9441\u001b[0m            \u001b[35m0.9423\u001b[0m            \u001b[31m0.9441\u001b[0m        0.1818     +  5.5074\n",
      "     65        \u001b[36m0.0488\u001b[0m       0.9400            0.9383            0.9400        0.2056        5.5593\n",
      "     66        0.0524       0.9278            0.9264            0.9278        0.2201        5.5933\n",
      "     67        0.0497       0.9380            0.9366            0.9380        0.1774        5.6087\n",
      "     68        0.0505       0.9196            0.9186            0.9196        0.2622        5.5542\n",
      "     69        0.0531       0.9392            0.9380            0.9392        0.2051        5.5844\n",
      "     70        0.0519       \u001b[32m0.9469\u001b[0m            \u001b[35m0.9454\u001b[0m            \u001b[31m0.9469\u001b[0m        0.1804     +  5.5215\n",
      "     71        \u001b[36m0.0470\u001b[0m       0.9029            0.9016            0.9029        0.2853        5.5235\n",
      "     72        \u001b[36m0.0464\u001b[0m       0.9367            0.9354            0.9367        0.2484        5.4801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        0.0468       0.9429            0.9413            0.9429        0.2012        5.5413\n",
      "     74        \u001b[36m0.0414\u001b[0m       0.9355            0.9343            0.9355        0.2230        5.5547\n",
      "     75        0.0433       0.9380            0.9366            0.9380        0.2154        5.6219\n",
      "     76        0.0455       0.9433            0.9418            0.9433        0.1730        5.5995\n",
      "     77        0.0421       0.9343            0.9330            0.9343        0.2013        5.5821\n",
      "     78        \u001b[36m0.0386\u001b[0m       0.9302            0.9289            0.9302        0.2054        5.5968\n",
      "     79        \u001b[36m0.0354\u001b[0m       0.9331            0.9318            0.9331        0.2217        5.6147\n",
      "     80        0.0387       0.9302            0.9291            0.9302        0.2302        5.5687\n",
      "     81        0.0380       0.9396            0.9384            0.9396        0.2235        5.5275\n",
      "     82        0.0395       0.9273            0.9263            0.9273        0.2353        5.5363\n",
      "     83        0.0388       0.9429            0.9414            0.9429        0.2035        5.4652\n",
      "     84        0.0362       0.9441            0.9427            0.9441        0.1777        5.5695\n",
      "     85        \u001b[36m0.0285\u001b[0m       0.9384            0.9373            0.9384        0.2170        5.4955\n",
      "     86        0.0357       0.9396            0.9384            0.9396        0.2184        5.5915\n",
      "     87        0.0341       0.9376            0.9364            0.9376        0.2463        5.6239\n",
      "     88        0.0342       0.9302            0.9290            0.9302        0.2536        5.5773\n",
      "     89        0.0322       0.9453            0.9440            0.9453        0.2203        5.5341\n",
      "     90        0.0300       0.9412            0.9397            0.9412        0.2257        5.5376\n",
      "     91        0.0306       0.9437            0.9420            0.9437        0.1969        5.5700\n",
      "     92        \u001b[36m0.0248\u001b[0m       \u001b[32m0.9482\u001b[0m            \u001b[35m0.9470\u001b[0m            \u001b[31m0.9482\u001b[0m        0.2133     +  5.5561\n",
      "     93        \u001b[36m0.0184\u001b[0m       0.9469            0.9456            0.9469        0.2194        5.5633\n",
      "     94        \u001b[36m0.0120\u001b[0m       0.9445            0.9434            0.9445        0.2845        5.4898\n",
      "     95        0.0233       0.9473            0.9460            0.9473        0.1919        5.5230\n",
      "     96        0.0145       \u001b[32m0.9494\u001b[0m            \u001b[35m0.9482\u001b[0m            \u001b[31m0.9494\u001b[0m        0.2367     +  5.5274\n",
      "     97        0.0151       0.9433            0.9421            0.9433        0.2308        5.6023\n",
      "     98        0.0138       0.9424            0.9412            0.9424        0.2496        5.5036\n",
      "     99        \u001b[36m0.0116\u001b[0m       0.9457            0.9444            0.9457        0.2524        5.5136\n",
      "    100        \u001b[36m0.0114\u001b[0m       0.9478            0.9467            0.9478        0.2693        5.6072\n",
      "    101        0.0121       0.9449            0.9437            0.9449        0.2937        5.6124\n",
      "    102        0.0140       0.9449            0.9435            0.9449        0.2514        5.5597\n",
      "    103        0.0126       0.9478            0.9463            0.9478        0.2574        5.4915\n",
      "    104        0.0167       0.9445            0.9431            0.9445        0.2486        5.5969\n",
      "    105        0.0158       0.9400            0.9387            0.9400        0.2582        5.5495\n",
      "    106        \u001b[36m0.0106\u001b[0m       0.9461            0.9449            0.9461        0.2901        5.5795\n",
      "    107        0.0148       0.9449            0.9436            0.9449        0.2331        5.4878\n",
      "    108        0.0127       0.9449            0.9436            0.9449        0.2435        5.5616\n",
      "    109        0.0138       0.9482            0.9467            0.9482        0.2406        5.6758\n",
      "    110        \u001b[36m0.0102\u001b[0m       0.9420            0.9408            0.9420        0.2895        5.6099\n",
      "    111        0.0113       0.9347            0.9334            0.9347        0.2895        5.5422\n",
      "    112        0.0169       0.9396            0.9384            0.9396        0.2524        5.5755\n",
      "    113        0.0113       0.9355            0.9341            0.9355        0.3270        5.5822\n",
      "    114        0.0125       0.9429            0.9412            0.9429        0.2603        5.5524\n",
      "    115        \u001b[36m0.0082\u001b[0m       0.9441            0.9428            0.9441        0.2672        5.4885\n",
      "    116        0.0131       0.9420            0.9406            0.9420        0.2851        5.5774\n",
      "    117        0.0116       0.9384            0.9371            0.9384        0.3081        5.5022\n",
      "    118        0.0105       0.9437            0.9421            0.9437        0.2627        5.5799\n",
      "    119        \u001b[36m0.0076\u001b[0m       0.9461            0.9448            0.9461        0.2941        5.6338\n",
      "    120        0.0138       0.9376            0.9362            0.9376        0.2842        5.5476\n",
      "    121        \u001b[36m0.0069\u001b[0m       0.9429            0.9414            0.9429        0.3081        5.5080\n",
      "    122        0.0078       0.9412            0.9398            0.9412        0.3043        5.5061\n",
      "    123        0.0134       0.9457            0.9443            0.9457        0.2370        5.5308\n",
      "    124        0.0098       0.9437            0.9422            0.9437        0.2987        5.5442\n",
      "    125        0.0110       0.9461            0.9448            0.9461        0.2465        5.5972\n",
      "    126        0.0085       0.9310            0.9297            0.9310        0.3223        5.5910\n",
      "    127        \u001b[36m0.0068\u001b[0m       0.9404            0.9390            0.9404        0.3364        5.5309\n",
      "    128        0.0176       0.9424            0.9409            0.9424        0.2859        5.5228\n",
      "    129        0.0102       0.9457            0.9444            0.9457        0.2763        5.5766\n",
      "    130        0.0110       0.9404            0.9391            0.9404        0.2708        5.5594\n",
      "    131        0.0078       0.9416            0.9404            0.9416        0.2954        5.6133\n",
      "    132        0.0153       0.9465            0.9451            0.9465        0.2286        5.5424\n",
      "    133        0.0080       0.9367            0.9355            0.9367        0.2835        5.5287\n",
      "    134        \u001b[36m0.0048\u001b[0m       0.9465            0.9452            0.9465        0.2844        5.5068\n",
      "    135        \u001b[36m0.0041\u001b[0m       \u001b[32m0.9498\u001b[0m            \u001b[35m0.9485\u001b[0m            \u001b[31m0.9498\u001b[0m        0.2964     +  5.6233\n",
      "    136        0.0061       0.9453            0.9440            0.9453        0.2955        5.5177\n",
      "    137        \u001b[36m0.0040\u001b[0m       0.9445            0.9432            0.9445        0.2815        5.5445\n",
      "    138        \u001b[36m0.0039\u001b[0m       0.9478            0.9464            0.9478        0.2853        5.6439\n",
      "    139        0.0048       0.9445            0.9432            0.9445        0.2864        5.5512\n",
      "    140        \u001b[36m0.0027\u001b[0m       0.9453            0.9441            0.9453        0.2990        5.5712\n",
      "    141        0.0033       0.9433            0.9420            0.9433        0.3338        5.5567\n",
      "    142        0.0028       0.9363            0.9350            0.9363        0.3546        5.5638\n",
      "    143        0.0030       0.9355            0.9344            0.9355        0.4048        5.4706\n",
      "    144        0.0035       0.9388            0.9375            0.9388        0.3794        5.5241\n",
      "    145        0.0058       0.9429            0.9416            0.9429        0.3174        5.6144\n",
      "    146        0.0036       0.9465            0.9451            0.9465        0.3060        5.5498\n",
      "    147        0.0029       0.9490            0.9477            0.9490        0.3028        5.5548\n",
      "    148        \u001b[36m0.0020\u001b[0m       0.9486            0.9473            0.9486        0.3036        5.5101\n",
      "    149        \u001b[36m0.0006\u001b[0m       0.9482            0.9469            0.9482        0.3169        5.5082\n",
      "    150        0.0013       0.9486            0.9473            0.9486        0.3180        5.5816\n",
      "    151        0.0006       0.9473            0.9462            0.9473        0.3421        5.5239\n",
      "    152        0.0016       0.9457            0.9445            0.9457        0.3438        5.5612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    153        0.0020       0.9469            0.9456            0.9469        0.3390        5.5294\n",
      "    154        0.0010       0.9445            0.9432            0.9445        0.3665        5.5588\n",
      "    155        0.0013       0.9445            0.9431            0.9445        0.3504        5.4978\n",
      "    156        0.0012       0.9453            0.9440            0.9453        0.3519        5.5185\n",
      "    157        0.0012       0.9465            0.9452            0.9465        0.3511        5.5515\n",
      "    158        \u001b[36m0.0005\u001b[0m       0.9441            0.9428            0.9441        0.3604        5.6302\n",
      "    159        0.0008       0.9457            0.9444            0.9457        0.3563        5.6079\n",
      "    160        \u001b[36m0.0004\u001b[0m       0.9465            0.9452            0.9465        0.3564        5.5553\n",
      "    161        0.0007       0.9478            0.9464            0.9478        0.3532        5.5694\n",
      "    162        0.0014       0.9486            0.9472            0.9486        0.3511        5.4995\n",
      "    163        0.0005       0.9461            0.9448            0.9461        0.3534        5.5247\n",
      "    164        0.0009       0.9461            0.9448            0.9461        0.3535        5.4975\n",
      "    165        0.0010       0.9473            0.9460            0.9473        0.3613        5.5968\n",
      "    166        0.0009       0.9461            0.9448            0.9461        0.3657        5.6555\n",
      "    167        0.0017       0.9469            0.9455            0.9469        0.3562        5.5348\n",
      "    168        0.0014       0.9449            0.9435            0.9449        0.3608        5.5749\n",
      "    169        0.0010       0.9465            0.9451            0.9465        0.3468        5.5312\n",
      "    170        0.0007       0.9445            0.9431            0.9445        0.3549        5.5428\n",
      "    171        0.0006       0.9457            0.9444            0.9457        0.3566        5.4980\n",
      "    172        0.0004       0.9453            0.9439            0.9453        0.3550        5.6492\n",
      "    173        0.0005       0.9461            0.9447            0.9461        0.3535        5.5204\n",
      "    174        0.0005       0.9461            0.9448            0.9461        0.3608        5.5762\n",
      "    175        0.0015       0.9445            0.9431            0.9445        0.3625        5.5048\n",
      "    176        0.0011       0.9449            0.9435            0.9449        0.3592        5.5685\n",
      "    177        \u001b[36m0.0003\u001b[0m       0.9437            0.9423            0.9437        0.3557        5.5250\n",
      "    178        0.0005       0.9465            0.9452            0.9465        0.3563        5.6296\n",
      "    179        0.0004       0.9449            0.9436            0.9449        0.3641        5.5962\n",
      "    180        0.0004       0.9457            0.9444            0.9457        0.3623        5.5989\n",
      "    181        0.0005       0.9465            0.9452            0.9465        0.3624        5.5526\n",
      "    182        0.0009       0.9461            0.9448            0.9461        0.3602        5.4794\n",
      "    183        \u001b[36m0.0002\u001b[0m       0.9469            0.9456            0.9469        0.3615        5.5248\n",
      "    184        0.0009       0.9461            0.9449            0.9461        0.3673        5.5349\n",
      "Stopping since valid_f1_macro has not improved in the last 50 epochs.\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from scifAI.dl.models import PretrainedModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_top_channels = 1\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed_value, shuffle=True)\n",
    "\n",
    "\n",
    "results_with_best_channels = pd.DataFrame(columns = [\"method\",\n",
    "                                                     \"f1_micro\",\n",
    "                                                     \"f1_macro\",\n",
    "                                                     \"accuracy\"])\n",
    "\n",
    "for met in interpretation_methods:\n",
    "    selected_channels = select_top_channels(channel_importance, met , num_top_channels)\n",
    "    channels = np.asarray([ \"Ch\" + str(i) for i in selected_channels])\n",
    "    \n",
    "    print(met, selected_channels)\n",
    "    num_of_all_channels = len(channels)\n",
    "    all_channels = np.arange(num_of_all_channels)\n",
    "    for train_index, test_index in skf.split(metadata.index.tolist(), metadata[\"label\"]):\n",
    "        train_index, validation_index, _, _ = train_test_split(train_index, \n",
    "                                                    metadata.loc[train_index,\"label\"].index.tolist(), \n",
    "                                                    stratify = metadata.loc[train_index,\"label\"].tolist(),\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=seed_value)\n",
    "        label_map = dict(zip(sorted(set(metadata.loc[train_index, \"label\"])), \n",
    "                     np.arange(len(set(metadata.loc[train_index, \"label\"])))))\n",
    "\n",
    "        set_of_interesting_classes = metadata.label.unique().tolist()\n",
    "\n",
    "        num_classes = len(metadata.label.unique())\n",
    "        \n",
    "        train_dataset = DatasetGenerator(metadata=metadata.loc[train_index,:],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=transforms.Compose([ ] ))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        statistics = get_statistics(train_loader, selected_channels=selected_channels)\n",
    "        \n",
    "        stats = dict()\n",
    "        stats[\"lower_bound\"] = torch.tensor([statistics['p01'][0]])\n",
    "        stats[\"upper_bound\"] = torch.tensor([statistics['p99'][0]])\n",
    "\n",
    "        train_transform = [ \n",
    "                MinMaxScaler(           min_in =  stats[\"lower_bound\"] , \n",
    "                                        max_in =  stats[\"upper_bound\"] , \n",
    "                                        min_out =  0. , \n",
    "                                        max_out =  1.),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                AddGaussianNoise(mean=0., std=0.01),\n",
    "        ]\n",
    "\n",
    "        validation_transform =  [ \n",
    "                MinMaxScaler(           min_in =  stats[\"lower_bound\"] , \n",
    "                                        max_in =  stats[\"upper_bound\"] , \n",
    "                                        min_out =  0. , \n",
    "                                        max_out =  1.),\n",
    "        ]\n",
    "\n",
    "        test_transform =  [ \n",
    "                MinMaxScaler(           min_in =  stats[\"lower_bound\"] , \n",
    "                                        max_in =  stats[\"upper_bound\"] , \n",
    "                                        min_out =  0. , \n",
    "                                        max_out =  1.),\n",
    "        ]\n",
    "        train_loader = None\n",
    "        \n",
    "        train_dataset = DatasetGenerator(metadata=metadata.loc[train_index,:],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor, \n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform= transforms.Compose(train_transform))\n",
    "\n",
    "        validation_dataset = DatasetGenerator(metadata=metadata.loc[validation_index,:],\n",
    "                                              label_map=label_map,\n",
    "                                              selected_channels=selected_channels,\n",
    "                                              scaling_factor=scaling_factor,\n",
    "                                              reshape_size=reshape_size,\n",
    "                                              transform=transforms.Compose(validation_transform))\n",
    "        \n",
    "        test_dataset = DatasetGenerator(metadata=metadata.loc[test_index,:],\n",
    "                                        label_map=label_map,\n",
    "                                        selected_channels=selected_channels,\n",
    "                                        scaling_factor=scaling_factor,\n",
    "                                        reshape_size=reshape_size,\n",
    "                                        transform=\n",
    "                                        transforms.Compose(test_transform))\n",
    "        \n",
    "        \n",
    "\n",
    "        resnet18_modified = PretrainedModel(num_channels = len(selected_channels),\n",
    "                                             num_classes = len(set_of_interesting_classes), \n",
    "                                             pretrained = True)\n",
    "        \n",
    "        lr_scheduler = LRScheduler(policy='ReduceLROnPlateau', factor=0.5, patience=5)\n",
    "\n",
    "        epoch_scoring_f1_micro = EpochScoring(\"f1_micro\", \n",
    "                                     name =  \"valid_f1_micro\", \n",
    "                                     on_train = False,\n",
    "                                     lower_is_better = False)\n",
    "\n",
    "        epoch_scoring_f1_macro = EpochScoring(\"f1_macro\", \n",
    "                                     name =  \"valid_f1_macro\", \n",
    "                                     on_train = False,\n",
    "                                     lower_is_better = False)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='valid_f1_macro', \n",
    "                                       patience=50, \n",
    "                                       threshold=0.0001, \n",
    "                                       threshold_mode='rel', \n",
    "                                       lower_is_better=False)\n",
    "\n",
    "        checkpoint = Checkpoint(f_params='apoptotic_cells_DL_method_comparison.pth',\n",
    "                                monitor='valid_f1_macro_best', load_best=True)\n",
    "        \n",
    "        net = NeuralNetClassifier(    \n",
    "            resnet18_modified, \n",
    "            criterion=nn.CrossEntropyLoss,\n",
    "            lr=0.001,\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=1000,\n",
    "            optimizer=optim.Adam,\n",
    "            iterator_train__shuffle=True,\n",
    "            iterator_train__num_workers=num_workers,\n",
    "            iterator_valid__shuffle=False,\n",
    "            iterator_valid__num_workers=2,\n",
    "            callbacks=[lr_scheduler, epoch_scoring_f1_micro, \n",
    "                       epoch_scoring_f1_macro, \n",
    "                       early_stopping, checkpoint],\n",
    "            train_split=predefined_split(validation_dataset),\n",
    "            device=\"cuda\",\n",
    "            warm_start=True)\n",
    "        net = net.fit(train_dataset, y = None)\n",
    "        net.module.load_state_dict(torch.load('apoptotic_cells_DL_method_comparison.pth')) \n",
    "        \n",
    "        inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "        preds = net.predict(test_dataset)\n",
    "        preds =  [inv_label_map[int(t)] for t in preds]\n",
    "        \n",
    "        results_with_best_channels = results_with_best_channels.append({\n",
    "            \"method\":met,\n",
    "            \"f1_micro\":f1_score(test_dataset.metadata.label, preds, average=\"micro\"),\n",
    "            \"f1_macro\":f1_score(test_dataset.metadata.label, preds, average=\"macro\"),\n",
    "            \"accuracy\":accuracy_score(test_dataset.metadata.label, preds),\n",
    "        },ignore_index = True)\n",
    "        net = None\n",
    "        resnet18_modified = None\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"---------------------------\"*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPermute</td>\n",
       "      <td>0.945805</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.945805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPermute</td>\n",
       "      <td>0.955258</td>\n",
       "      <td>0.953805</td>\n",
       "      <td>0.955258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPermute</td>\n",
       "      <td>0.936316</td>\n",
       "      <td>0.934746</td>\n",
       "      <td>0.936316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPermute</td>\n",
       "      <td>0.943828</td>\n",
       "      <td>0.942436</td>\n",
       "      <td>0.943828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPermute</td>\n",
       "      <td>0.946767</td>\n",
       "      <td>0.945362</td>\n",
       "      <td>0.946767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DeepLift</td>\n",
       "      <td>0.639243</td>\n",
       "      <td>0.636417</td>\n",
       "      <td>0.639243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DeepLift</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.630634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DeepLift</td>\n",
       "      <td>0.643697</td>\n",
       "      <td>0.632303</td>\n",
       "      <td>0.643697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DeepLift</td>\n",
       "      <td>0.653494</td>\n",
       "      <td>0.645024</td>\n",
       "      <td>0.653494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DeepLift</td>\n",
       "      <td>0.669824</td>\n",
       "      <td>0.661182</td>\n",
       "      <td>0.669824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IntegratedGradients</td>\n",
       "      <td>0.641528</td>\n",
       "      <td>0.632074</td>\n",
       "      <td>0.641528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IntegratedGradients</td>\n",
       "      <td>0.644024</td>\n",
       "      <td>0.632244</td>\n",
       "      <td>0.644024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IntegratedGradients</td>\n",
       "      <td>0.636185</td>\n",
       "      <td>0.621456</td>\n",
       "      <td>0.636185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IntegratedGradients</td>\n",
       "      <td>0.663619</td>\n",
       "      <td>0.651279</td>\n",
       "      <td>0.663619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IntegratedGradients</td>\n",
       "      <td>0.666884</td>\n",
       "      <td>0.656913</td>\n",
       "      <td>0.666884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LRP</td>\n",
       "      <td>0.651975</td>\n",
       "      <td>0.643473</td>\n",
       "      <td>0.651975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LRP</td>\n",
       "      <td>0.645656</td>\n",
       "      <td>0.640938</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LRP</td>\n",
       "      <td>0.645330</td>\n",
       "      <td>0.634032</td>\n",
       "      <td>0.645330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LRP</td>\n",
       "      <td>0.654148</td>\n",
       "      <td>0.643673</td>\n",
       "      <td>0.654148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LRP</td>\n",
       "      <td>0.659046</td>\n",
       "      <td>0.648102</td>\n",
       "      <td>0.659046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GuidedGradCAM</td>\n",
       "      <td>0.947437</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>0.947437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GuidedGradCAM</td>\n",
       "      <td>0.949053</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>0.949053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GuidedGradCAM</td>\n",
       "      <td>0.940235</td>\n",
       "      <td>0.938481</td>\n",
       "      <td>0.940235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GuidedGradCAM</td>\n",
       "      <td>0.942848</td>\n",
       "      <td>0.941263</td>\n",
       "      <td>0.942848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GuidedGradCAM</td>\n",
       "      <td>0.942195</td>\n",
       "      <td>0.940842</td>\n",
       "      <td>0.942195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 method  f1_micro  f1_macro  accuracy\n",
       "0             PXPermute  0.945805  0.944060  0.945805\n",
       "1             PXPermute  0.955258  0.953805  0.955258\n",
       "2             PXPermute  0.936316  0.934746  0.936316\n",
       "3             PXPermute  0.943828  0.942436  0.943828\n",
       "4             PXPermute  0.946767  0.945362  0.946767\n",
       "5              DeepLift  0.639243  0.636417  0.639243\n",
       "6              DeepLift  0.630634  0.629893  0.630634\n",
       "7              DeepLift  0.643697  0.632303  0.643697\n",
       "8              DeepLift  0.653494  0.645024  0.653494\n",
       "9              DeepLift  0.669824  0.661182  0.669824\n",
       "10  IntegratedGradients  0.641528  0.632074  0.641528\n",
       "11  IntegratedGradients  0.644024  0.632244  0.644024\n",
       "12  IntegratedGradients  0.636185  0.621456  0.636185\n",
       "13  IntegratedGradients  0.663619  0.651279  0.663619\n",
       "14  IntegratedGradients  0.666884  0.656913  0.666884\n",
       "15                  LRP  0.651975  0.643473  0.651975\n",
       "16                  LRP  0.645656  0.640938  0.645656\n",
       "17                  LRP  0.645330  0.634032  0.645330\n",
       "18                  LRP  0.654148  0.643673  0.654148\n",
       "19                  LRP  0.659046  0.648102  0.659046\n",
       "20        GuidedGradCAM  0.947437  0.945852  0.947437\n",
       "21        GuidedGradCAM  0.949053  0.947802  0.949053\n",
       "22        GuidedGradCAM  0.940235  0.938481  0.940235\n",
       "23        GuidedGradCAM  0.942848  0.941263  0.942848\n",
       "24        GuidedGradCAM  0.942195  0.940842  0.942195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_best_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': tensor([0.]),\n",
       " 'p01': tensor([0.0170]),\n",
       " 'p05': tensor([0.0272]),\n",
       " 'p25': tensor([0.0484]),\n",
       " 'p50': tensor([0.0764]),\n",
       " 'p75': tensor([0.1635]),\n",
       " 'p95': tensor([0.7942]),\n",
       " 'p99': tensor([2.1700]),\n",
       " 'max': tensor([250.7382]),\n",
       " 'mean': tensor([0.2241]),\n",
       " 'std': tensor([1.9374])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we calculate the statistics of every channel to later use for nomalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='method', ylabel='f1_micro'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(data = results_with_best_channels, \n",
    "            x = \"method\", \n",
    "            y = \"f1_micro\",\n",
    "           palette = [\"gray\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_best_channels.to_csv(\"results_with_best_channels.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc85c72049d21f557e30689d2619ffc4ab3f684c40ae26d281fe4539bf4644b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
